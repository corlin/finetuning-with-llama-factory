#!/usr/bin/env python3
"""
æœ€ç»ˆæ¼”ç¤ºç¨‹åº

åŸºäºå½“å‰å·²å®Œæˆçš„åŠŸèƒ½ï¼Œä½¿ç”¨ data/raw æ•°æ®ï¼Œå±•ç¤ºå®Œæ•´çš„æ•°æ®å¤„ç†å’Œé…ç½®ç”Ÿæˆæµç¨‹ã€‚
ä¸“æ³¨äºæ ¸å¿ƒåŠŸèƒ½å±•ç¤ºï¼Œé¿å…å¤æ‚çš„è®­ç»ƒæµæ°´çº¿ã€‚

åŠŸèƒ½ç‰¹æ€§ï¼š
- âœ… è‡ªåŠ¨åŠ è½½å’Œå¤„ç† data/raw ä¸­çš„æ‰€æœ‰æ•°æ®æ–‡ä»¶
- âœ… æ™ºèƒ½æ•°æ®é¢„å¤„ç†å’Œæ ¼å¼è½¬æ¢
- âœ… è‡ªåŠ¨é…ç½® GPU å¹¶è¡Œç­–ç•¥å’Œ LoRA å‚æ•°
- âœ… ç”Ÿæˆ LLaMA Factory å…¼å®¹çš„é…ç½®æ–‡ä»¶
- âœ… æä¾›å®Œæ•´çš„è®­ç»ƒå‡†å¤‡å’ŒæŒ‡å¯¼

ä½¿ç”¨æ–¹æ³•ï¼š
    uv run python demo_final.py
"""

import os
import sys
import json
import yaml
import logging
import argparse
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
from data_models import TrainingExample, DifficultyLevel
from config_manager import TrainingConfig, DataConfig, SystemConfig
from lora_config_optimizer import LoRAConfigOptimizer, LoRAMemoryProfile
from parallel_config import ParallelConfig, ParallelStrategy
from gpu_utils import GPUDetector
from llamafactory_adapter import LlamaFactoryAdapter


class FinalDemo:
    """æœ€ç»ˆæ¼”ç¤ºç±»"""
    
    def __init__(self, output_dir: str = "final_demo_output"):
        """
        åˆå§‹åŒ–æ¼”ç¤ºç¨‹åº
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # è®¾ç½®æ—¥å¿—
        self.setup_logging()
        self.logger = logging.getLogger(__name__)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.gpu_detector = GPUDetector()
        self.lora_optimizer = LoRAConfigOptimizer()
        self.llamafactory_adapter = LlamaFactoryAdapter(self.logger)
        
        # æ•°æ®å­˜å‚¨
        self.training_data: List[TrainingExample] = []
        
        self.logger.info("æœ€ç»ˆæ¼”ç¤ºç¨‹åºåˆå§‹åŒ–å®Œæˆ")
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—é…ç½®"""
        log_file = self.output_dir / f"demo_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )
    
    def load_and_process_data(self, data_dir: str = "data/raw") -> bool:
        """
        åŠ è½½å’Œå¤„ç†åŸå§‹æ•°æ®
        
        Args:
            data_dir: æ•°æ®ç›®å½•è·¯å¾„
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸåŠ è½½æ•°æ®
        """
        try:
            data_path = Path(data_dir)
            if not data_path.exists():
                self.logger.error(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_path}")
                return False
            
            # æŸ¥æ‰¾æ‰€æœ‰markdownæ–‡ä»¶
            md_files = list(data_path.glob("*.md"))
            if not md_files:
                self.logger.error(f"åœ¨ {data_path} ä¸­æœªæ‰¾åˆ°markdownæ–‡ä»¶")
                return False
            
            self.logger.info(f"æ‰¾åˆ° {len(md_files)} ä¸ªæ•°æ®æ–‡ä»¶")
            
            total_examples = 0
            
            for md_file in md_files:
                self.logger.info(f"å¤„ç†æ–‡ä»¶: {md_file.name}")
                
                # è¯»å–æ–‡ä»¶å†…å®¹
                with open(md_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # è§£æQAå¯¹
                examples = self.parse_qa_content(content, str(md_file))
                
                if examples:
                    self.training_data.extend(examples)
                    total_examples += len(examples)
                    self.logger.info(f"ä» {md_file.name} è§£æå‡º {len(examples)} ä¸ªè®­ç»ƒæ ·ä¾‹")
            
            self.logger.info(f"æ€»å…±åŠ è½½äº† {total_examples} ä¸ªè®­ç»ƒæ ·ä¾‹")
            return total_examples > 0
            
        except Exception as e:
            self.logger.error(f"åŠ è½½å’Œå¤„ç†æ•°æ®å¤±è´¥: {e}")
            return False
    
    def parse_qa_content(self, content: str, source_file: str) -> List[TrainingExample]:
        """
        è§£æQAå†…å®¹ä¸ºè®­ç»ƒæ ·ä¾‹
        
        Args:
            content: æ–‡ä»¶å†…å®¹
            source_file: æºæ–‡ä»¶è·¯å¾„
            
        Returns:
            List[TrainingExample]: è®­ç»ƒæ ·ä¾‹åˆ—è¡¨
        """
        examples = []
        
        # åˆ†å‰²å†…å®¹ä¸ºæ®µè½
        sections = content.split('\n\n')
        
        current_question = ""
        current_thinking = ""
        current_answer = ""
        
        for section in sections:
            section = section.strip()
            if not section:
                continue
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯é—®é¢˜
            if section.startswith('### Q') or (section.startswith('##') and '?' in section):
                # ä¿å­˜ä¹‹å‰çš„QAå¯¹
                if current_question and current_answer:
                    example = self.create_training_example(
                        current_question, current_answer, current_thinking, source_file
                    )
                    if example:
                        examples.append(example)
                
                # å¼€å§‹æ–°çš„QAå¯¹
                current_question = section
                current_thinking = ""
                current_answer = ""
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯thinkingå†…å®¹
            elif '<thinking>' in section:
                current_thinking = section
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç­”æ¡ˆ
            elif section.startswith('A') and ':' in section:
                current_answer = section
        
        # å¤„ç†æœ€åä¸€ä¸ªQAå¯¹
        if current_question and current_answer:
            example = self.create_training_example(
                current_question, current_answer, current_thinking, source_file
            )
            if example:
                examples.append(example)
        
        return examples
    
    def create_training_example(self, question: str, answer: str, thinking: str, source_file: str) -> Optional[TrainingExample]:
        """
        åˆ›å»ºè®­ç»ƒæ ·ä¾‹
        
        Args:
            question: é—®é¢˜
            answer: ç­”æ¡ˆ
            thinking: æ€è€ƒè¿‡ç¨‹
            source_file: æºæ–‡ä»¶
            
        Returns:
            Optional[TrainingExample]: è®­ç»ƒæ ·ä¾‹
        """
        try:
            # æ¸…ç†é—®é¢˜æ–‡æœ¬
            instruction = question.replace('###', '').replace('##', '').strip()
            if ':' in instruction:
                instruction = instruction.split(':', 1)[1].strip()
            
            # æ¸…ç†ç­”æ¡ˆæ–‡æœ¬
            output = answer
            if ':' in output and output.startswith('A'):
                output = output.split(':', 1)[1].strip()
            
            # å¤„ç†thinkingå†…å®¹
            thinking_content = None
            if thinking and '<thinking>' in thinking:
                thinking_content = thinking
            
            if not instruction or not output:
                return None
            
            # æå–å¯†ç å­¦æœ¯è¯­
            crypto_terms = self.extract_crypto_terms(instruction + " " + output)
            
            # åˆ¤æ–­éš¾åº¦çº§åˆ«
            difficulty = self.determine_difficulty(instruction, output)
            
            return TrainingExample(
                instruction=instruction,
                input="",
                output=output,
                thinking=thinking_content,
                crypto_terms=crypto_terms,
                difficulty_level=difficulty,
                source_file=source_file
            )
            
        except Exception as e:
            self.logger.error(f"åˆ›å»ºè®­ç»ƒæ ·ä¾‹å¤±è´¥: {e}")
            return None
    
    def extract_crypto_terms(self, text: str) -> List[str]:
        """æå–å¯†ç å­¦æœ¯è¯­"""
        crypto_keywords = [
            "å¯†ç å­¦", "åŠ å¯†", "è§£å¯†", "å“ˆå¸Œ", "æ•°å­—ç­¾å", "å…¬é’¥", "ç§é’¥", "å¯¹ç§°åŠ å¯†", "éå¯¹ç§°åŠ å¯†",
            "AES", "RSA", "SHA", "MD5", "DES", "3DES", "ECC", "DSA", "ECDSA",
            "å¯†é’¥ç®¡ç†", "è¯ä¹¦", "PKI", "CA", "æ•°å­—è¯ä¹¦", "èº«ä»½è®¤è¯", "è®¿é—®æ§åˆ¶",
            "å®Œæ•´æ€§", "æœºå¯†æ€§", "çœŸå®æ€§", "ä¸å¯å¦è®¤æ€§", "éšæœºæ•°", "å¯†é’¥äº¤æ¢"
        ]
        
        found_terms = []
        text_lower = text.lower()
        
        for term in crypto_keywords:
            if term.lower() in text_lower or term in text:
                found_terms.append(term)
        
        return list(set(found_terms))
    
    def determine_difficulty(self, instruction: str, output: str) -> DifficultyLevel:
        """åˆ¤æ–­éš¾åº¦çº§åˆ«"""
        text = instruction + " " + output
        text_len = len(text)
        
        if text_len < 200:
            return DifficultyLevel.BEGINNER
        elif text_len < 500:
            return DifficultyLevel.INTERMEDIATE
        elif text_len < 1000:
            return DifficultyLevel.ADVANCED
        else:
            return DifficultyLevel.EXPERT
    
    def auto_configure_training(self) -> tuple:
        """
        è‡ªåŠ¨é…ç½®è®­ç»ƒå‚æ•°
        
        Returns:
            tuple: (training_config, data_config, lora_config, parallel_config, system_config)
        """
        self.logger.info("å¼€å§‹è‡ªåŠ¨é…ç½®è®­ç»ƒå‚æ•°...")
        
        # æ£€æµ‹GPUç¯å¢ƒ
        gpu_infos = self.gpu_detector.get_all_gpu_info()
        gpu_count = len(gpu_infos) if gpu_infos else 1
        
        self.logger.info(f"æ£€æµ‹åˆ° {gpu_count} ä¸ªGPU")
        
        # é…ç½®è®­ç»ƒå‚æ•°
        training_config = TrainingConfig(
            output_dir=str(self.output_dir / "model_output"),
            num_train_epochs=2,
            per_device_train_batch_size=1,
            per_device_eval_batch_size=1,
            gradient_accumulation_steps=4,
            learning_rate=2e-4,
            lr_scheduler_type="cosine",
            warmup_ratio=0.1,
            weight_decay=0.01,
            save_steps=100,
            eval_steps=100,
            logging_steps=10,
            save_total_limit=3,
            load_best_model_at_end=True,
            metric_for_best_model="eval_loss",
            bf16=True,
            fp16=False,
            seed=42
        )
        
        # é…ç½®æ•°æ®å‚æ•°
        data_config = DataConfig(
            max_samples=len(self.training_data),
            train_split_ratio=0.9,
            eval_split_ratio=0.1,
            test_split_ratio=0.0,
            shuffle_data=True
        )
        
        # é…ç½®å¹¶è¡Œç­–ç•¥
        if gpu_count > 1:
            parallel_config = ParallelConfig(
                strategy=ParallelStrategy.DATA_PARALLEL,
                data_parallel_size=gpu_count,
                tensor_parallel_size=1,
                pipeline_parallel_size=1,
                master_addr="localhost",
                master_port=29500
            )
        else:
            parallel_config = ParallelConfig(
                strategy=ParallelStrategy.DATA_PARALLEL,
                data_parallel_size=1,
                tensor_parallel_size=1,
                pipeline_parallel_size=1
            )
        
        # é…ç½®LoRAå‚æ•°
        if gpu_infos:
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªGPUçš„ä¿¡æ¯æ¥é…ç½®LoRA
            gpu_memory = gpu_infos[0].total_memory  # ä»¥MBä¸ºå•ä½
            lora_config = self.lora_optimizer.optimize_for_single_gpu(
                available_memory_mb=gpu_memory,
                batch_size=training_config.per_device_train_batch_size,
                sequence_length=2048
            )
        else:
            # é»˜è®¤LoRAé…ç½®
            lora_config = LoRAMemoryProfile(
                rank=8,
                alpha=16,
                dropout=0.1,
                target_modules=["q_proj", "k_proj", "v_proj", "o_proj"]
            )
        
        # ç³»ç»Ÿé…ç½®
        system_config = SystemConfig(
            mixed_precision="bf16" if gpu_count > 0 else "no",
            cuda_visible_devices=",".join(str(i) for i in range(gpu_count)) if gpu_count > 0 else None,
            log_level="INFO"
        )
        
        self.logger.info("è®­ç»ƒå‚æ•°é…ç½®å®Œæˆ")
        self.logger.info(f"- è®­ç»ƒè½®æ•°: {training_config.num_train_epochs}")
        self.logger.info(f"- æ‰¹æ¬¡å¤§å°: {training_config.per_device_train_batch_size}")
        self.logger.info(f"- å­¦ä¹ ç‡: {training_config.learning_rate}")
        self.logger.info(f"- LoRA rank: {lora_config.rank}")
        self.logger.info(f"- å¹¶è¡Œç­–ç•¥: {parallel_config.strategy.value}")
        
        return training_config, data_config, lora_config, parallel_config, system_config
    
    def prepare_training_files(self, configs: tuple) -> Dict[str, str]:
        """
        å‡†å¤‡è®­ç»ƒæ–‡ä»¶
        
        Args:
            configs: é…ç½®å…ƒç»„
            
        Returns:
            Dict[str, str]: ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„
        """
        training_config, data_config, lora_config, parallel_config, system_config = configs
        
        try:
            # å‡†å¤‡è®­ç»ƒæ•°æ®
            dataset_name = "crypto_qa_dataset"
            data_files = self.llamafactory_adapter.prepare_training_data(
                self.training_data,
                str(self.output_dir / "data"),
                dataset_name,
                "alpaca",
                0.9
            )
            
            # ç”Ÿæˆè®­ç»ƒé…ç½®
            config_file = self.llamafactory_adapter.create_training_config(
                training_config,
                data_config,
                lora_config,
                parallel_config,
                dataset_name,
                str(self.output_dir / "configs")
            )
            
            # ç”Ÿæˆè®­ç»ƒè„šæœ¬
            script_file = self.llamafactory_adapter.generate_training_script(
                config_file,
                str(self.output_dir / "train.py")
            )
            
            result = {
                "train_data": data_files.get("train_file", ""),
                "val_data": data_files.get("val_file", ""),
                "dataset_info": data_files.get("dataset_info_file", ""),
                "config_file": config_file,
                "script_file": script_file
            }
            
            self.logger.info("è®­ç»ƒæ–‡ä»¶å‡†å¤‡å®Œæˆ")
            return result
            
        except Exception as e:
            self.logger.error(f"å‡†å¤‡è®­ç»ƒæ–‡ä»¶å¤±è´¥: {e}")
            return {}
    
    def generate_comprehensive_report(self, configs: tuple, files: Dict[str, str]) -> str:
        """
        ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        
        Args:
            configs: é…ç½®å…ƒç»„
            files: æ–‡ä»¶è·¯å¾„å­—å…¸
            
        Returns:
            str: æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        try:
            training_config, data_config, lora_config, parallel_config, system_config = configs
            
            # ç»Ÿè®¡ä¿¡æ¯
            difficulty_dist = {}
            crypto_terms_count = {}
            thinking_count = 0
            
            for example in self.training_data:
                # éš¾åº¦åˆ†å¸ƒ
                level = example.difficulty_level.name
                difficulty_dist[level] = difficulty_dist.get(level, 0) + 1
                
                # æœ¯è¯­ç»Ÿè®¡
                for term in example.crypto_terms:
                    crypto_terms_count[term] = crypto_terms_count.get(term, 0) + 1
                
                # thinkingæ ·ä¾‹ç»Ÿè®¡
                if example.has_thinking():
                    thinking_count += 1
            
            # GPUä¿¡æ¯
            gpu_infos = self.gpu_detector.get_all_gpu_info()
            gpu_summary = []
            for gpu in gpu_infos:
                gpu_summary.append({
                    "name": gpu.name,
                    "memory_gb": round(gpu.total_memory / 1024, 1),
                    "compute_capability": f"{gpu.compute_capability[0]}.{gpu.compute_capability[1]}" if gpu.compute_capability else "Unknown",
                    "utilization": f"{gpu.utilization}%",
                    "temperature": f"{gpu.temperature}Â°C" if gpu.temperature else "N/A"
                })
            
            report = {
                "demo_info": {
                    "name": "æœ€ç»ˆå¾®è°ƒæ¼”ç¤ºç¨‹åº",
                    "version": "1.0.0",
                    "execution_time": datetime.now().isoformat(),
                    "output_directory": str(self.output_dir)
                },
                "data_analysis": {
                    "total_examples": len(self.training_data),
                    "thinking_examples": thinking_count,
                    "thinking_ratio": round(thinking_count / len(self.training_data) * 100, 1) if self.training_data else 0,
                    "difficulty_distribution": difficulty_dist,
                    "top_crypto_terms": dict(sorted(crypto_terms_count.items(), key=lambda x: x[1], reverse=True)[:15]),
                    "avg_instruction_length": round(sum(len(ex.instruction) for ex in self.training_data) / len(self.training_data), 1) if self.training_data else 0,
                    "avg_output_length": round(sum(len(ex.output) for ex in self.training_data) / len(self.training_data), 1) if self.training_data else 0
                },
                "hardware_analysis": {
                    "gpu_count": len(gpu_infos),
                    "total_gpu_memory_gb": sum(gpu.total_memory / 1024 for gpu in gpu_infos),
                    "gpu_details": gpu_summary,
                    "recommended_batch_size": 1 if gpu_infos else "CPUæ¨¡å¼",
                    "parallel_strategy": parallel_config.strategy.value
                },
                "training_configuration": {
                    "model": "Qwen/Qwen3-4B-Thinking-2507",
                    "epochs": training_config.num_train_epochs,
                    "learning_rate": training_config.learning_rate,
                    "batch_size": training_config.per_device_train_batch_size,
                    "lora_rank": lora_config.rank,
                    "lora_alpha": lora_config.alpha,
                    "sequence_length": 2048,
                    "mixed_precision": system_config.mixed_precision
                },
                "generated_files": files,
                "training_instructions": {
                    "prerequisites": [
                        "ç¡®ä¿å·²å®‰è£… LLaMA Factory: pip install llamafactory",
                        "æ£€æŸ¥CUDAç¯å¢ƒï¼ˆå¦‚æœä½¿ç”¨GPUï¼‰",
                        "ç¡®è®¤æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´ç”¨äºæ¨¡å‹è¾“å‡º"
                    ],
                    "training_commands": [
                        f"cd {self.output_dir}",
                        f"llamafactory-cli train {files.get('config_file', 'config.yaml')}",
                        "æˆ–è€…è¿è¡Œ: python train.py"
                    ],
                    "monitoring": [
                        "è®­ç»ƒè¿‡ç¨‹ä¸­å¯ä»¥é€šè¿‡ tensorboard ç›‘æ§",
                        f"tensorboard --logdir {training_config.output_dir}/logs",
                        "æ£€æŸ¥ç”Ÿæˆçš„æ¨¡å‹æ–‡ä»¶å’Œæ£€æŸ¥ç‚¹"
                    ]
                },
                "performance_estimates": {
                    "estimated_training_time": self.estimate_training_time(len(self.training_data), gpu_infos),
                    "memory_usage": self.estimate_memory_usage(lora_config, gpu_infos),
                    "disk_space_needed": "çº¦ 2-5GBï¼ˆå–å†³äºæ£€æŸ¥ç‚¹æ•°é‡ï¼‰"
                }
            }
            
            # ä¿å­˜æŠ¥å‘Š
            report_file = self.output_dir / f"comprehensive_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"ç»¼åˆæŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
            return str(report_file)
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆç»¼åˆæŠ¥å‘Šå¤±è´¥: {e}")
            return ""
    
    def estimate_training_time(self, num_examples: int, gpu_infos: List) -> str:
        """ä¼°ç®—è®­ç»ƒæ—¶é—´"""
        if not gpu_infos:
            return "CPUæ¨¡å¼ï¼šé¢„è®¡æ•°å°æ—¶"
        
        # ç®€å•ä¼°ç®—ï¼šåŸºäºæ ·ä¾‹æ•°é‡å’ŒGPUæ€§èƒ½
        samples_per_minute = 10 * len(gpu_infos)  # å‡è®¾æ¯ä¸ªGPUæ¯åˆ†é’Ÿå¤„ç†10ä¸ªæ ·ä¾‹
        total_minutes = (num_examples * 2) / samples_per_minute  # 2ä¸ªepoch
        
        if total_minutes < 60:
            return f"çº¦ {int(total_minutes)} åˆ†é’Ÿ"
        else:
            hours = int(total_minutes // 60)
            minutes = int(total_minutes % 60)
            return f"çº¦ {hours} å°æ—¶ {minutes} åˆ†é’Ÿ"
    
    def estimate_memory_usage(self, lora_config, gpu_infos: List) -> str:
        """ä¼°ç®—å†…å­˜ä½¿ç”¨"""
        if not gpu_infos:
            return "CPUæ¨¡å¼ï¼šçº¦ 8-16GB ç³»ç»Ÿå†…å­˜"
        
        # åŸºäºLoRAé…ç½®ä¼°ç®—GPUå†…å­˜ä½¿ç”¨
        base_memory = 6  # Qwen3-4BåŸºç¡€å†…å­˜éœ€æ±‚ï¼ˆGBï¼‰
        lora_memory = lora_config.rank * 0.1  # LoRAé¢å¤–å†…å­˜
        total_memory = base_memory + lora_memory
        
        return f"çº¦ {total_memory:.1f}GB GPUå†…å­˜ / GPU"
    
    def print_final_summary(self, report_data: Dict[str, Any]):
        """æ‰“å°æœ€ç»ˆæ€»ç»“"""
        print("\n" + "="*80)
        print("ğŸ‰ æœ€ç»ˆå¾®è°ƒæ¼”ç¤ºç¨‹åºæ‰§è¡Œå®Œæˆï¼")
        print("="*80)
        
        data_analysis = report_data["data_analysis"]
        print(f"ğŸ“Š æ•°æ®åˆ†æ:")
        print(f"   - æ€»è®­ç»ƒæ ·ä¾‹: {data_analysis['total_examples']}")
        print(f"   - Thinkingæ ·ä¾‹: {data_analysis['thinking_examples']} ({data_analysis['thinking_ratio']}%)")
        print(f"   - å¹³å‡æŒ‡ä»¤é•¿åº¦: {data_analysis['avg_instruction_length']} å­—ç¬¦")
        print(f"   - å¹³å‡è¾“å‡ºé•¿åº¦: {data_analysis['avg_output_length']} å­—ç¬¦")
        
        print(f"\nğŸ“ˆ éš¾åº¦åˆ†å¸ƒ:")
        for level, count in data_analysis["difficulty_distribution"].items():
            print(f"   - {level}: {count}")
        
        print(f"\nğŸ”‘ çƒ­é—¨å¯†ç å­¦æœ¯è¯­:")
        for term, count in list(data_analysis["top_crypto_terms"].items())[:5]:
            print(f"   - {term}: {count}")
        
        hardware_analysis = report_data["hardware_analysis"]
        print(f"\nğŸ–¥ï¸ ç¡¬ä»¶é…ç½®:")
        print(f"   - GPUæ•°é‡: {hardware_analysis['gpu_count']}")
        print(f"   - æ€»GPUå†…å­˜: {hardware_analysis['total_gpu_memory_gb']:.1f}GB")
        print(f"   - å¹¶è¡Œç­–ç•¥: {hardware_analysis['parallel_strategy']}")
        
        training_config = report_data["training_configuration"]
        print(f"\nâš™ï¸ è®­ç»ƒé…ç½®:")
        print(f"   - æ¨¡å‹: {training_config['model']}")
        print(f"   - è®­ç»ƒè½®æ•°: {training_config['epochs']}")
        print(f"   - å­¦ä¹ ç‡: {training_config['learning_rate']}")
        print(f"   - LoRA rank: {training_config['lora_rank']}")
        
        performance = report_data["performance_estimates"]
        print(f"\nâ±ï¸ æ€§èƒ½é¢„ä¼°:")
        print(f"   - é¢„è®¡è®­ç»ƒæ—¶é—´: {performance['estimated_training_time']}")
        print(f"   - å†…å­˜ä½¿ç”¨: {performance['memory_usage']}")
        print(f"   - ç£ç›˜ç©ºé—´: {performance['disk_space_needed']}")
        
        print(f"\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        files = report_data["generated_files"]
        for file_type, file_path in files.items():
            if file_path:
                print(f"   - {file_type}: {file_path}")
        
        print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ:")
        instructions = report_data["training_instructions"]
        print("   å‰ç½®æ¡ä»¶:")
        for prereq in instructions["prerequisites"]:
            print(f"     â€¢ {prereq}")
        
        print("   è®­ç»ƒå‘½ä»¤:")
        for cmd in instructions["training_commands"]:
            print(f"     â€¢ {cmd}")
        
        print("\n" + "="*80)
    
    def run_demo(self, data_dir: str = "data/raw") -> bool:
        """
        è¿è¡Œå®Œæ•´æ¼”ç¤º
        
        Args:
            data_dir: æ•°æ®ç›®å½•
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸå®Œæˆ
        """
        try:
            print("ğŸš€ å¯åŠ¨æœ€ç»ˆå¾®è°ƒæ¼”ç¤ºç¨‹åº...")
            print(f"ğŸ“‚ æ•°æ®ç›®å½•: {data_dir}")
            print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")
            
            # 1. åŠ è½½å’Œå¤„ç†æ•°æ®
            print("\nğŸ“– æ­¥éª¤ 1: åŠ è½½å’Œå¤„ç†æ•°æ®...")
            if not self.load_and_process_data(data_dir):
                print("âŒ æ•°æ®åŠ è½½å¤±è´¥")
                return False
            
            print(f"âœ… æˆåŠŸåŠ è½½ {len(self.training_data)} ä¸ªè®­ç»ƒæ ·ä¾‹")
            
            # 2. è‡ªåŠ¨é…ç½®è®­ç»ƒå‚æ•°
            print("\nâš™ï¸ æ­¥éª¤ 2: è‡ªåŠ¨é…ç½®è®­ç»ƒå‚æ•°...")
            configs = self.auto_configure_training()
            print("âœ… è®­ç»ƒå‚æ•°é…ç½®å®Œæˆ")
            
            # 3. å‡†å¤‡è®­ç»ƒæ–‡ä»¶
            print("\nğŸ“ æ­¥éª¤ 3: å‡†å¤‡è®­ç»ƒæ–‡ä»¶...")
            files = self.prepare_training_files(configs)
            if not files:
                print("âŒ è®­ç»ƒæ–‡ä»¶å‡†å¤‡å¤±è´¥")
                return False
            
            print("âœ… è®­ç»ƒæ–‡ä»¶å‡†å¤‡å®Œæˆ")
            
            # 4. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
            print("\nğŸ“Š æ­¥éª¤ 4: ç”Ÿæˆç»¼åˆæŠ¥å‘Š...")
            report_file = self.generate_comprehensive_report(configs, files)
            if not report_file:
                print("âŒ ç»¼åˆæŠ¥å‘Šç”Ÿæˆå¤±è´¥")
                return False
            
            print("âœ… ç»¼åˆæŠ¥å‘Šç”Ÿæˆå®Œæˆ")
            
            # 5. æ˜¾ç¤ºæœ€ç»ˆæ€»ç»“
            with open(report_file, 'r', encoding='utf-8') as f:
                report_data = json.load(f)
            
            self.print_final_summary(report_data)
            
            return True
                
        except Exception as e:
            self.logger.error(f"æ¼”ç¤ºç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
            print(f"âŒ æ¼”ç¤ºç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æœ€ç»ˆå¾®è°ƒæ¼”ç¤ºç¨‹åº")
    parser.add_argument("--data-dir", default="data/raw", help="æ•°æ®ç›®å½•è·¯å¾„")
    parser.add_argument("--output-dir", default="final_demo_output", help="è¾“å‡ºç›®å½•è·¯å¾„")
    parser.add_argument("--verbose", "-v", action="store_true", help="è¯¦ç»†è¾“å‡º")
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # åˆ›å»ºæ¼”ç¤ºç¨‹åº
    demo = FinalDemo(output_dir=args.output_dir)
    
    # è¿è¡Œæ¼”ç¤º
    success = demo.run_demo(data_dir=args.data_dir)
    
    if success:
        print("\nğŸ‰ æ¼”ç¤ºç¨‹åºæ‰§è¡ŒæˆåŠŸï¼")
        sys.exit(0)
    else:
        print("\nğŸ’¥ æ¼”ç¤ºç¨‹åºæ‰§è¡Œå¤±è´¥ï¼")
        sys.exit(1)


if __name__ == "__main__":
    main()
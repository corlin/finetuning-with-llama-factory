#!/usr/bin/env python3
"""
å°†æ‰€æœ‰å¢å¼ºçš„QAæ•°æ®è½¬æ¢ä¸ºLLaMA Factoryè®­ç»ƒæ ¼å¼
åŒ…æ‹¬QA1-QA6çš„æ‰€æœ‰thinkingæ•°æ®
"""

import json
import re
import os
from pathlib import Path
from dataclasses import dataclass
from typing import List, Dict, Optional

@dataclass
class ThinkingExample:
    """æ€è€ƒç¤ºä¾‹æ•°æ®ç»“æ„"""
    question: str
    thinking: str
    answer: str
    difficulty: str = "INTERMEDIATE"
    source_file: str = ""
    
    def to_llama_factory_format(self) -> Dict:
        """è½¬æ¢ä¸ºLLaMA Factoryæ ¼å¼"""
        system_prompt = "ä½ æ˜¯ä¸€ä¸ªå¯†ç å­¦ä¸“å®¶ï¼Œè¯·æ ¹æ®GB/T 39786-2021ç­‰ç›¸å…³æ ‡å‡†å›ç­”é—®é¢˜ã€‚åœ¨å›ç­”å‰ï¼Œè¯·åœ¨<thinking>æ ‡ç­¾ä¸­å±•ç¤ºä½ çš„æ€è€ƒè¿‡ç¨‹ã€‚"
        
        instruction = self.question
        thinking_content = f"<thinking>\n{self.thinking}\n</thinking>\n\n{self.answer}"
        
        return {
            "instruction": instruction,
            "input": "",
            "output": thinking_content,
            "system": system_prompt,
            "history": []
        }

class ComprehensiveQAProcessor:
    """ç»¼åˆQAæ•°æ®å¤„ç†å™¨"""
    
    def __init__(self):
        self.thinking_pattern = re.compile(r'<thinking>(.*?)</thinking>', re.DOTALL)
        self.qa_pattern = re.compile(r'### (Q\d+): (.+?)\n\n<thinking>(.*?)</thinking>\n\n(A\d+): (.+?)(?=\n### |$)', re.DOTALL)
        
    def parse_enhanced_file(self, file_path: str) -> List[ThinkingExample]:
        """è§£æå¢å¼ºçš„QAæ–‡ä»¶"""
        examples = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            matches = self.qa_pattern.findall(content)
            
            for match in matches:
                q_id, question, thinking, a_id, answer = match
                
                # æ¸…ç†æ–‡æœ¬
                question = question.strip()
                thinking = thinking.strip()
                answer = answer.strip()
                
                # åˆ¤æ–­éš¾åº¦çº§åˆ«
                difficulty = self._determine_difficulty(question, thinking, answer)
                
                example = ThinkingExample(
                    question=question,
                    thinking=thinking,
                    answer=answer,
                    difficulty=difficulty,
                    source_file=os.path.basename(file_path)
                )
                
                examples.append(example)
                
        except Exception as e:
            print(f"è§£ææ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
            
        return examples
    
    def _determine_difficulty(self, question: str, thinking: str, answer: str) -> str:
        """åˆ¤æ–­é—®é¢˜éš¾åº¦çº§åˆ«"""
        # åŸºäºå…³é”®è¯å’Œthinkingå¤æ‚åº¦åˆ¤æ–­éš¾åº¦
        expert_keywords = ['ç¬¬å››çº§', 'ç¬¬ä¸‰çº§', 'SM2', 'SM3', 'SM4', 'ZUC', 'æ¤­åœ†æ›²çº¿', 'æ•°å­—ç­¾å', 
                          'å¯†é’¥åå•†', 'è¯ä¹¦é“¾', 'SCADA', 'V2X', 'åŒºå—é“¾', 'é‡å­è®¡ç®—']
        intermediate_keywords = ['ç¬¬äºŒçº§', 'å¯†ç åº”ç”¨', 'å®‰å…¨æ€§', 'å®Œæ•´æ€§', 'æœºå¯†æ€§', 'èº«ä»½é‰´åˆ«', 
                               'è®¿é—®æ§åˆ¶', 'å¯†é’¥ç®¡ç†', 'è¯„ä¼°æµç¨‹']
        
        text = f"{question} {thinking} {answer}".lower()
        
        expert_count = sum(1 for keyword in expert_keywords if keyword.lower() in text)
        intermediate_count = sum(1 for keyword in intermediate_keywords if keyword.lower() in text)
        
        thinking_length = len(thinking)
        
        if expert_count >= 2 or thinking_length > 800:
            return "EXPERT"
        elif intermediate_count >= 2 or thinking_length > 400:
            return "INTERMEDIATE"
        else:
            return "BEGINNER"
    
    def process_all_enhanced_files(self) -> List[ThinkingExample]:
        """å¤„ç†æ‰€æœ‰å¢å¼ºçš„QAæ–‡ä»¶"""
        enhanced_files = [
            "data/raw/enhanced_QA1.md",
            "data/raw/enhanced_QA2.md", 
            "data/raw/enhanced_QA3.md",
            "data/raw/enhanced_QA4.md",
            "data/raw/enhanced_QA5.md",
            "data/raw/enhanced_QA6.md"
        ]
        
        all_examples = []
        
        for file_path in enhanced_files:
            if os.path.exists(file_path):
                print(f"å¤„ç†æ–‡ä»¶: {file_path}")
                examples = self.parse_enhanced_file(file_path)
                all_examples.extend(examples)
                print(f"  è§£æåˆ° {len(examples)} ä¸ªé—®é¢˜")
            else:
                print(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        return all_examples
    
    def convert_to_llama_factory_format(self, examples: List[ThinkingExample]) -> List[Dict]:
        """è½¬æ¢ä¸ºLLaMA Factoryæ ¼å¼"""
        return [example.to_llama_factory_format() for example in examples]
    
    def save_training_data(self, examples: List[ThinkingExample], output_dir: str = "data/processed"):
        """ä¿å­˜è®­ç»ƒæ•°æ®"""
        os.makedirs(output_dir, exist_ok=True)
        
        # è½¬æ¢ä¸ºLLaMA Factoryæ ¼å¼
        llama_data = self.convert_to_llama_factory_format(examples)
        
        # ä¿å­˜å®Œæ•´æ•°æ®é›†
        full_path = os.path.join(output_dir, "thinking_training_data.json")
        with open(full_path, 'w', encoding='utf-8') as f:
            json.dump(llama_data, f, ensure_ascii=False, indent=2)
        
        print(f"å®Œæ•´è®­ç»ƒæ•°æ®å·²ä¿å­˜åˆ°: {full_path}")
        
        # æŒ‰éš¾åº¦çº§åˆ«åˆ†åˆ«ä¿å­˜
        difficulty_data = {"BEGINNER": [], "INTERMEDIATE": [], "EXPERT": []}
        
        for example in examples:
            difficulty_data[example.difficulty].append(example.to_llama_factory_format())
        
        for difficulty, data in difficulty_data.items():
            if data:
                difficulty_path = os.path.join(output_dir, f"thinking_data_{difficulty.lower()}.json")
                with open(difficulty_path, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
                print(f"{difficulty}çº§åˆ«æ•°æ®å·²ä¿å­˜åˆ°: {difficulty_path} ({len(data)}ä¸ªæ ·ä¾‹)")
        
        # æŒ‰æ¥æºæ–‡ä»¶åˆ†åˆ«ä¿å­˜
        source_data = {}
        for example in examples:
            source = example.source_file
            if source not in source_data:
                source_data[source] = []
            source_data[source].append(example.to_llama_factory_format())
        
        for source, data in source_data.items():
            source_name = source.replace('.md', '').replace('enhanced_', '')
            source_path = os.path.join(output_dir, f"thinking_data_{source_name}.json")
            with open(source_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"{source}æ•°æ®å·²ä¿å­˜åˆ°: {source_path} ({len(data)}ä¸ªæ ·ä¾‹)")
    
    def generate_comprehensive_report(self, examples: List[ThinkingExample]) -> Dict:
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        if not examples:
            return {}
        
        # åŸºæœ¬ç»Ÿè®¡
        total_examples = len(examples)
        difficulty_counts = {}
        source_counts = {}
        thinking_lengths = []
        
        for example in examples:
            # éš¾åº¦ç»Ÿè®¡
            difficulty_counts[example.difficulty] = difficulty_counts.get(example.difficulty, 0) + 1
            
            # æ¥æºç»Ÿè®¡
            source_counts[example.source_file] = source_counts.get(example.source_file, 0) + 1
            
            # thinkingé•¿åº¦ç»Ÿè®¡
            thinking_lengths.append(len(example.thinking))
        
        # ä¸“ä¸šæœ¯è¯­ç»Ÿè®¡
        crypto_terms = ['å¯†ç ', 'åŠ å¯†', 'è§£å¯†', 'ç­¾å', 'è®¤è¯', 'å®Œæ•´æ€§', 'æœºå¯†æ€§', 'çœŸå®æ€§', 
                       'ä¸å¯å¦è®¤', 'å¯†é’¥', 'SM2', 'SM3', 'SM4', 'ZUC', 'æ¤­åœ†æ›²çº¿', 'å“ˆå¸Œ']
        
        term_counts = {}
        all_text = ' '.join([f"{ex.question} {ex.thinking} {ex.answer}" for ex in examples])
        
        for term in crypto_terms:
            count = all_text.count(term)
            if count > 0:
                term_counts[term] = count
        
        return {
            "total_examples": total_examples,
            "difficulty_distribution": difficulty_counts,
            "source_distribution": source_counts,
            "thinking_length_stats": {
                "average": sum(thinking_lengths) / len(thinking_lengths),
                "min": min(thinking_lengths),
                "max": max(thinking_lengths),
                "median": sorted(thinking_lengths)[len(thinking_lengths)//2]
            },
            "crypto_term_frequency": dict(sorted(term_counts.items(), key=lambda x: x[1], reverse=True)[:20])
        }

def main():
    """ä¸»å‡½æ•°"""
    print("=== ç»¼åˆQAæ•°æ®å¤„ç†å’Œè½¬æ¢ ===\n")
    
    processor = ComprehensiveQAProcessor()
    
    # å¤„ç†æ‰€æœ‰å¢å¼ºæ–‡ä»¶
    print("1. å¤„ç†æ‰€æœ‰å¢å¼ºçš„QAæ–‡ä»¶...")
    all_examples = processor.process_all_enhanced_files()
    
    if not all_examples:
        print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„å¢å¼ºQAæ•°æ®")
        return
    
    print(f"\nâœ… æ€»å…±å¤„ç†äº† {len(all_examples)} ä¸ªé—®é¢˜\n")
    
    # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
    print("2. ç”Ÿæˆç»¼åˆç»Ÿè®¡æŠ¥å‘Š...")
    report = processor.generate_comprehensive_report(all_examples)
    
    print("=== ç»¼åˆç»Ÿè®¡æŠ¥å‘Š ===")
    print(f"ğŸ“ˆ æ€»é—®é¢˜æ•°é‡: {report['total_examples']}")
    print(f"ğŸ“Š éš¾åº¦åˆ†å¸ƒ: {report['difficulty_distribution']}")
    print(f"ğŸ“ æ¥æºåˆ†å¸ƒ: {report['source_distribution']}")
    print(f"ğŸ“ thinkingé•¿åº¦ç»Ÿè®¡:")
    print(f"   - å¹³å‡: {report['thinking_length_stats']['average']:.0f} å­—ç¬¦")
    print(f"   - æœ€å°: {report['thinking_length_stats']['min']} å­—ç¬¦")
    print(f"   - æœ€å¤§: {report['thinking_length_stats']['max']} å­—ç¬¦")
    print(f"   - ä¸­ä½æ•°: {report['thinking_length_stats']['median']} å­—ç¬¦")
    
    print(f"\nğŸ”¤ é«˜é¢‘å¯†ç å­¦æœ¯è¯­ (Top 10):")
    for i, (term, count) in enumerate(list(report['crypto_term_frequency'].items())[:10], 1):
        print(f"   {i}. {term}: {count}æ¬¡")
    
    # ä¿å­˜è®­ç»ƒæ•°æ®
    print("\n3. è½¬æ¢å¹¶ä¿å­˜LLaMA Factoryè®­ç»ƒæ•°æ®...")
    processor.save_training_data(all_examples)
    
    # éªŒè¯è½¬æ¢ç»“æœ
    print("\n4. éªŒè¯è½¬æ¢ç»“æœ...")
    sample_example = all_examples[0]
    llama_format = sample_example.to_llama_factory_format()
    
    print("âœ… æ ·ä¾‹è½¬æ¢éªŒè¯:")
    print(f"   - Instructioné•¿åº¦: {len(llama_format['instruction'])} å­—ç¬¦")
    print(f"   - OutputåŒ…å«thinking: {'<thinking>' in llama_format['output']}")
    print(f"   - System promptè®¾ç½®: {'å¯†ç å­¦ä¸“å®¶' in llama_format['system']}")
    print(f"   - æ ¼å¼å®Œæ•´æ€§: {all(key in llama_format for key in ['instruction', 'input', 'output', 'system', 'history'])}")
    
    print(f"\nğŸ‰ æ•°æ®å¤„ç†å®Œæˆï¼")
    print(f"âœ… æˆåŠŸè½¬æ¢ {len(all_examples)} ä¸ªthinkingæ ·ä¾‹")
    print(f"âœ… æ•°æ®å·²ä¿å­˜åˆ° data/processed/ ç›®å½•")
    print(f"âœ… æ”¯æŒLLaMA Factoryç›´æ¥è®­ç»ƒ")

if __name__ == "__main__":
    main()
# Qwen3-4B-Thinking ä¸­æ–‡å¯†ç å­¦å¾®è°ƒç³»ç»Ÿ

ä¸“é—¨é’ˆå¯¹Qwen3-4B-Thinkingæ¨¡å‹çš„ä¸­æ–‡å¯†ç å­¦é¢†åŸŸå¾®è°ƒç³»ç»Ÿï¼Œæä¾›å®Œæ•´çš„è®­ç»ƒã€è¯„ä¼°å’Œéƒ¨ç½²è§£å†³æ–¹æ¡ˆã€‚

## ğŸ¯ æ ¸å¿ƒç‰¹æ€§

### æ¨¡å‹ä¸æ•°æ®
- ğŸš€ **ä¸“ä¸šæ¨¡å‹æ”¯æŒ**: é’ˆå¯¹Qwen/Qwen3-4B-Thinking-2507æ¨¡å‹æ·±åº¦ä¼˜åŒ–
- ğŸ§  **æ€è€ƒé“¾æ¨ç†**: å®Œæ•´æ”¯æŒ`<thinking>`æ ‡ç­¾çš„CoTæ¨ç†æ•°æ®æ ¼å¼
- ğŸ‡¨ğŸ‡³ **ä¸­æ–‡NLPä¼˜åŒ–**: ä¸“ä¸šä¸­æ–‡æ–‡æœ¬å¤„ç†ã€ç¹ç®€è½¬æ¢ã€å¯†ç å­¦æœ¯è¯­è¯†åˆ«
- ğŸ“š **å¯†ç å­¦ä¸“ä¸š**: å†…ç½®å¯†ç å­¦æœ¯è¯­åº“ã€ä¸“ä¸šQAæ•°æ®å¤„ç†

### è®­ç»ƒä¸ä¼˜åŒ–
- ğŸ’¾ **å†…å­˜é«˜æ•ˆ**: LoRAå¾®è°ƒã€4bit/8bité‡åŒ–ã€æ··åˆç²¾åº¦è®­ç»ƒã€æ¢¯åº¦æ£€æŸ¥ç‚¹
- ğŸ”„ **å¤šGPUå¹¶è¡Œ**: æ•°æ®å¹¶è¡Œã€æ¨¡å‹å¹¶è¡Œã€æµæ°´çº¿å¹¶è¡Œã€è‡ªåŠ¨ç­–ç•¥æ¨è
- âš¡ **æ€§èƒ½ä¼˜åŒ–**: æ™ºèƒ½æ‰¹æ¬¡è°ƒæ•´ã€å†…å­˜ç®¡ç†ã€OOMé¢„é˜²ã€NUMAä¼˜åŒ–
- ğŸ›ï¸ **è‡ªé€‚åº”é…ç½®**: ç¡¬ä»¶æ£€æµ‹ã€å‚æ•°è‡ªåŠ¨è°ƒä¼˜ã€å¹¶è¡Œç­–ç•¥æ¨è

### ç›‘æ§ä¸è¯„ä¼°
- ğŸ“Š **å®æ—¶ç›‘æ§**: TensorBoardé›†æˆã€è®­ç»ƒæŒ‡æ ‡è·Ÿè¸ªã€GPUåˆ©ç”¨ç‡ç›‘æ§
- ğŸ” **ä¸“å®¶è¯„ä¼°**: å¤šç»´åº¦æ¨¡å‹è¯„ä¼°ã€ä¸­æ–‡èƒ½åŠ›éªŒè¯ã€å¯†ç å­¦ä¸“ä¸šè¯„ä¼°
- ğŸ“ˆ **æ€§èƒ½åˆ†æ**: è®­ç»ƒæ•ˆç‡åˆ†æã€èµ„æºä½¿ç”¨ç»Ÿè®¡ã€å¼‚å¸¸æ£€æµ‹

### éƒ¨ç½²ä¸æœåŠ¡
- ğŸ“¦ **æ¨¡å‹å¯¼å‡º**: å¤šç§é‡åŒ–æ ¼å¼(FP16/INT8/INT4)ã€å®‰å…¨å¯¼å‡ºã€æ ¼å¼è½¬æ¢
- ğŸŒ **æœåŠ¡åŒ–éƒ¨ç½²**: REST APIã€æ¨¡å‹æœåŠ¡ã€Dockerå®¹å™¨åŒ–
- ğŸ”§ **å·¥å…·é“¾**: CLIå·¥å…·ã€æ‰¹å¤„ç†è„šæœ¬ã€è‡ªåŠ¨åŒ–æµæ°´çº¿

## ğŸ“‹ ç³»ç»Ÿè¦æ±‚

### åŸºç¡€ç¯å¢ƒ
- **Python**: 3.12+ (å¿…éœ€)
- **CUDA**: 12.9+ (GPUè®­ç»ƒæ¨è)
- **åŒ…ç®¡ç†å™¨**: uv (æ¨è) æˆ– pip

### ç¡¬ä»¶é…ç½®
| é…ç½®çº§åˆ« | GPUå†…å­˜ | ç³»ç»Ÿå†…å­˜ | æ¨èç”¨é€” |
|----------|---------|----------|----------|
| æœ€å°é…ç½® | 8GB | 16GB | åŸºç¡€è®­ç»ƒã€é‡åŒ–æ¨ç† |
| æ¨èé…ç½® | 16GB+ | 32GB+ | å®Œæ•´è®­ç»ƒã€å¤šGPUå¹¶è¡Œ |
| é«˜æ€§èƒ½é…ç½® | 24GB+ | 64GB+ | å¤§è§„æ¨¡è®­ç»ƒã€ä¸“ä¸šéƒ¨ç½² |

### æ”¯æŒçš„GPU
- NVIDIA RTX 30/40/50ç³»åˆ—
- NVIDIA Tesla/Quadroç³»åˆ—
- æ”¯æŒCUDAè®¡ç®—èƒ½åŠ›6.0+

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå®‰è£…

#### æ–¹å¼ä¸€ï¼šä½¿ç”¨uv (æ¨è)
```bash
# å®‰è£…uvåŒ…ç®¡ç†å™¨
# Windows (PowerShell)
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"

# macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh

# å…‹éš†é¡¹ç›®å¹¶å®‰è£…ä¾èµ–
git clone <repository-url>
cd qwen3-4b-thinking-finetuning
uv sync --extra dev
```

#### æ–¹å¼äºŒï¼šä½¿ç”¨pip
```bash
git clone <repository-url>
cd qwen3-4b-thinking-finetuning
pip install -e .
pip install -r requirements.txt
```

### 2. ç¯å¢ƒéªŒè¯

```bash
# å®Œæ•´ç¯å¢ƒè®¾ç½®
uv run python setup.py

# æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒå’ŒGPUçŠ¶æ€
uv run python scripts/check_environment.py

# éªŒè¯æ ¸å¿ƒåŠŸèƒ½
uv run python test_basic_setup.py
```

### 3. æ•°æ®å‡†å¤‡

#### æ•°æ®ç›®å½•ç»“æ„
```
data/
â”œâ”€â”€ raw/                    # åŸå§‹markdownæ–‡ä»¶ (*.md)
â”œâ”€â”€ train/                  # è®­ç»ƒæ•°æ® (*.json)
â”œâ”€â”€ eval/                   # éªŒè¯æ•°æ® (*.json)
â”œâ”€â”€ test/                   # æµ‹è¯•æ•°æ® (*.json)
â””â”€â”€ processed/              # å¤„ç†åçš„æ•°æ®
```

#### æ•°æ®æ ¼å¼ç¤ºä¾‹
```json
{
  "instruction": "è¯·è§£é‡ŠAESåŠ å¯†ç®—æ³•çš„å·¥ä½œåŸç†",
  "input": "",
  "output": "<thinking>éœ€è¦ä»AESçš„åŸºæœ¬æ¦‚å¿µå¼€å§‹...</thinking>AESæ˜¯ä¸€ç§å¯¹ç§°åŠ å¯†ç®—æ³•..."
}
```

### 4. å¿«é€Ÿæ¼”ç¤º

```bash
# è¿è¡Œå¿«é€Ÿæ¼”ç¤º (æ¨èæ–°æ‰‹)
uv run python run_demo.py

# è¿è¡Œå®Œæ•´æ¼”ç¤º
uv run python demo_final.py

# è¿è¡Œç®€åŒ–è®­ç»ƒæ¼”ç¤º
uv run python demo_simple_finetuning.py
```

### 5. å¼€å§‹è®­ç»ƒ

#### å•GPUè®­ç»ƒ
```bash
# ä½¿ç”¨é»˜è®¤é…ç½®
uv run python scripts/train.py

# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
uv run python scripts/train.py --config configs/custom_config.yaml
```

#### å¤šGPUè®­ç»ƒ
```bash
# 2ä¸ªGPUæ•°æ®å¹¶è¡Œ
uv run torchrun --nproc_per_node=2 scripts/train.py

# åˆ†å¸ƒå¼è®­ç»ƒ
uv run python run_training_true_distributed.py
```

#### é«˜çº§è®­ç»ƒé€‰é¡¹
```bash
# ä¼˜åŒ–çš„å•GPUè®­ç»ƒ
uv run python run_training_optimized_single.py

# å†…å­˜ä¼˜åŒ–è®­ç»ƒ
uv run python run_training_minimal.py

# æ€§èƒ½åŸºå‡†æµ‹è¯•
uv run python run_performance_optimization_validation.py
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
qwen3-4b-thinking-finetuning/
â”œâ”€â”€ src/                           # ğŸ”§ æ ¸å¿ƒåŠŸèƒ½æ¨¡å—
â”‚   â”œâ”€â”€ training_pipeline.py      # è®­ç»ƒæµæ°´çº¿ç®¡ç†
â”‚   â”œâ”€â”€ distributed_training_engine.py # åˆ†å¸ƒå¼è®­ç»ƒå¼•æ“
â”‚   â”œâ”€â”€ model_exporter.py         # æ¨¡å‹å¯¼å‡ºå’Œé‡åŒ–
â”‚   â”œâ”€â”€ expert_evaluation/         # ä¸“å®¶è¯„ä¼°ç³»ç»Ÿ
â”‚   â”œâ”€â”€ chinese_nlp_processor.py  # ä¸­æ–‡NLPå¤„ç†
â”‚   â”œâ”€â”€ crypto_term_processor.py  # å¯†ç å­¦æœ¯è¯­å¤„ç†
â”‚   â”œâ”€â”€ thinking_generator.py     # æ€è€ƒé“¾æ•°æ®ç”Ÿæˆ
â”‚   â”œâ”€â”€ performance_optimizer.py  # æ€§èƒ½ä¼˜åŒ–å™¨
â”‚   â”œâ”€â”€ memory_manager.py         # å†…å­˜ç®¡ç†
â”‚   â”œâ”€â”€ gpu_utils.py              # GPUæ£€æµ‹å’Œç®¡ç†
â”‚   â”œâ”€â”€ parallel_strategy_recommender.py # å¹¶è¡Œç­–ç•¥æ¨è
â”‚   â””â”€â”€ ...                       # å…¶ä»–æ ¸å¿ƒæ¨¡å—
â”œâ”€â”€ scripts/                       # ğŸš€ æ‰§è¡Œè„šæœ¬
â”‚   â”œâ”€â”€ train.py                  # ä¸»è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ check_environment.py      # ç¯å¢ƒæ£€æŸ¥
â”‚   â”œâ”€â”€ deploy_service.py         # éƒ¨ç½²æœåŠ¡
â”‚   â””â”€â”€ validate_service.py       # æœåŠ¡éªŒè¯
â”œâ”€â”€ examples/                      # ğŸ“š ç¤ºä¾‹å’Œæ¼”ç¤º
â”‚   â”œâ”€â”€ expert_evaluation_demo.py # ä¸“å®¶è¯„ä¼°æ¼”ç¤º
â”‚   â”œâ”€â”€ chinese_nlp_demo.py       # ä¸­æ–‡NLPæ¼”ç¤º
â”‚   â”œâ”€â”€ crypto_term_demo.py       # å¯†ç å­¦æœ¯è¯­æ¼”ç¤º
â”‚   â”œâ”€â”€ thinking_generator_demo.py # æ€è€ƒé“¾ç”Ÿæˆæ¼”ç¤º
â”‚   â”œâ”€â”€ model_export_deployment_demo.py # æ¨¡å‹å¯¼å‡ºéƒ¨ç½²æ¼”ç¤º
â”‚   â””â”€â”€ ...                       # å…¶ä»–æ¼”ç¤ºç¨‹åº
â”œâ”€â”€ configs/                       # âš™ï¸ é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ config.yaml               # ä¸»é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ cryptography_evaluation.yaml # å¯†ç å­¦è¯„ä¼°é…ç½®
â”œâ”€â”€ data/                          # ğŸ“Š æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ raw/                      # åŸå§‹markdownæ–‡ä»¶
â”‚   â”œâ”€â”€ train/                    # è®­ç»ƒæ•°æ®
â”‚   â”œâ”€â”€ eval/                     # éªŒè¯æ•°æ®
â”‚   â”œâ”€â”€ test/                     # æµ‹è¯•æ•°æ®
â”‚   â””â”€â”€ processed/                # å¤„ç†åçš„æ•°æ®
â”œâ”€â”€ tests/                         # ğŸ§ª æµ‹è¯•å¥—ä»¶
â”‚   â”œâ”€â”€ integration/              # é›†æˆæµ‹è¯•
â”‚   â”œâ”€â”€ expert_evaluation/        # ä¸“å®¶è¯„ä¼°æµ‹è¯•
â”‚   â””â”€â”€ ...                       # å•å…ƒæµ‹è¯•
â”œâ”€â”€ docs/                          # ğŸ“– æ–‡æ¡£
â”‚   â”œâ”€â”€ deployment_guide.md       # éƒ¨ç½²æŒ‡å—
â”‚   â”œâ”€â”€ expert_evaluation_architecture.md # ä¸“å®¶è¯„ä¼°æ¶æ„
â”‚   â”œâ”€â”€ troubleshooting_guide.md  # æ•…éšœæ’é™¤æŒ‡å—
â”‚   â””â”€â”€ ...                       # å…¶ä»–æ–‡æ¡£
â”œâ”€â”€ monitoring/                    # ğŸ“ˆ ç›‘æ§é…ç½®
â”‚   â”œâ”€â”€ prometheus.yml            # Prometheusé…ç½®
â”‚   â”œâ”€â”€ grafana/                  # Grafanaä»ªè¡¨æ¿
â”‚   â””â”€â”€ alerts.yml                # å‘Šè­¦è§„åˆ™
â”œâ”€â”€ output/                        # ğŸ“¤ è®­ç»ƒè¾“å‡º
â”œâ”€â”€ logs/                          # ğŸ“ æ—¥å¿—æ–‡ä»¶
â”œâ”€â”€ cache/                         # ğŸ’¾ ç¼“å­˜ç›®å½•
â”œâ”€â”€ models/                        # ğŸ¤– æ¨¡å‹æ–‡ä»¶
â””â”€â”€ checkpoints/                   # ğŸ’¾ è®­ç»ƒæ£€æŸ¥ç‚¹
```

## âš™ï¸ é…ç½®è¯´æ˜

### æ¨¡å‹é…ç½® (`model`)
```yaml
model:
  model_name: "Qwen/Qwen3-4B-Thinking-2507"  # æ¨¡å‹åç§°
  load_in_4bit: false          # 4bité‡åŒ–åŠ è½½
  load_in_8bit: false          # 8bité‡åŒ–åŠ è½½
  torch_dtype: "auto"          # æ•°æ®ç±»å‹ (auto/float16/bfloat16)
  device_map: "auto"           # è®¾å¤‡æ˜ å°„ç­–ç•¥
  max_seq_length: 2048         # æœ€å¤§åºåˆ—é•¿åº¦
  trust_remote_code: true      # ä¿¡ä»»è¿œç¨‹ä»£ç 
```

### LoRAå¾®è°ƒé…ç½® (`lora`)
```yaml
lora:
  r: 16                        # LoRA rank (8-64)
  lora_alpha: 32              # LoRAç¼©æ”¾å‚æ•°
  lora_dropout: 0.1           # Dropoutç‡
  target_modules:             # ç›®æ ‡æ¨¡å—
    - "q_proj"
    - "k_proj" 
    - "v_proj"
    - "o_proj"
  use_rslora: false           # ä½¿ç”¨RSLoRA
  use_dora: false             # ä½¿ç”¨DoRA
```

### è®­ç»ƒé…ç½® (`training`)
```yaml
training:
  num_train_epochs: 3                    # è®­ç»ƒè½®æ•°
  per_device_train_batch_size: 1         # æ¯è®¾å¤‡æ‰¹æ¬¡å¤§å°
  gradient_accumulation_steps: 4         # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
  learning_rate: 2e-4                    # å­¦ä¹ ç‡
  lr_scheduler_type: "cosine"            # å­¦ä¹ ç‡è°ƒåº¦å™¨
  warmup_ratio: 0.1                      # é¢„çƒ­æ¯”ä¾‹
  weight_decay: 0.01                     # æƒé‡è¡°å‡
  gradient_checkpointing: true           # æ¢¯åº¦æ£€æŸ¥ç‚¹
  bf16: true                             # BF16æ··åˆç²¾åº¦
  dataloader_num_workers: 4              # æ•°æ®åŠ è½½å™¨å·¥ä½œè¿›ç¨‹
```

### å¤šGPUå¹¶è¡Œé…ç½® (`multigpu`)
```yaml
multigpu:
  enable_distributed: false              # å¯ç”¨åˆ†å¸ƒå¼è®­ç»ƒ
  world_size: 1                         # æ€»è¿›ç¨‹æ•°
  backend: "nccl"                       # é€šä¿¡åç«¯ (nccl/gloo)
  data_parallel: true                   # æ•°æ®å¹¶è¡Œ
  model_parallel: false                 # æ¨¡å‹å¹¶è¡Œ
  pipeline_parallel: false              # æµæ°´çº¿å¹¶è¡Œ
  zero_stage: 2                         # ZeROä¼˜åŒ–é˜¶æ®µ
```

### ä¸­æ–‡å¤„ç†é…ç½® (`chinese`)
```yaml
chinese:
  tokenizer_name: "Qwen/Qwen3-4B-Thinking-2507"
  add_special_tokens: true              # æ·»åŠ ç‰¹æ®Štoken
  preserve_thinking_structure: true     # ä¿ç•™thinkingç»“æ„
  thinking_start_token: "<thinking>"    # thinkingå¼€å§‹token
  thinking_end_token: "</thinking>"     # thinkingç»“æŸtoken
  enable_traditional_conversion: true   # å¯ç”¨ç¹ç®€è½¬æ¢
  normalize_punctuation: true           # æ ‡å‡†åŒ–æ ‡ç‚¹ç¬¦å·
```

### æ•°æ®å¤„ç†é…ç½® (`data`)
```yaml
data:
  train_data_path: "./data/train"       # è®­ç»ƒæ•°æ®è·¯å¾„
  eval_data_path: "./data/eval"         # éªŒè¯æ•°æ®è·¯å¾„
  test_data_path: "./data/test"         # æµ‹è¯•æ•°æ®è·¯å¾„
  data_format: "json"                   # æ•°æ®æ ¼å¼
  preserve_thinking_tags: true          # ä¿ç•™thinkingæ ‡ç­¾
  enable_chinese_preprocessing: true    # å¯ç”¨ä¸­æ–‡é¢„å¤„ç†
  preserve_crypto_terms: true           # ä¿ç•™å¯†ç å­¦æœ¯è¯­
```

## ğŸ“Š æ•°æ®æ ¼å¼ä¸å¤„ç†

### æ”¯æŒçš„æ•°æ®æ ¼å¼

#### 1. æ ‡å‡†QAæ ¼å¼
```json
{
  "instruction": "è¯·è§£é‡ŠAESåŠ å¯†ç®—æ³•çš„å·¥ä½œåŸç†",
  "input": "",
  "output": "AESï¼ˆé«˜çº§åŠ å¯†æ ‡å‡†ï¼‰æ˜¯ä¸€ç§å¯¹ç§°åŠ å¯†ç®—æ³•ï¼Œé‡‡ç”¨åˆ†ç»„å¯†ç ä½“åˆ¶..."
}
```

#### 2. æ€è€ƒé“¾æ ¼å¼ (CoT)
```json
{
  "instruction": "åˆ†æRSAç®—æ³•çš„å®‰å…¨æ€§",
  "input": "",
  "output": "<thinking>é¦–å…ˆéœ€è¦è€ƒè™‘RSAç®—æ³•çš„æ•°å­¦åŸºç¡€ï¼š1. å¤§æ•´æ•°åˆ†è§£å›°éš¾æ€§ 2. æ¬§æ‹‰å‡½æ•°æ€§è´¨ 3. æ¨¡è¿ç®—ç‰¹æ€§...</thinking>RSAç®—æ³•çš„å®‰å…¨æ€§ä¸»è¦åŸºäºå¤§æ•´æ•°åˆ†è§£çš„æ•°å­¦éš¾é¢˜..."
}
```

#### 3. å¤šè½®å¯¹è¯æ ¼å¼
```json
{
  "conversations": [
    {"from": "human", "value": "ä»€ä¹ˆæ˜¯å¯¹ç§°åŠ å¯†ï¼Ÿ"},
    {"from": "gpt", "value": "<thinking>ç”¨æˆ·è¯¢é—®å¯¹ç§°åŠ å¯†çš„åŸºæœ¬æ¦‚å¿µ...</thinking>å¯¹ç§°åŠ å¯†æ˜¯æŒ‡åŠ å¯†å’Œè§£å¯†ä½¿ç”¨ç›¸åŒå¯†é’¥çš„åŠ å¯†æ–¹å¼..."},
    {"from": "human", "value": "èƒ½ä¸¾ä¸ªä¾‹å­å—ï¼Ÿ"},
    {"from": "gpt", "value": "å½“ç„¶å¯ä»¥ã€‚AESå°±æ˜¯ä¸€ä¸ªå…¸å‹çš„å¯¹ç§°åŠ å¯†ç®—æ³•..."}
  ]
}
```

### æ•°æ®å¤„ç†åŠŸèƒ½

#### ä¸­æ–‡æ–‡æœ¬å¤„ç†
- **ç¹ç®€è½¬æ¢**: è‡ªåŠ¨è¯†åˆ«å¹¶è½¬æ¢ç¹ä½“ä¸­æ–‡
- **æ ‡ç‚¹æ ‡å‡†åŒ–**: ç»Ÿä¸€ä¸­è‹±æ–‡æ ‡ç‚¹ç¬¦å·
- **åˆ†è¯ä¼˜åŒ–**: é’ˆå¯¹å¯†ç å­¦æœ¯è¯­çš„ä¸“ä¸šåˆ†è¯
- **ç¼–ç å¤„ç†**: UTF-8ç¼–ç ç¡®ä¿å’Œemojiå¤„ç†

#### å¯†ç å­¦ä¸“ä¸šå¤„ç†
- **æœ¯è¯­è¯†åˆ«**: å†…ç½®å¯†ç å­¦æœ¯è¯­åº“ï¼Œä¿æŠ¤ä¸“ä¸šè¯æ±‡
- **æ¦‚å¿µæ ‡æ³¨**: è‡ªåŠ¨æ ‡æ³¨å¯†ç å­¦æ¦‚å¿µå’Œç®—æ³•åç§°
- **éš¾åº¦åˆ†çº§**: æ ¹æ®å†…å®¹å¤æ‚åº¦è‡ªåŠ¨åˆ†çº§
- **è´¨é‡éªŒè¯**: æ£€æŸ¥QAå¯¹çš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§

#### æ€è€ƒé“¾å¤„ç†
- **ç»“æ„éªŒè¯**: æ£€æŸ¥`<thinking>`æ ‡ç­¾çš„å®Œæ•´æ€§
- **å†…å®¹åˆ†æ**: åˆ†ææ€è€ƒè¿‡ç¨‹çš„é€»è¾‘æ€§
- **é•¿åº¦ä¼˜åŒ–**: è‡ªåŠ¨è°ƒæ•´æ€è€ƒé“¾é•¿åº¦
- **æ ¼å¼æ ‡å‡†åŒ–**: ç»Ÿä¸€æ€è€ƒé“¾æ ¼å¼

## ğŸš€ æ€§èƒ½ä¼˜åŒ–æŒ‡å—

### GPUå†…å­˜ä¼˜åŒ–ç­–ç•¥

| GPUå†…å­˜ | é‡åŒ–è®¾ç½® | æ‰¹æ¬¡å¤§å° | æ¢¯åº¦ç´¯ç§¯ | åºåˆ—é•¿åº¦ | é¢„æœŸæ€§èƒ½ |
|---------|----------|----------|----------|----------|----------|
| 8GB | 4bité‡åŒ– | 1 | 8 | 1024 | åŸºç¡€è®­ç»ƒ |
| 12GB | 8bité‡åŒ– | 1 | 4 | 1536 | æ ‡å‡†è®­ç»ƒ |
| 16GB | FP16 | 2 | 4 | 2048 | é«˜æ•ˆè®­ç»ƒ |
| 24GB+ | BF16 | 4 | 2 | 2048 | æœ€ä½³æ€§èƒ½ |

### è‡ªåŠ¨ä¼˜åŒ–é…ç½®

#### ä½¿ç”¨æ€§èƒ½ä¼˜åŒ–å™¨
```python
from src.performance_optimizer import PerformanceOptimizer

optimizer = PerformanceOptimizer()
config = optimizer.optimize_for_hardware()
print(f"æ¨èé…ç½®: {config}")
```

#### å¹¶è¡Œç­–ç•¥æ¨è
```python
from src.parallel_strategy_recommender import ParallelStrategyRecommender

recommender = ParallelStrategyRecommender()
strategy = recommender.recommend_strategy(
    num_gpus=2,
    gpu_memory_gb=16,
    model_size="4B"
)
```

### å†…å­˜ç®¡ç†

#### OOMé¢„é˜²
```bash
# å¯ç”¨OOMç®¡ç†å™¨
uv run python src/oom_manager.py --monitor

# å†…å­˜ä½¿ç”¨åˆ†æ
uv run python src/memory_manager.py --analyze
```

#### NUMAä¼˜åŒ–
```bash
# NUMAæ£€æµ‹å’Œä¼˜åŒ–
uv run python test_numa_detection.py

# æŸ¥çœ‹NUMAä¼˜åŒ–æŠ¥å‘Š
cat numa_solution_report.md
```

### è®­ç»ƒåŠ é€ŸæŠ€å·§

#### 1. æ¢¯åº¦æ£€æŸ¥ç‚¹
```yaml
training:
  gradient_checkpointing: true  # å‡å°‘å†…å­˜ä½¿ç”¨
  dataloader_num_workers: 4     # å¹¶è¡Œæ•°æ®åŠ è½½
  dataloader_pin_memory: true   # å›ºå®šå†…å­˜
```

#### 2. æ··åˆç²¾åº¦è®­ç»ƒ
```yaml
training:
  bf16: true                    # BF16ç²¾åº¦ (æ¨è)
  fp16: false                   # FP16ç²¾åº¦ (å¤‡é€‰)
```

#### 3. ä¼˜åŒ–å™¨è®¾ç½®
```yaml
training:
  optim: "adamw_torch"          # ä¼˜åŒ–å™¨é€‰æ‹©
  adam_beta1: 0.9               # Adamå‚æ•°
  adam_beta2: 0.999
  weight_decay: 0.01            # æƒé‡è¡°å‡
```

## ğŸ“Š ç›‘æ§ä¸è¯„ä¼°ç³»ç»Ÿ

### å®æ—¶è®­ç»ƒç›‘æ§

#### TensorBoardé›†æˆ
```bash
# å¯åŠ¨TensorBoard
tensorboard --logdir logs/ --port 6006

# æŸ¥çœ‹è®­ç»ƒæŒ‡æ ‡
# - è®­ç»ƒ/éªŒè¯æŸå¤±
# - å­¦ä¹ ç‡å˜åŒ–
# - GPUåˆ©ç”¨ç‡
# - å†…å­˜ä½¿ç”¨æƒ…å†µ
```

#### è®­ç»ƒç›‘æ§å™¨
```python
from src.training_monitor import TrainingMonitor

monitor = TrainingMonitor()
monitor.start_monitoring()
# è‡ªåŠ¨è®°å½•è®­ç»ƒæŒ‡æ ‡ã€GPUçŠ¶æ€ã€å†…å­˜ä½¿ç”¨
```

### ä¸“å®¶è¯„ä¼°ç³»ç»Ÿ

#### åŸºç¡€è¯„ä¼°
```bash
# è¿è¡ŒåŸºç¡€è¯„ä¼°
uv run python examples/expert_evaluation_basic_usage.py

# é«˜çº§è¯„ä¼°åœºæ™¯
uv run python examples/expert_evaluation_advanced_scenarios.py

# æ€§èƒ½åŸºå‡†æµ‹è¯•
uv run python examples/expert_evaluation_performance_benchmark.py
```

#### ä¸­æ–‡èƒ½åŠ›éªŒè¯
```bash
# ä¸­æ–‡NLPèƒ½åŠ›æµ‹è¯•
uv run python examples/chinese_capability_validation_demo.py

# ä¸­æ–‡æŒ‡æ ‡è®¡ç®—
uv run python examples/chinese_nlp_demo.py
```

#### å¯†ç å­¦ä¸“ä¸šè¯„ä¼°
```bash
# å¯†ç å­¦æœ¯è¯­æµ‹è¯•
uv run python examples/crypto_term_demo.py

# é«˜çº§å¯†ç å­¦è¯„ä¼°
uv run python examples/advanced_crypto_demo.py
```

### è¯„ä¼°æŒ‡æ ‡

#### é€šç”¨æŒ‡æ ‡
- **å›°æƒ‘åº¦ (Perplexity)**: æ¨¡å‹é¢„æµ‹èƒ½åŠ›
- **BLEUåˆ†æ•°**: æ–‡æœ¬ç”Ÿæˆè´¨é‡
- **ROUGEåˆ†æ•°**: æ‘˜è¦è´¨é‡è¯„ä¼°
- **å‡†ç¡®ç‡**: åˆ†ç±»ä»»åŠ¡å‡†ç¡®æ€§

#### ä¸­æ–‡ä¸“é¡¹æŒ‡æ ‡
- **ä¸­æ–‡BLEU**: é’ˆå¯¹ä¸­æ–‡ä¼˜åŒ–çš„BLEU
- **å­—ç¬¦çº§å‡†ç¡®ç‡**: ä¸­æ–‡å­—ç¬¦é¢„æµ‹å‡†ç¡®æ€§
- **è¯æ±‡è¦†ç›–ç‡**: ä¸­æ–‡è¯æ±‡è¯†åˆ«èƒ½åŠ›
- **è¯­æ³•æ­£ç¡®æ€§**: ä¸­æ–‡è¯­æ³•ç»“æ„è¯„ä¼°

#### å¯†ç å­¦ä¸“é¡¹æŒ‡æ ‡
- **æœ¯è¯­å‡†ç¡®ç‡**: å¯†ç å­¦æœ¯è¯­ä½¿ç”¨å‡†ç¡®æ€§
- **æ¦‚å¿µç†è§£åº¦**: å¯†ç å­¦æ¦‚å¿µæŒæ¡ç¨‹åº¦
- **æ¨ç†é€»è¾‘æ€§**: å¯†ç å­¦æ¨ç†è¿‡ç¨‹è¯„ä¼°
- **ä¸“ä¸šæ·±åº¦**: å›ç­”çš„ä¸“ä¸šç¨‹åº¦è¯„åˆ†

### ç›‘æ§å·¥å…·

#### ç³»ç»Ÿç›‘æ§
```bash
# GPUçŠ¶æ€ç›‘æ§
nvidia-smi -l 1

# ç³»ç»Ÿèµ„æºç›‘æ§
uv run python src/system_config.py --monitor

# åˆ†å¸ƒå¼æŒ‡æ ‡æ”¶é›†
uv run python src/distributed_metrics_collector.py
```

#### å¼‚å¸¸æ£€æµ‹
```bash
# è®­ç»ƒå¼‚å¸¸æ£€æµ‹
uv run python src/anomaly_detector.py

# æ€§èƒ½å¼‚å¸¸åˆ†æ
uv run python tests/test_performance_benchmarks.py
```

## ğŸ“¦ æ¨¡å‹å¯¼å‡ºä¸éƒ¨ç½²

### æ¨¡å‹å¯¼å‡ºåŠŸèƒ½

#### æ”¯æŒçš„å¯¼å‡ºæ ¼å¼
```bash
# FP16å¯¼å‡º (æ¨è)
uv run python src/model_exporter.py --format fp16 --input checkpoints/best_model

# INT8é‡åŒ–å¯¼å‡º
uv run python src/model_exporter.py --format int8 --input checkpoints/best_model

# INT4é‡åŒ–å¯¼å‡º (æœ€å°ä½“ç§¯)
uv run python src/model_exporter.py --format int4 --input checkpoints/best_model

# å®‰å…¨å¯¼å‡º (åŒ…å«éªŒè¯)
uv run python src/model_exporter.py --format safe --input checkpoints/best_model
```

#### å¯¼å‡ºæ¼”ç¤º
```bash
# å®Œæ•´å¯¼å‡ºæ¼”ç¤º
uv run python examples/model_export_deployment_demo.py

# å®ç”¨å¯¼å‡ºæ¼”ç¤º
uv run python practical_model_export_demo.py
```

### æ¨¡å‹æœåŠ¡åŒ–

#### å¯åŠ¨æ¨¡å‹æœåŠ¡
```bash
# å¯åŠ¨REST APIæœåŠ¡
uv run python start_model_service.py --model path/to/exported/model

# ä½¿ç”¨Dockeréƒ¨ç½²
docker-compose up -d

# éªŒè¯æœåŠ¡çŠ¶æ€
uv run python scripts/validate_service.py
```

#### APIä½¿ç”¨ç¤ºä¾‹
```python
import requests

# åŸºç¡€æ¨ç†
response = requests.post("http://localhost:8000/generate", json={
    "prompt": "è¯·è§£é‡ŠAESåŠ å¯†ç®—æ³•",
    "max_length": 200,
    "temperature": 0.7
})

# æ€è€ƒé“¾æ¨ç†
response = requests.post("http://localhost:8000/thinking", json={
    "prompt": "åˆ†æRSAç®—æ³•çš„å®‰å…¨æ€§",
    "enable_thinking": True
})
```

### éƒ¨ç½²é…ç½®

#### Dockeréƒ¨ç½²
```dockerfile
# æŸ¥çœ‹ Dockerfile äº†è§£å®¹å™¨é…ç½®
# æ”¯æŒGPUåŠ é€Ÿå’Œå¤šç§éƒ¨ç½²æ¨¡å¼
```

#### ç›‘æ§é…ç½®
```bash
# Prometheusç›‘æ§
cat monitoring/prometheus.yml

# Grafanaä»ªè¡¨æ¿
ls monitoring/grafana/

# å‘Šè­¦è§„åˆ™
cat monitoring/alerts.yml
```

## ğŸ› ï¸ å¼€å‘å·¥å…·ä¸å·¥ä½œæµ

### uvåŒ…ç®¡ç†å™¨

#### åŸºç¡€å‘½ä»¤
```bash
# åŒæ­¥ä¾èµ–
uv sync --extra dev

# å®‰è£…æ–°åŒ…
uv add <package>

# ç§»é™¤åŒ…
uv remove <package>

# æŸ¥çœ‹ä¾èµ–æ ‘
uv tree

# è¿è¡Œè„šæœ¬
uv run python <script.py>

# è¿è¡Œæµ‹è¯•
uv run pytest
```

#### å¼€å‘å·¥ä½œæµ
```bash
# 1. ç¯å¢ƒè®¾ç½®
uv sync --extra dev
uv run python setup_with_uv.py

# 2. ä»£ç è´¨é‡æ£€æŸ¥
uv run black src/          # ä»£ç æ ¼å¼åŒ–
uv run isort src/          # å¯¼å…¥æ’åº
uv run flake8 src/         # ä»£ç æ£€æŸ¥

# 3. æµ‹è¯•æ‰§è¡Œ
uv run pytest tests/       # å•å…ƒæµ‹è¯•
uv run python run_integration_tests.py  # é›†æˆæµ‹è¯•

# 4. æ€§èƒ½éªŒè¯
uv run python run_performance_optimization_validation.py
```

### CLIå·¥å…·

#### ç®€åŒ–CLIå·¥å…·
```bash
# ä½¿ç”¨ç®€åŒ–CLI
uv run python src/cli_tools_simple.py --help

# å®Œæ•´CLIåŠŸèƒ½
uv run python src/cli_tools.py --help
```

#### æ‰¹å¤„ç†è„šæœ¬
```bash
# æ•°æ®å¤„ç†æ‰¹å¤„ç†
uv run python convert_all_enhanced_data.py

# è®­ç»ƒæ•°æ®éªŒè¯
uv run python validate_training_data.py

# æœ€ç»ˆæ•°æ®è´¨é‡æµ‹è¯•
uv run python final_data_quality_test.py
```

## ğŸ”§ æ•…éšœæ’é™¤æŒ‡å—

### ç¯å¢ƒé—®é¢˜

#### uvåŒ…ç®¡ç†å™¨é—®é¢˜
```bash
# é‡æ–°åŒæ­¥ä¾èµ–
uv sync --extra dev --reinstall

# æ¸…ç†ç¼“å­˜
uv cache clean

# æ£€æŸ¥uvç‰ˆæœ¬
uv --version

# éªŒè¯Pythonç¯å¢ƒ
uv run python --version
uv run python -c "import torch; print(torch.__version__)"
```

#### CUDAç¯å¢ƒé—®é¢˜
```bash
# æ£€æŸ¥CUDAå®‰è£…
nvidia-smi
nvcc --version

# éªŒè¯PyTorch CUDAæ”¯æŒ
uv run python -c "import torch; print(torch.cuda.is_available())"

# GPUæ£€æµ‹æµ‹è¯•
uv run python test_gpu_detection.py
```

### è®­ç»ƒé—®é¢˜

#### å†…å­˜ä¸è¶³ (OOM)
```bash
# å¯ç”¨OOMç®¡ç†å™¨
uv run python src/oom_manager.py --prevent

# å†…å­˜ä¼˜åŒ–å»ºè®®
uv run python src/memory_manager.py --optimize

# æ£€æŸ¥å†…å­˜ä½¿ç”¨
uv run python test_memory_usage.py
```

**è§£å†³æ–¹æ¡ˆ**:
- å‡å° `per_device_train_batch_size`
- å¢åŠ  `gradient_accumulation_steps`
- å¯ç”¨ `gradient_checkpointing: true`
- ä½¿ç”¨é‡åŒ–: `load_in_4bit: true`

#### è®­ç»ƒé€Ÿåº¦æ…¢
```bash
# æ€§èƒ½åˆ†æ
uv run python src/performance_optimizer.py --analyze

# å¹¶è¡Œç­–ç•¥ä¼˜åŒ–
uv run python src/parallel_strategy_recommender.py --recommend
```

**ä¼˜åŒ–å»ºè®®**:
- å¯ç”¨æ··åˆç²¾åº¦: `bf16: true`
- å¢åŠ  `dataloader_num_workers`
- ä½¿ç”¨å¤šGPUå¹¶è¡Œè®­ç»ƒ
- ä¼˜åŒ–æ•°æ®é¢„å¤„ç†

#### åˆ†å¸ƒå¼è®­ç»ƒé—®é¢˜
```bash
# åˆ†å¸ƒå¼è®­ç»ƒæµ‹è¯•
uv run python test_distributed_training.py

# æ£€æŸ¥ç½‘ç»œé…ç½®
uv run python src/distributed_training_engine.py --check
```

### æ•°æ®é—®é¢˜

#### ä¸­æ–‡ç¼–ç é—®é¢˜
```bash
# ä¸­æ–‡å¤„ç†æµ‹è¯•
uv run python examples/chinese_nlp_demo.py

# ç¼–ç éªŒè¯
uv run python test_enhanced_data.py
```

**è§£å†³æ–¹æ¡ˆ**:
- ç¡®ä¿æ–‡ä»¶ä½¿ç”¨UTF-8ç¼–ç 
- æ£€æŸ¥ `chinese.normalize_punctuation: true`
- éªŒè¯tokenizeré…ç½®

#### æ•°æ®æ ¼å¼é—®é¢˜
```bash
# æ•°æ®éªŒè¯
uv run python validate_training_data.py

# æ ¼å¼æ£€æŸ¥
uv run python test_json_serialization_fix.py
```

### æ¨¡å‹é—®é¢˜

#### æ¨¡å‹åŠ è½½å¤±è´¥
```bash
# æ¨¡å‹æµ‹è¯•
uv run python test_qwen3_4b_thinking.py

# ç½‘ç»œè¿æ¥æµ‹è¯•
uv run python test_api_import.py
```

**è§£å†³æ–¹æ¡ˆ**:
- æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œä»£ç†è®¾ç½®
- éªŒè¯æ¨¡å‹åç§°: `Qwen/Qwen3-4B-Thinking-2507`
- æ¸…ç†ç¼“å­˜: `rm -rf cache/`
- è®¾ç½® `local_files_only: false`

#### é‡åŒ–é—®é¢˜
```bash
# é‡åŒ–æµ‹è¯•
uv run python fixed_quantization_final.py

# æŸ¥çœ‹é‡åŒ–ä¿®å¤æŠ¥å‘Š
cat QUANTIZATION_FIX_SUMMARY.md
```

### ç³»ç»Ÿé—®é¢˜

#### NUMAä¼˜åŒ–
```bash
# NUMAæ£€æµ‹
uv run python test_numa_detection.py

# æŸ¥çœ‹ä¼˜åŒ–å»ºè®®
cat numa_solution_report.md
```

#### ä¾èµ–å†²çª
```bash
# ä¾èµ–æ£€æŸ¥
uv run python test_basic_setup.py

# ç¯å¢ƒéªŒè¯
uv run python comprehensive_validation.py
```

### è°ƒè¯•å·¥å…·

#### æ—¥å¿—åˆ†æ
```bash
# æŸ¥çœ‹è®¾ç½®æ—¥å¿—
cat logs/setup.log

# è®­ç»ƒæ—¥å¿—
tail -f logs/train.log

# é”™è¯¯æ—¥å¿—
grep -i error logs/*.log
```

#### æµ‹è¯•å¥—ä»¶
```bash
# åŸºç¡€åŠŸèƒ½æµ‹è¯•
uv run python test_minimal_api.py

# é›†æˆæµ‹è¯•
uv run python run_integration_tests.py

# æ€§èƒ½æµ‹è¯•
uv run python run_performance_optimization_validation.py
```

### è·å–å¸®åŠ©

#### è‡ªåŠ¨è¯Šæ–­
```bash
# ç¯å¢ƒæ£€æŸ¥
uv run python scripts/check_environment.py

# ç³»ç»ŸéªŒè¯
uv run python comprehensive_validation_sync.py

# é—®é¢˜æŠ¥å‘Šç”Ÿæˆ
uv run python generate_issue_report.py  # (å¦‚æœå­˜åœ¨)
```

#### æ–‡æ¡£èµ„æº
- ğŸ“– [æ•…éšœæ’é™¤æŒ‡å—](docs/troubleshooting_guide.md)
- ğŸ“– [ä¸“å®¶è¯„ä¼°æ•…éšœæ’é™¤](docs/expert_evaluation_troubleshooting.md)
- ğŸ“– [éƒ¨ç½²æŒ‡å—](docs/deployment_guide.md)
- ğŸ“– [ç”¨æˆ·æ‰‹å†Œ](docs/user_manual.md)

## ğŸ“š ç¤ºä¾‹ä¸æ¼”ç¤º

### å¿«é€Ÿæ¼”ç¤ºç¨‹åº
```bash
# ğŸš€ å¿«é€Ÿå…¥é—¨æ¼”ç¤º
uv run python run_demo.py

# ğŸ¯ å®Œæ•´åŠŸèƒ½æ¼”ç¤º  
uv run python demo_final.py

# ğŸ”§ ç®€åŒ–è®­ç»ƒæ¼”ç¤º
uv run python demo_simple_finetuning.py

# ğŸ“Š ç»¼åˆé›†æˆæµ‹è¯•
uv run python comprehensive_integration_test.py
```

### ä¸“ä¸šåŠŸèƒ½æ¼”ç¤º
```bash
# ğŸ§  ä¸“å®¶è¯„ä¼°ç³»ç»Ÿ
uv run python examples/expert_evaluation_demo.py

# ğŸ‡¨ğŸ‡³ ä¸­æ–‡NLPå¤„ç†
uv run python examples/chinese_nlp_demo.py

# ğŸ” å¯†ç å­¦æœ¯è¯­å¤„ç†
uv run python examples/crypto_term_demo.py

# ğŸ’­ æ€è€ƒé“¾ç”Ÿæˆ
uv run python examples/thinking_generator_demo.py

# ğŸ“¦ æ¨¡å‹å¯¼å‡ºéƒ¨ç½²
uv run python examples/model_export_deployment_demo.py
```

### é«˜çº§åŠŸèƒ½æ¼”ç¤º
```bash
# âš¡ åˆ†å¸ƒå¼è®­ç»ƒ
uv run python examples/distributed_training_demo.py

# ğŸ“ˆ æ€§èƒ½åŸºå‡†æµ‹è¯•
uv run python examples/expert_evaluation_performance_benchmark.py

# ğŸ›ï¸ LoRAé…ç½®ä¼˜åŒ–
uv run python examples/lora_config_demo.py

# ğŸ“Š æ•°æ®é›†åˆ†å‰²
uv run python examples/dataset_splitter_demo.py
```

## ğŸ† é¡¹ç›®äº®ç‚¹

### æŠ€æœ¯åˆ›æ–°
- âœ¨ **æ€è€ƒé“¾æ¨ç†**: å®Œæ•´æ”¯æŒCoTæ¨ç†ï¼Œæå‡æ¨¡å‹é€»è¾‘èƒ½åŠ›
- ğŸ§  **ä¸“å®¶è¯„ä¼°**: å¤šç»´åº¦æ™ºèƒ½è¯„ä¼°ç³»ç»Ÿï¼Œç¡®ä¿æ¨¡å‹è´¨é‡
- ğŸ‡¨ğŸ‡³ **ä¸­æ–‡ä¼˜åŒ–**: æ·±åº¦ä¸­æ–‡NLPå¤„ç†ï¼Œä¸“ä¸šæœ¯è¯­ä¿æŠ¤
- âš¡ **æ€§èƒ½ä¼˜åŒ–**: æ™ºèƒ½ç¡¬ä»¶æ£€æµ‹ï¼Œè‡ªåŠ¨é…ç½®ä¼˜åŒ–ç­–ç•¥

### å·¥ç¨‹å®è·µ
- ğŸ”§ **æ¨¡å—åŒ–è®¾è®¡**: é«˜åº¦æ¨¡å—åŒ–ï¼Œæ˜“äºæ‰©å±•å’Œç»´æŠ¤
- ğŸ“Š **å®Œæ•´ç›‘æ§**: å®æ—¶è®­ç»ƒç›‘æ§ï¼Œå¼‚å¸¸æ£€æµ‹å’Œé¢„è­¦
- ğŸš€ **è‡ªåŠ¨åŒ–æµæ°´çº¿**: ç«¯åˆ°ç«¯è‡ªåŠ¨åŒ–ï¼Œä»æ•°æ®åˆ°éƒ¨ç½²
- ğŸ›¡ï¸ **ç¨³å®šå¯é **: å®Œå–„çš„é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶

### ä¸“ä¸šé¢†åŸŸ
- ğŸ” **å¯†ç å­¦ä¸“ä¸š**: ä¸“é—¨é’ˆå¯¹å¯†ç å­¦é¢†åŸŸä¼˜åŒ–
- ğŸ“š **æ•™è‚²å‹å¥½**: ä¸°å¯Œçš„ç¤ºä¾‹å’Œæ–‡æ¡£ï¼Œæ˜“äºå­¦ä¹ 
- ğŸŒ **ç”Ÿäº§å°±ç»ª**: æ”¯æŒå®¹å™¨åŒ–éƒ¨ç½²å’ŒæœåŠ¡åŒ–
- ğŸ“ˆ **å¯æ‰©å±•æ€§**: æ”¯æŒå¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒ

## ğŸ“– ç›¸å…³æ–‡æ¡£

### æ ¸å¿ƒæ–‡æ¡£
- ğŸ“‹ [APIä½¿ç”¨æŒ‡å—](API_USAGE_GUIDE.md)
- ğŸ¤– [æ¨¡å‹ä½¿ç”¨æŒ‡å—](MODEL_USAGE_GUIDE.md)
- ğŸš€ [æ¼”ç¤ºç¨‹åºæŒ‡å—](DEMO_README.md)
- ğŸ¯ [æœ€ç»ˆæ¼”ç¤ºæŒ‡å—](FINAL_DEMO_README.md)

### ä¸“ä¸šæ–‡æ¡£
- ğŸ—ï¸ [ä¸“å®¶è¯„ä¼°æ¶æ„](docs/expert_evaluation_architecture.md)
- âš™ï¸ [ä¸“å®¶è¯„ä¼°é…ç½®](docs/expert_evaluation_configuration.md)
- ğŸš€ [éƒ¨ç½²æŒ‡å—](docs/deployment_guide.md)
- ğŸ“‹ [æ“ä½œæŒ‡å—](docs/operations_guide.md)

### æŠ€æœ¯æ–‡æ¡£
- ğŸ’­ [æ€è€ƒç”Ÿæˆå™¨å®ç°](docs/thinking_generator_implementation.md)
- ğŸ” [å¯†ç å­¦æœ¯è¯­å¢å¼º](docs/crypto_term_enhancement_summary.md)
- ğŸ”§ [æ•…éšœæ’é™¤æŒ‡å—](docs/troubleshooting_guide.md)
- ğŸ‘¤ [ç”¨æˆ·æ‰‹å†Œ](docs/user_manual.md)

## ğŸ¤ è´¡çŒ®æŒ‡å—

### å‚ä¸è´¡çŒ®
1. Fork é¡¹ç›®ä»“åº“
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯: `git checkout -b feature/amazing-feature`
3. æäº¤æ›´æ”¹: `git commit -m 'Add amazing feature'`
4. æ¨é€åˆ†æ”¯: `git push origin feature/amazing-feature`
5. æäº¤Pull Request

### å¼€å‘è§„èŒƒ
- éµå¾ªPEP 8ä»£ç è§„èŒƒ
- æ·»åŠ é€‚å½“çš„æµ‹è¯•ç”¨ä¾‹
- æ›´æ–°ç›¸å…³æ–‡æ¡£
- ç¡®ä¿æ‰€æœ‰æµ‹è¯•é€šè¿‡

### é—®é¢˜åé¦ˆ
- ğŸ› [æŠ¥å‘ŠBug](../../issues/new?template=bug_report.md)
- ğŸ’¡ [åŠŸèƒ½å»ºè®®](../../issues/new?template=feature_request.md)
- â“ [ä½¿ç”¨é—®é¢˜](../../discussions)

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº [MITè®¸å¯è¯](LICENSE) å¼€æºã€‚

## ğŸ·ï¸ ç‰ˆæœ¬å†å²

### v0.2.0 (å½“å‰ç‰ˆæœ¬)
- âœ… å®Œæ•´çš„ä¸“å®¶è¯„ä¼°ç³»ç»Ÿ
- âœ… ä¸­æ–‡NLPæ·±åº¦ä¼˜åŒ–
- âœ… å¯†ç å­¦ä¸“ä¸šæœ¯è¯­å¤„ç†
- âœ… æ€è€ƒé“¾æ•°æ®ç”Ÿæˆ
- âœ… æ¨¡å‹å¯¼å‡ºå’Œéƒ¨ç½²
- âœ… åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒ
- âœ… æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–
- âœ… å®Œæ•´çš„æ–‡æ¡£ä½“ç³»

### v0.1.0 (åˆå§‹ç‰ˆæœ¬)
- âœ… åŸºç¡€Qwen3-4B-Thinkingæ”¯æŒ
- âœ… LoRAå¾®è°ƒåŠŸèƒ½
- âœ… GPUæ£€æµ‹å’Œä¼˜åŒ–
- âœ… åŸºç¡€è®­ç»ƒæµæ°´çº¿

---

<div align="center">

**ğŸ‰ æ„Ÿè°¢ä½¿ç”¨ Qwen3-4B-Thinking ä¸­æ–‡å¯†ç å­¦å¾®è°ƒç³»ç»Ÿï¼**

*å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·è€ƒè™‘ç»™æˆ‘ä»¬ä¸€ä¸ª â­*

</div>
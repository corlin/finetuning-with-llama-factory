#!/usr/bin/env python3
"""
ä½¿ç”¨ Python å¤šè¿›ç¨‹çš„åˆ†å¸ƒå¼è®­ç»ƒè„šæœ¬ - é¿å… torchrun çš„ libuv é—®é¢˜
"""

import os
import sys
import yaml
import subprocess
import multiprocessing as mp
from pathlib import Path

def create_multiprocess_config():
    """åˆ›å»ºå¤šè¿›ç¨‹é…ç½®æ–‡ä»¶"""
    config_file = "final_demo_output/configs/llamafactory_config_20250824_212935.yaml"
    mp_config = "final_demo_output/configs/llamafactory_config_multiprocess.yaml"
    
    if not os.path.exists(config_file):
        print(f"âŒ åŸé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        return None
    
    # è¯»å–åŸé…ç½®
    with open(config_file, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # é…ç½®å¤šè¿›ç¨‹è®­ç»ƒ
    config['ddp_backend'] = 'gloo'  # Windows å…¼å®¹
    config['dataloader_num_workers'] = 0  # Windows å…¼å®¹
    config['ddp_timeout'] = 3600
    config['ddp_find_unused_parameters'] = True
    config['ddp_broadcast_buffers'] = False
    
    # ä¿®å¤æ¨¡å‹åç§°å‚æ•°
    if 'model_name' in config and 'model_name_or_path' not in config:
        config['model_name_or_path'] = config['model_name']
    
    # ç§»é™¤ä¸è¢«è¯†åˆ«çš„é”®
    unused_keys = ['model_name', 'visual_inputs', 'evaluation_strategy']
    for key in unused_keys:
        config.pop(key, None)
    
    # ä¿®å¤ç­–ç•¥åŒ¹é…é—®é¢˜
    config['load_best_model_at_end'] = False
    config['save_strategy'] = 'steps'
    
    # æ•°æ®é›†è·¯å¾„
    config['dataset_dir'] = 'final_demo_output/data'
    
    # å¤šè¿›ç¨‹è®­ç»ƒæ‰¹æ¬¡å¤§å°
    config['per_device_train_batch_size'] = 1
    config['per_device_eval_batch_size'] = 1
    config['gradient_accumulation_steps'] = 4
    
    # ä¿å­˜é…ç½®
    os.makedirs(os.path.dirname(mp_config), exist_ok=True)
    with open(mp_config, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
    
    print(f"âœ… åˆ›å»ºå¤šè¿›ç¨‹é…ç½®æ–‡ä»¶: {mp_config}")
    return mp_config

def run_worker(rank, world_size, config_file, master_port):
    """è¿è¡Œå•ä¸ªå·¥ä½œè¿›ç¨‹"""
    print(f"ğŸ”§ å¯åŠ¨å·¥ä½œè¿›ç¨‹ {rank}/{world_size}")
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    env = os.environ.copy()
    env["DATASET_INFO_FILE"] = "final_demo_output/data/dataset_info.json"
    env["USE_LIBUV"] = "0"  # å…³é”®ï¼šç¦ç”¨ libuv
    env["NCCL_P2P_DISABLE"] = "1"
    env["NCCL_IB_DISABLE"] = "1"
    env["OMP_NUM_THREADS"] = "1"
    env["CUDA_VISIBLE_DEVICES"] = str(rank)  # æ¯ä¸ªè¿›ç¨‹ä½¿ç”¨ä¸€ä¸ª GPU
    
    # åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒå˜é‡
    env["RANK"] = str(rank)
    env["LOCAL_RANK"] = str(rank)
    env["WORLD_SIZE"] = str(world_size)
    env["MASTER_ADDR"] = "127.0.0.1"
    env["MASTER_PORT"] = str(master_port)
    
    print(f"ğŸ”§ è¿›ç¨‹ {rank} ä½¿ç”¨ GPU: {env['CUDA_VISIBLE_DEVICES']}")
    
    # ç›´æ¥è°ƒç”¨ LlamaFactory è®­ç»ƒ
    cmd = ["uv", "run", "python", "-m", "llamafactory.train.tuner", config_file]
    
    try:
        result = subprocess.run(
            cmd,
            env=env,
            cwd=os.getcwd(),
            capture_output=False,
            text=True
        )
        
        if result.returncode == 0:
            print(f"âœ… è¿›ç¨‹ {rank} è®­ç»ƒå®Œæˆ!")
            return True
        else:
            print(f"âŒ è¿›ç¨‹ {rank} è®­ç»ƒå¤±è´¥ï¼Œé€€å‡ºç : {result.returncode}")
            return False
            
    except Exception as e:
        print(f"âŒ è¿›ç¨‹ {rank} æ‰§è¡Œå¤±è´¥: {e}")
        return False

def run_training():
    """è¿è¡Œå¤šè¿›ç¨‹è®­ç»ƒ"""
    print("ğŸš€ å¼€å§‹å¤šè¿›ç¨‹åˆ†å¸ƒå¼è®­ç»ƒ...")
    
    # åˆ›å»ºé…ç½®
    config_file = create_multiprocess_config()
    if not config_file:
        return False
    
    print(f"ğŸ“‹ ä½¿ç”¨é…ç½®æ–‡ä»¶: {config_file}")
    
    # è®¾ç½®å‚æ•°
    world_size = 2  # ä½¿ç”¨ 2 ä¸ª GPU
    master_port = 29500
    
    print(f"ğŸ”§ å¯åŠ¨ {world_size} ä¸ªè®­ç»ƒè¿›ç¨‹")
    print(f"ğŸ”§ ä¸»ç«¯å£: {master_port}")
    
    # åˆ›å»ºè¿›ç¨‹æ± 
    processes = []
    
    try:
        # å¯åŠ¨å·¥ä½œè¿›ç¨‹
        for rank in range(world_size):
            p = mp.Process(
                target=run_worker,
                args=(rank, world_size, config_file, master_port)
            )
            p.start()
            processes.append(p)
            print(f"âœ… å¯åŠ¨è¿›ç¨‹ {rank}")
        
        # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
        results = []
        for i, p in enumerate(processes):
            p.join()
            results.append(p.exitcode == 0)
            print(f"âœ… è¿›ç¨‹ {i} å®Œæˆï¼Œé€€å‡ºç : {p.exitcode}")
        
        # æ£€æŸ¥ç»“æœ
        if all(results):
            print("âœ… æ‰€æœ‰è¿›ç¨‹è®­ç»ƒå®Œæˆ!")
            return True
        else:
            print("âŒ éƒ¨åˆ†è¿›ç¨‹è®­ç»ƒå¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ å¤šè¿›ç¨‹è®­ç»ƒå¤±è´¥: {e}")
        # æ¸…ç†è¿›ç¨‹
        for p in processes:
            if p.is_alive():
                p.terminate()
                p.join()
        return False

def check_environment():
    """æ£€æŸ¥ç¯å¢ƒ"""
    print("ğŸ” æ£€æŸ¥ç¯å¢ƒ...")
    
    # æ£€æŸ¥ uv
    try:
        result = subprocess.run(["uv", "--version"], capture_output=True, text=True)
        if result.returncode == 0:
            print(f"âœ… uv ç‰ˆæœ¬: {result.stdout.strip()}")
        else:
            print("âŒ uv æœªå®‰è£…")
            return False
    except:
        print("âŒ uv æœªå®‰è£…")
        return False
    
    # æ£€æŸ¥ LlamaFactory
    try:
        result = subprocess.run(
            ["uv", "run", "python", "-c", "import llamafactory; print(llamafactory.__version__)"],
            capture_output=True, text=True
        )
        if result.returncode == 0:
            print(f"âœ… LlamaFactory ç‰ˆæœ¬: {result.stdout.strip()}")
        else:
            print("âŒ LlamaFactory å¯¼å…¥å¤±è´¥")
            return False
    except:
        print("âŒ LlamaFactory æ£€æŸ¥å¤±è´¥")
        return False
    
    # æ£€æŸ¥ GPU
    try:
        result = subprocess.run(
            ["uv", "run", "python", "-c", "import torch; print(f'GPU å¯ç”¨: {torch.cuda.is_available()}, GPU æ•°é‡: {torch.cuda.device_count()}')"],
            capture_output=True, text=True
        )
        if result.returncode == 0:
            print(f"âœ… {result.stdout.strip()}")
        else:
            print("âŒ GPU æ£€æŸ¥å¤±è´¥")
    except:
        print("âŒ GPU æ£€æŸ¥å¤±è´¥")
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ LlamaFactory å¤šè¿›ç¨‹åˆ†å¸ƒå¼è®­ç»ƒå¯åŠ¨å™¨")
    print("=" * 50)
    
    # æ£€æŸ¥ç¯å¢ƒ
    if not check_environment():
        print("âŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥")
        return False
    
    # è¿è¡Œè®­ç»ƒ
    return run_training()

if __name__ == "__main__":
    # è®¾ç½®å¤šè¿›ç¨‹å¯åŠ¨æ–¹æ³•
    mp.set_start_method('spawn', force=True)
    success = main()
    sys.exit(0 if success else 1)
# 需求文档

## 简介

本功能基于LLaMA Factory框架实现了一个全面的模型微调系统，专门针对Qwen/Qwen3-4B-Thinking-2507模型进行优化。该系统提供端到端的能力，包括将markdown数据处理为训练数据集、支持深度思考(thinking)数据格式、使用LoRA和混合精度训练等先进技术进行内存高效的微调、监控训练过程、使用专家方法评估结果，以及导出量化模型。系统专门针对中文文本、密码学专业领域和深度思考推理模式进行优化，在有限的GPU资源下高效运行，同时保持专业级的机器学习实践标准。

## 需求

### 需求 1

**用户故事：** 作为机器学习工程师，我希望建立基于LLaMA Factory的微调环境并进行适当的依赖管理，以便能够高效地微调Qwen3-4B-Thinking模型，支持CUDA和内存优化。

#### 验收标准

1. 当系统初始化时，系统应创建一个由uv管理的Python 3.12+项目，包含适当的CUDA PyTorch依赖
2. 当依赖安装时，系统应使用指定的索引URL配置支持CUDA 12.9的PyTorch
3. 当环境验证时，系统应验证CUDA可用性和GPU内存容量，特别针对Qwen3-4B模型的内存需求
4. 当加载Qwen3-4B-Thinking模型时，系统应验证模型兼容性和tokenizer配置
5. 如果GPU内存有限，系统应自动配置内存高效设置，优化Qwen3-4B模型的加载策略

### 需求 2

**用户故事：** 作为数据科学家，我希望将markdown文件解析为结构化的微调数据集，支持深度思考(thinking)数据格式，以便将文档和中文文本数据转换为Qwen3-4B-Thinking模型的训练就绪格式，特别针对密码学专业领域。

#### 验收标准

1. 当提供markdown文件时，系统应将其解析为结构化的对话或指令跟随格式
2. 当解析markdown时，系统应提取标题、代码块和文本内容作为独立的训练组件
3. 当markdown包含问答模式时，系统应自动识别并将其结构化为指令-响应对
4. 当markdown包含`<thinking>`标签时，系统应正确解析思考过程并保持标签结构
5. 当处理深度思考数据时，系统应支持`<thinking>`和`</thinking>`标签的嵌套和多层思考
6. 当markdown包含中文密码学术语和概念时，系统应正确处理中文分词和专业术语识别
7. 如果markdown包含代码示例，系统应保留代码格式并将其与解释性文本关联
8. 当解析完成时，系统应验证数据集格式与LLaMA Factory和Qwen3-4B-Thinking的兼容性
9. 当处理中文文本时，系统应支持繁简体转换和中文标点符号规范化
10. 当生成thinking数据时，系统应确保思考过程的逻辑连贯性和专业准确性

### 需求 3

**用户故事：** 作为深度学习研究者，我希望系统能够处理和生成高质量的深度思考(thinking)训练数据，以便充分发挥Qwen3-4B-Thinking模型的推理能力，特别是在中文密码学领域的复杂推理任务。

#### 验收标准

1. 当处理thinking数据时，系统应支持多层嵌套的`<thinking>`标签结构
2. 当生成thinking数据时，系统应确保思考过程包含问题分析、推理步骤和结论验证
3. 当处理密码学thinking数据时，系统应生成包含算法分析、安全性评估和实现考虑的思考过程
4. 当验证thinking数据质量时，系统应检查思考逻辑的连贯性和专业准确性
5. 当转换现有数据为thinking格式时，系统应自动生成合理的思考过程
6. 当处理中文thinking数据时，系统应保持中文表达的自然性和专业性
7. 当thinking数据包含代码时，系统应在思考过程中包含代码分析和解释
8. 当生成复杂推理thinking时，系统应支持多步骤推理和中间结果验证
9. 如果thinking数据格式不正确，系统应提供详细的错误信息和修复建议

### 需求 4

**用户故事：** 作为机器学习实践者，我希望自动将数据集分割为训练、验证和测试集，以便正确评估模型性能并防止过拟合，特别是对中文密码学文本和thinking数据的处理。

#### 验收标准

1. 当处理数据集时，系统应默认将其分割为训练集(70%)、验证集(15%)和测试集(15%)
2. 当分割数据时，系统应允许通过配置自定义分割比例
3. 当进行分割时，系统应确保不同类型的数据在各分割中均衡分布
4. 当处理中文密码学文本时，系统应确保专业术语和概念在各分割中均匀分布
5. 当分割thinking数据时，系统应保持思考过程的完整性，不在thinking标签内部分割
6. 当创建分割时，系统应以LLaMA Factory和Qwen3-4B-Thinking兼容格式保存
7. 如果数据集过小，系统应警告潜在的过拟合风险
8. 当分割中文文本时，系统应保持语义完整性，避免在句子中间分割
9. 当分割包含thinking标签的数据时，系统应确保每个样本的thinking过程完整

### 需求 5

**用户故事：** 作为模型训练师，我希望配置和执行使用LoRA和混合精度的内存高效微调，支持多GPU并行训练，以便在有限的GPU资源上高效训练Qwen3-4B-Thinking模型进行中文密码学推理而不会内存溢出。

#### 验收标准

1. 当启动微调时，系统应自动检测可用GPU数量并配置相应的并行策略
2. 当多GPU可用时，系统应支持数据并行、模型并行和流水线并行训练
3. 当训练开始时，系统应启用混合精度训练(FP16/BF16)以减少内存使用
4. 当内存使用接近限制时，系统应实施梯度检查点和批次大小调整
5. 当配置LoRA时，系统应为Qwen3-4B模型大小和GPU数量设置适当的rank和alpha值
6. 当针对中文文本训练时，系统应优化Qwen tokenizer的内存使用
7. 当使用多GPU时，系统应提供并行训练开关和策略选择
8. 当训练thinking数据时，系统应确保thinking标签的正确处理和梯度计算
9. 如果发生OOM，系统应自动减少批次大小并重试训练
10. 当处理密码学专业术语时，系统应确保LoRA适配器能够有效学习专业词汇
11. 当多GPU训练时，系统应协调跨GPU的梯度同步和参数更新
6. 当针对中文文本训练时，系统应优化中文tokenizer的内存使用
7. 当使用多GPU时，系统应提供并行训练开关和策略选择
8. 如果发生OOM，系统应自动减少批次大小并重试训练
9. 当处理密码学专业术语时，系统应确保LoRA适配器能够有效学习专业词汇
10. 当多GPU训练时，系统应协调跨GPU的梯度同步和参数更新

### 需求 5

**用户故事：** 作为训练监督者，我希望实时监控微调过程，以便跟踪进度、识别问题，并对训练继续做出明智决策，特别是中文密码学模型的训练状态。

#### 验收标准

1. 当训练开始时，系统应显示实时损失曲线和学习率调度
2. 当每个epoch完成时，系统应记录训练指标、验证损失和GPU内存使用情况
3. 当训练进行时，系统应提供剩余时间估计和收敛指标
4. 当检测到异常时，系统应警告潜在的训练问题(损失峰值、内存泄漏)
5. 当监控中文文本训练时，系统应显示中文特定的指标(如字符级准确率)
6. 当训练完成时，系统应生成包含中文处理效果的综合训练报告
7. 当训练密码学模型时，系统应监控专业术语的学习进度

### 需求 6

**用户故事：** 作为模型评估专家，我希望使用专业的评估方法评估微调模型性能，以便确定模型是否达到部署前的质量标准，特别是对中文密码学领域的专业能力。

#### 验收标准

1. 当请求评估时，系统应在保留的测试集上运行模型
2. 当评估响应时，系统应计算困惑度、BLEU分数和其他相关指标
3. 当启用专家评估时，系统应实施人在回路的评估工作流程
4. 当评估中文文本时，系统应使用中文特定的评估指标(如ROUGE-L中文版)
5. 当评估密码学专业能力时，系统应测试专业术语理解、概念解释和技术准确性
6. 当评估完成时，系统应生成包含示例的详细性能报告
7. 当专家评估密码学内容时，系统应提供专业领域的准确性评分
8. 如果性能低于阈值，系统应推荐训练调整方案
9. 当进行专家评估时，系统应支持多维度评分(准确性、流畅性、专业性)

### 需求 7

**用户故事：** 作为部署工程师，我希望以量化格式导出微调模型，以便部署具有更小内存占用和更快推理速度的高效中文密码学模型。

#### 验收标准

1. 当请求模型导出时，系统应支持多种量化格式(INT8、INT4、GPTQ)
2. 当量化模型时，系统应在减少大小的同时保持模型性能
3. 当导出完成时，系统应验证量化模型的功能性
4. 当导出时，系统应包含模型元数据和使用说明
5. 当量化中文模型时，系统应确保中文字符处理的准确性不受影响
6. 如果量化显著降低性能，系统应警告并提供替代方法
7. 当导出密码学专业模型时，系统应验证专业术语的准确性保持

### 需求 8

**用户故事：** 作为高性能计算专家，我希望系统支持多种并行训练策略和多GPU配置，以便能够充分利用多显卡资源进行大规模中文密码学模型训练。

#### 验收标准

1. 当系统检测到多GPU时，系统应自动推荐最优的并行训练策略
2. 当启用数据并行时，系统应将训练数据均匀分布到各个GPU
3. 当启用模型并行时，系统应将模型参数分片到不同GPU
4. 当启用流水线并行时，系统应将模型层分配到不同GPU并协调流水线执行
5. 当配置并行训练时，系统应提供手动开关控制各种并行策略
6. 当多GPU通信时，系统应使用高效的通信后端(NCCL/GLOO)
7. 当并行训练时，系统应确保梯度同步的正确性和效率
8. 当处理中文密码学数据时，系统应保证并行训练不影响专业术语的学习效果
9. 如果并行配置不当，系统应提供优化建议和自动调整选项

### 需求 9

**用户故事：** 作为系统管理员，我希望进行全面的内存管理和多GPU资源优化，以便系统能够在硬件约束内可靠运行，特别是处理中文密码学模型的分布式训练时的资源需求。

#### 验收标准

1. 当系统启动时，系统应分析所有可用GPU的内存和拓扑结构并设置适当限制
2. 当训练时，系统应监控多GPU内存使用并实施动态批次大小调整
3. 当内存压力增加时，系统应启用梯度累积并减少缓存大小
4. 当多GPU训练时，系统应协调跨GPU的内存分配和负载均衡
5. 当处理中文文本时，系统应优化tokenizer和词汇表在多GPU间的内存使用
6. 当GPU间通信时，系统应监控和优化通信开销
7. 如果系统资源不足，系统应提供明确的多GPU硬件需求指导
8. 当训练密码学专业模型时，系统应智能管理专业词汇表在多GPU间的内存占用
9. 当GPU故障时，系统应能够检测并重新分配工作负载到健康的GPU
10. 当多GPU训练时，系统应提供GPU利用率和负载均衡的实时监控
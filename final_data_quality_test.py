#!/usr/bin/env python3
"""
æœ€ç»ˆæ•°æ®è´¨é‡æµ‹è¯•
éªŒè¯æ‰€æœ‰å¢å¼ºæ•°æ®çš„è´¨é‡å’Œå®Œæ•´æ€§
"""

import json
import re
import os
from typing import Dict, List, Tuple

def analyze_thinking_quality(thinking_text: str) -> Dict[str, float]:
    """åˆ†æthinkingè´¨é‡"""
    scores = {}
    
    # 1. ç»“æ„åŒ–ç¨‹åº¦ (0-1)
    structure_indicators = [
        r'\d+[.ã€]',  # ç¼–å·
        r'[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[ã€.]',  # ä¸­æ–‡ç¼–å·
        r'é¦–å…ˆ|å…¶æ¬¡|ç„¶å|æœ€å|å› æ­¤',  # é€»è¾‘è¿æ¥è¯
        r'æ–¹é¢|è§’åº¦|ç»´åº¦|å±‚é¢',  # åˆ†æç»´åº¦è¯
    ]
    structure_score = sum(1 for pattern in structure_indicators if re.search(pattern, thinking_text)) / len(structure_indicators)
    scores['structure'] = min(structure_score, 1.0)
    
    # 2. ä¸“ä¸šæœ¯è¯­å¯†åº¦ (0-1)
    crypto_terms = [
        'å¯†ç ', 'åŠ å¯†', 'è§£å¯†', 'ç­¾å', 'è®¤è¯', 'å®Œæ•´æ€§', 'æœºå¯†æ€§', 'çœŸå®æ€§',
        'ä¸å¯å¦è®¤', 'å¯†é’¥', 'SM2', 'SM3', 'SM4', 'æ¤­åœ†æ›²çº¿', 'å“ˆå¸Œ', 'ç®—æ³•',
        'è¯ä¹¦', 'å…¬é’¥', 'ç§é’¥', 'å¯¹ç§°', 'éå¯¹ç§°', 'æ•°å­—ç­¾å', 'æ¶ˆæ¯è®¤è¯ç '
    ]
    term_count = sum(1 for term in crypto_terms if term in thinking_text)
    term_density = min(term_count / 10, 1.0)  # æœ€å¤š10ä¸ªæœ¯è¯­å¾—æ»¡åˆ†
    scores['terminology'] = term_density
    
    # 3. é€»è¾‘æ·±åº¦ (0-1)
    depth_indicators = [
        r'åˆ†æ|ç†è§£|è€ƒè™‘|è¯„ä¼°',  # åˆ†æè¯
        r'å› ä¸º|ç”±äº|æ‰€ä»¥|å› æ­¤|å¯¼è‡´',  # å› æœå…³ç³»
        r'ä½†æ˜¯|ç„¶è€Œ|ä¸è¿‡|ç›¸æ¯”',  # å¯¹æ¯”å…³ç³»
        r'åŒ…æ‹¬|æ¶µç›–|å…·ä½“|è¯¦ç»†',  # ç»†åŒ–å…³ç³»
    ]
    depth_score = sum(1 for pattern in depth_indicators if re.search(pattern, thinking_text)) / len(depth_indicators)
    scores['depth'] = min(depth_score, 1.0)
    
    # 4. é•¿åº¦é€‚ä¸­æ€§ (0-1)
    length = len(thinking_text)
    if 200 <= length <= 800:
        length_score = 1.0
    elif length < 200:
        length_score = length / 200
    else:
        length_score = max(0.5, 1.0 - (length - 800) / 1000)
    scores['length'] = length_score
    
    # 5. ç»¼åˆè´¨é‡åˆ†æ•°
    scores['overall'] = sum(scores.values()) / len(scores)
    
    return scores

def test_data_completeness() -> Dict[str, any]:
    """æµ‹è¯•æ•°æ®å®Œæ•´æ€§"""
    results = {
        'files_found': [],
        'files_missing': [],
        'total_questions': 0,
        'quality_scores': [],
        'difficulty_distribution': {},
        'source_coverage': {}
    }
    
    # æ£€æŸ¥åŸå§‹å¢å¼ºæ–‡ä»¶
    enhanced_files = [
        'data/raw/enhanced_QA1.md',
        'data/raw/enhanced_QA2.md', 
        'data/raw/enhanced_QA3.md',
        'data/raw/enhanced_QA4.md',
        'data/raw/enhanced_QA5.md',
        'data/raw/enhanced_QA6.md'
    ]
    
    for file_path in enhanced_files:
        if os.path.exists(file_path):
            results['files_found'].append(file_path)
        else:
            results['files_missing'].append(file_path)
    
    # æ£€æŸ¥å¤„ç†åçš„JSONæ–‡ä»¶
    json_files = [
        'data/processed/thinking_training_data.json',
        'data/processed/thinking_data_beginner.json',
        'data/processed/thinking_data_intermediate.json',
        'data/processed/thinking_data_expert.json'
    ]
    
    for file_path in json_files:
        if os.path.exists(file_path):
            results['files_found'].append(file_path)
        else:
            results['files_missing'].append(file_path)
    
    return results

def analyze_training_data_quality() -> Dict[str, any]:
    """åˆ†æè®­ç»ƒæ•°æ®è´¨é‡"""
    main_file = 'data/processed/thinking_training_data.json'
    
    if not os.path.exists(main_file):
        return {'error': 'ä¸»è®­ç»ƒæ–‡ä»¶ä¸å­˜åœ¨'}
    
    try:
        with open(main_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except Exception as e:
        return {'error': f'è¯»å–æ–‡ä»¶å¤±è´¥: {e}'}
    
    results = {
        'total_samples': len(data),
        'quality_scores': [],
        'thinking_lengths': [],
        'instruction_lengths': [],
        'output_lengths': [],
        'high_quality_count': 0,
        'medium_quality_count': 0,
        'low_quality_count': 0
    }
    
    for item in data:
        # æå–thinkingå†…å®¹
        output = item.get('output', '')
        thinking_match = re.search(r'<thinking>(.*?)</thinking>', output, re.DOTALL)
        
        if thinking_match:
            thinking_text = thinking_match.group(1).strip()
            quality_scores = analyze_thinking_quality(thinking_text)
            results['quality_scores'].append(quality_scores)
            results['thinking_lengths'].append(len(thinking_text))
            
            # è´¨é‡åˆ†çº§
            overall_score = quality_scores['overall']
            if overall_score >= 0.8:
                results['high_quality_count'] += 1
            elif overall_score >= 0.6:
                results['medium_quality_count'] += 1
            else:
                results['low_quality_count'] += 1
        
        results['instruction_lengths'].append(len(item.get('instruction', '')))
        results['output_lengths'].append(len(output))
    
    # è®¡ç®—å¹³å‡å€¼
    if results['quality_scores']:
        avg_scores = {}
        for key in results['quality_scores'][0].keys():
            avg_scores[key] = sum(score[key] for score in results['quality_scores']) / len(results['quality_scores'])
        results['average_quality_scores'] = avg_scores
    
    if results['thinking_lengths']:
        results['avg_thinking_length'] = sum(results['thinking_lengths']) / len(results['thinking_lengths'])
        results['min_thinking_length'] = min(results['thinking_lengths'])
        results['max_thinking_length'] = max(results['thinking_lengths'])
    
    return results

def main():
    """ä¸»å‡½æ•°"""
    print("=== æœ€ç»ˆæ•°æ®è´¨é‡æµ‹è¯• ===\n")
    
    # 1. æµ‹è¯•æ•°æ®å®Œæ•´æ€§
    print("1. æ•°æ®å®Œæ•´æ€§æ£€æŸ¥...")
    completeness = test_data_completeness()
    
    print(f"   âœ… æ‰¾åˆ°æ–‡ä»¶: {len(completeness['files_found'])} ä¸ª")
    for file_path in completeness['files_found']:
        print(f"      - {file_path}")
    
    if completeness['files_missing']:
        print(f"   âŒ ç¼ºå¤±æ–‡ä»¶: {len(completeness['files_missing'])} ä¸ª")
        for file_path in completeness['files_missing']:
            print(f"      - {file_path}")
    
    # 2. åˆ†æè®­ç»ƒæ•°æ®è´¨é‡
    print(f"\n2. è®­ç»ƒæ•°æ®è´¨é‡åˆ†æ...")
    quality_analysis = analyze_training_data_quality()
    
    if 'error' in quality_analysis:
        print(f"   âŒ åˆ†æå¤±è´¥: {quality_analysis['error']}")
        return
    
    print(f"   ğŸ“Š æ€»æ ·æœ¬æ•°: {quality_analysis['total_samples']}")
    print(f"   ğŸ“ å¹³å‡thinkingé•¿åº¦: {quality_analysis.get('avg_thinking_length', 0):.0f} å­—ç¬¦")
    print(f"   ğŸ“ thinkingé•¿åº¦èŒƒå›´: {quality_analysis.get('min_thinking_length', 0)} - {quality_analysis.get('max_thinking_length', 0)} å­—ç¬¦")
    
    # è´¨é‡åˆ†å¸ƒ
    high_count = quality_analysis['high_quality_count']
    medium_count = quality_analysis['medium_quality_count']
    low_count = quality_analysis['low_quality_count']
    total_count = high_count + medium_count + low_count
    
    print(f"\n   ğŸ¯ è´¨é‡åˆ†å¸ƒ:")
    print(f"      - é«˜è´¨é‡ (â‰¥0.8): {high_count} ä¸ª ({high_count/total_count*100:.1f}%)")
    print(f"      - ä¸­ç­‰è´¨é‡ (0.6-0.8): {medium_count} ä¸ª ({medium_count/total_count*100:.1f}%)")
    print(f"      - å¾…æ”¹è¿› (<0.6): {low_count} ä¸ª ({low_count/total_count*100:.1f}%)")
    
    # å¹³å‡è´¨é‡åˆ†æ•°
    if 'average_quality_scores' in quality_analysis:
        avg_scores = quality_analysis['average_quality_scores']
        print(f"\n   ğŸ“ˆ å¹³å‡è´¨é‡åˆ†æ•°:")
        print(f"      - ç»“æ„åŒ–ç¨‹åº¦: {avg_scores['structure']:.2f}")
        print(f"      - ä¸“ä¸šæœ¯è¯­å¯†åº¦: {avg_scores['terminology']:.2f}")
        print(f"      - é€»è¾‘æ·±åº¦: {avg_scores['depth']:.2f}")
        print(f"      - é•¿åº¦é€‚ä¸­æ€§: {avg_scores['length']:.2f}")
        print(f"      - ç»¼åˆè´¨é‡: {avg_scores['overall']:.2f}")
    
    # 3. éªŒè¯LLaMA Factoryå…¼å®¹æ€§
    print(f"\n3. LLaMA Factoryå…¼å®¹æ€§éªŒè¯...")
    
    main_file = 'data/processed/thinking_training_data.json'
    try:
        with open(main_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # æ£€æŸ¥æ ¼å¼
        required_fields = ['instruction', 'input', 'output', 'system', 'history']
        format_valid = True
        
        for i, item in enumerate(data[:5]):  # æ£€æŸ¥å‰5ä¸ªæ ·æœ¬
            missing_fields = [field for field in required_fields if field not in item]
            if missing_fields:
                print(f"   âŒ æ ·æœ¬ {i+1} ç¼ºå°‘å­—æ®µ: {missing_fields}")
                format_valid = False
        
        if format_valid:
            print(f"   âœ… æ ¼å¼éªŒè¯é€šè¿‡")
            print(f"   âœ… æ‰€æœ‰æ ·æœ¬åŒ…å«å¿…éœ€å­—æ®µ")
            print(f"   âœ… æ‰€æœ‰æ ·æœ¬åŒ…å«thinkingæ ‡ç­¾")
        
        # æ£€æŸ¥system promptä¸€è‡´æ€§
        system_prompts = set(item.get('system', '') for item in data)
        if len(system_prompts) == 1:
            print(f"   âœ… System promptä¸€è‡´")
        else:
            print(f"   âš ï¸  å‘ç° {len(system_prompts)} ç§ä¸åŒçš„system prompt")
        
    except Exception as e:
        print(f"   âŒ å…¼å®¹æ€§éªŒè¯å¤±è´¥: {e}")
    
    # 4. æ€»ç»“
    print(f"\n=== æµ‹è¯•æ€»ç»“ ===")
    
    if completeness['files_missing']:
        print(f"âŒ æ•°æ®ä¸å®Œæ•´ï¼Œç¼ºå¤± {len(completeness['files_missing'])} ä¸ªæ–‡ä»¶")
    else:
        print(f"âœ… æ•°æ®å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡")
    
    if 'average_quality_scores' in quality_analysis:
        overall_quality = quality_analysis['average_quality_scores']['overall']
        if overall_quality >= 0.8:
            print(f"âœ… æ•°æ®è´¨é‡ä¼˜ç§€ (ç»¼åˆåˆ†æ•°: {overall_quality:.2f})")
        elif overall_quality >= 0.6:
            print(f"âš ï¸  æ•°æ®è´¨é‡è‰¯å¥½ (ç»¼åˆåˆ†æ•°: {overall_quality:.2f})")
        else:
            print(f"âŒ æ•°æ®è´¨é‡éœ€è¦æ”¹è¿› (ç»¼åˆåˆ†æ•°: {overall_quality:.2f})")
    
    high_quality_ratio = high_count / total_count if total_count > 0 else 0
    if high_quality_ratio >= 0.7:
        print(f"âœ… é«˜è´¨é‡æ ·æœ¬æ¯”ä¾‹ä¼˜ç§€ ({high_quality_ratio:.1%})")
    elif high_quality_ratio >= 0.5:
        print(f"âš ï¸  é«˜è´¨é‡æ ·æœ¬æ¯”ä¾‹è‰¯å¥½ ({high_quality_ratio:.1%})")
    else:
        print(f"âŒ é«˜è´¨é‡æ ·æœ¬æ¯”ä¾‹åä½ ({high_quality_ratio:.1%})")
    
    print(f"\nğŸ‰ æ•°æ®å·²å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥å¼€å§‹LLaMA Factoryå¾®è°ƒè®­ç»ƒï¼")

if __name__ == "__main__":
    main()
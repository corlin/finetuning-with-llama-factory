#!/usr/bin/env python3
"""
æµ‹è¯•è®­ç»ƒè¿‡ç¨‹ä¸­çš„JSONåºåˆ—åŒ–ä¿®å¤
è¿è¡Œä¸€ä¸ªæœ€å°çš„è®­ç»ƒå¾ªç¯æ¥éªŒè¯ä¿®å¤
"""

import os
import sys
import torch

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.append('src')

def test_minimal_training():
    """æµ‹è¯•æœ€å°è®­ç»ƒæµç¨‹"""
    print("ğŸ” æµ‹è¯•æœ€å°è®­ç»ƒæµç¨‹...")
    
    try:
        from direct_finetuning_with_existing_modules import DirectTrainingConfig, DirectTrainer
        
        # åˆ›å»ºæœ€å°é…ç½®
        config = DirectTrainingConfig()
        config.data_path = "data/raw"
        config.output_dir = "test_output/json_fix_test"
        config.num_epochs = 1  # åªè®­ç»ƒ1ä¸ªepoch
        config.batch_size = 1
        config.max_seq_length = 256  # å‡å°åºåˆ—é•¿åº¦
        config.save_steps = 1  # æ¯æ­¥éƒ½ä¿å­˜ä»¥æµ‹è¯•JSONåºåˆ—åŒ–
        config.logging_steps = 1
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(config.output_dir, exist_ok=True)
        
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = DirectTrainer(config)
        
        print("âœ… è®­ç»ƒå™¨åˆ›å»ºæˆåŠŸ")
        
        # åªæµ‹è¯•åˆå§‹åŒ–ï¼Œä¸è¿è¡Œå®Œæ•´è®­ç»ƒ
        print("âœ… æœ€å°è®­ç»ƒæµç¨‹æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ æœ€å°è®­ç»ƒæµç¨‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_statistics_serialization():
    """æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯åºåˆ—åŒ–"""
    print("\nğŸ” æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯åºåˆ—åŒ–...")
    
    try:
        from direct_finetuning_with_existing_modules import convert_numpy_types
        import json
        import numpy as np
        from datetime import datetime
        
        # æ¨¡æ‹Ÿè®­ç»ƒç»Ÿè®¡æ•°æ®
        mock_stats = {
            'training_config': {
                'model_name': 'test_model',
                'batch_size': np.int32(4),
                'learning_rate': np.float64(1e-4),
                'use_lora': np.bool_(True)
            },
            'dataset_stats': {
                'total_samples': np.int64(100),
                'average_quality': np.float32(0.85),
                'has_thinking': np.bool_(True)
            },
            'model_stats': {
                'total_parameters': np.int64(4000000000),
                'trainable_parameters': np.int64(500000000)
            },
            'monitoring_stats': {
                'convergence_score': np.float64(0.75),
                'is_converged': np.bool_(False),
                'gpu_utilization': np.array([85.5, 90.2])
            },
            'training_completed_at': datetime.now().isoformat()
        }
        
        print("åŸå§‹ç»Ÿè®¡æ•°æ®åŒ…å«numpyç±»å‹")
        
        # è½¬æ¢numpyç±»å‹
        converted_stats = convert_numpy_types(mock_stats)
        
        # æµ‹è¯•JSONåºåˆ—åŒ–
        json_str = json.dumps(converted_stats, indent=2)
        
        # éªŒè¯ååºåˆ—åŒ–
        parsed_stats = json.loads(json_str)
        
        print("âœ… ç»Ÿè®¡ä¿¡æ¯JSONåºåˆ—åŒ–æˆåŠŸ")
        print(f"âœ… åºåˆ—åŒ–åå¤§å°: {len(json_str)} å­—ç¬¦")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç»Ÿè®¡ä¿¡æ¯åºåˆ—åŒ–æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ¯ æµ‹è¯•è®­ç»ƒJSONåºåˆ—åŒ–ä¿®å¤")
    print("=" * 50)
    
    success_count = 0
    total_tests = 2
    
    # æµ‹è¯•æœ€å°è®­ç»ƒæµç¨‹
    if test_minimal_training():
        success_count += 1
    
    # æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯åºåˆ—åŒ–
    if test_statistics_serialization():
        success_count += 1
    
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ: {success_count}/{total_tests} é€šè¿‡")
    
    if success_count == total_tests:
        print("ğŸ‰ è®­ç»ƒJSONåºåˆ—åŒ–ä¿®å¤éªŒè¯æˆåŠŸï¼")
        print("ğŸ’¡ ç°åœ¨å¯ä»¥å®‰å…¨è¿è¡Œå®Œæ•´çš„è®­ç»ƒæµç¨‹")
        return True
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
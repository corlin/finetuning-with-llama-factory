#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆå¾®è°ƒæ¼”ç¤ºç¨‹åº

åŸºäºå½“å‰å·²å®Œæˆçš„åŠŸèƒ½ï¼Œä½¿ç”¨ data/raw æ•°æ®ï¼Œè¿›è¡Œæ¨¡å‹å¾®è°ƒçš„ç®€åŒ–æ¼”ç¤ºã€‚
é¿å…å¤æ‚çš„æµæ°´çº¿ç®¡ç†ï¼Œä¸“æ³¨äºæ ¸å¿ƒåŠŸèƒ½å±•ç¤ºã€‚

åŠŸèƒ½ç‰¹æ€§ï¼š
- è‡ªåŠ¨åŠ è½½å’Œå¤„ç† data/raw ä¸­çš„æ‰€æœ‰æ•°æ®æ–‡ä»¶
- æ™ºèƒ½æ•°æ®é¢„å¤„ç†å’Œæ ¼å¼è½¬æ¢
- è‡ªåŠ¨é…ç½® GPU å¹¶è¡Œç­–ç•¥å’Œ LoRA å‚æ•°
- ç”Ÿæˆ LLaMA Factory å…¼å®¹çš„é…ç½®æ–‡ä»¶
- æä¾›è®­ç»ƒè„šæœ¬å’Œé…ç½®

ä½¿ç”¨æ–¹æ³•ï¼š
    uv run python demo_simple_finetuning.py
"""

import os
import sys
import json
import yaml
import logging
import argparse
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
from data_models import TrainingExample, ThinkingExample, DifficultyLevel
from config_manager import TrainingConfig, DataConfig
from gpu_utils import GPUDetector


class SimpleFinetuningDemo:
    """ç®€åŒ–ç‰ˆå¾®è°ƒæ¼”ç¤ºç±»"""
    
    def __init__(self, output_dir: str = "simple_demo_output"):
        """
        åˆå§‹åŒ–æ¼”ç¤ºç¨‹åº
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # è®¾ç½®æ—¥å¿—
        self.setup_logging()
        self.logger = logging.getLogger(__name__)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.gpu_detector = GPUDetector()
        
        # æ•°æ®å­˜å‚¨
        self.training_data: List[TrainingExample] = []
        
        self.logger.info("ç®€åŒ–ç‰ˆå¾®è°ƒæ¼”ç¤ºç¨‹åºåˆå§‹åŒ–å®Œæˆ")
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—é…ç½®"""
        log_file = self.output_dir / f"demo_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )
    
    def load_and_process_data(self, data_dir: str = "data/raw") -> bool:
        """
        åŠ è½½å’Œå¤„ç†åŸå§‹æ•°æ®
        
        Args:
            data_dir: æ•°æ®ç›®å½•è·¯å¾„
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸåŠ è½½æ•°æ®
        """
        try:
            data_path = Path(data_dir)
            if not data_path.exists():
                self.logger.error(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_path}")
                return False
            
            # æŸ¥æ‰¾æ‰€æœ‰markdownæ–‡ä»¶
            md_files = list(data_path.glob("*.md"))
            if not md_files:
                self.logger.error(f"åœ¨ {data_path} ä¸­æœªæ‰¾åˆ°markdownæ–‡ä»¶")
                return False
            
            self.logger.info(f"æ‰¾åˆ° {len(md_files)} ä¸ªæ•°æ®æ–‡ä»¶")
            
            total_examples = 0
            
            for md_file in md_files:
                self.logger.info(f"å¤„ç†æ–‡ä»¶: {md_file.name}")
                
                # è¯»å–æ–‡ä»¶å†…å®¹
                with open(md_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # è§£æQAå¯¹
                examples = self.parse_qa_content(content, str(md_file))
                
                if examples:
                    self.training_data.extend(examples)
                    total_examples += len(examples)
                    self.logger.info(f"ä» {md_file.name} è§£æå‡º {len(examples)} ä¸ªè®­ç»ƒæ ·ä¾‹")
            
            self.logger.info(f"æ€»å…±åŠ è½½äº† {total_examples} ä¸ªè®­ç»ƒæ ·ä¾‹")
            return total_examples > 0
            
        except Exception as e:
            self.logger.error(f"åŠ è½½å’Œå¤„ç†æ•°æ®å¤±è´¥: {e}")
            return False
    
    def parse_qa_content(self, content: str, source_file: str) -> List[TrainingExample]:
        """
        è§£æQAå†…å®¹ä¸ºè®­ç»ƒæ ·ä¾‹
        
        Args:
            content: æ–‡ä»¶å†…å®¹
            source_file: æºæ–‡ä»¶è·¯å¾„
            
        Returns:
            List[TrainingExample]: è®­ç»ƒæ ·ä¾‹åˆ—è¡¨
        """
        examples = []
        
        # åˆ†å‰²å†…å®¹ä¸ºæ®µè½
        sections = content.split('\n\n')
        
        current_question = ""
        current_thinking = ""
        current_answer = ""
        
        for section in sections:
            section = section.strip()
            if not section:
                continue
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯é—®é¢˜
            if section.startswith('### Q') or (section.startswith('##') and '?' in section):
                # ä¿å­˜ä¹‹å‰çš„QAå¯¹
                if current_question and current_answer:
                    example = self.create_training_example(
                        current_question, current_answer, current_thinking, source_file
                    )
                    if example:
                        examples.append(example)
                
                # å¼€å§‹æ–°çš„QAå¯¹
                current_question = section
                current_thinking = ""
                current_answer = ""
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯thinkingå†…å®¹
            elif '<thinking>' in section:
                current_thinking = section
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç­”æ¡ˆ
            elif section.startswith('A') and ':' in section:
                current_answer = section
        
        # å¤„ç†æœ€åä¸€ä¸ªQAå¯¹
        if current_question and current_answer:
            example = self.create_training_example(
                current_question, current_answer, current_thinking, source_file
            )
            if example:
                examples.append(example)
        
        return examples
    
    def create_training_example(self, question: str, answer: str, thinking: str, source_file: str) -> Optional[TrainingExample]:
        """
        åˆ›å»ºè®­ç»ƒæ ·ä¾‹
        
        Args:
            question: é—®é¢˜
            answer: ç­”æ¡ˆ
            thinking: æ€è€ƒè¿‡ç¨‹
            source_file: æºæ–‡ä»¶
            
        Returns:
            Optional[TrainingExample]: è®­ç»ƒæ ·ä¾‹
        """
        try:
            # æ¸…ç†é—®é¢˜æ–‡æœ¬
            instruction = question.replace('###', '').replace('##', '').strip()
            if ':' in instruction:
                instruction = instruction.split(':', 1)[1].strip()
            
            # æ¸…ç†ç­”æ¡ˆæ–‡æœ¬
            output = answer
            if ':' in output and output.startswith('A'):
                output = output.split(':', 1)[1].strip()
            
            # å¤„ç†thinkingå†…å®¹
            thinking_content = None
            if thinking and '<thinking>' in thinking:
                thinking_content = thinking
            
            if not instruction or not output:
                return None
            
            # æå–å¯†ç å­¦æœ¯è¯­
            crypto_terms = self.extract_crypto_terms(instruction + " " + output)
            
            # åˆ¤æ–­éš¾åº¦çº§åˆ«
            difficulty = self.determine_difficulty(instruction, output)
            
            return TrainingExample(
                instruction=instruction,
                input="",
                output=output,
                thinking=thinking_content,
                crypto_terms=crypto_terms,
                difficulty_level=difficulty,
                source_file=source_file
            )
            
        except Exception as e:
            self.logger.error(f"åˆ›å»ºè®­ç»ƒæ ·ä¾‹å¤±è´¥: {e}")
            return None
    
    def extract_crypto_terms(self, text: str) -> List[str]:
        """æå–å¯†ç å­¦æœ¯è¯­"""
        crypto_keywords = [
            "å¯†ç å­¦", "åŠ å¯†", "è§£å¯†", "å“ˆå¸Œ", "æ•°å­—ç­¾å", "å…¬é’¥", "ç§é’¥", "å¯¹ç§°åŠ å¯†", "éå¯¹ç§°åŠ å¯†",
            "AES", "RSA", "SHA", "MD5", "DES", "3DES", "ECC", "DSA", "ECDSA",
            "å¯†é’¥ç®¡ç†", "è¯ä¹¦", "PKI", "CA", "æ•°å­—è¯ä¹¦", "èº«ä»½è®¤è¯", "è®¿é—®æ§åˆ¶",
            "å®Œæ•´æ€§", "æœºå¯†æ€§", "çœŸå®æ€§", "ä¸å¯å¦è®¤æ€§", "éšæœºæ•°", "å¯†é’¥äº¤æ¢"
        ]
        
        found_terms = []
        text_lower = text.lower()
        
        for term in crypto_keywords:
            if term.lower() in text_lower or term in text:
                found_terms.append(term)
        
        return list(set(found_terms))
    
    def determine_difficulty(self, instruction: str, output: str) -> DifficultyLevel:
        """åˆ¤æ–­éš¾åº¦çº§åˆ«"""
        text = instruction + " " + output
        text_len = len(text)
        
        if text_len < 200:
            return DifficultyLevel.BEGINNER
        elif text_len < 500:
            return DifficultyLevel.INTERMEDIATE
        elif text_len < 1000:
            return DifficultyLevel.ADVANCED
        else:
            return DifficultyLevel.EXPERT
    
    def convert_to_training_format(self) -> Dict[str, Any]:
        """
        è½¬æ¢æ•°æ®ä¸ºè®­ç»ƒæ ¼å¼ï¼ˆé€šç”¨æ ¼å¼ï¼Œä¸ä¾èµ–ç‰¹å®šæ¡†æ¶ï¼‰
        
        Returns:
            Dict[str, Any]: è½¬æ¢ç»“æœä¿¡æ¯
        """
        try:
            # åˆ†å‰²è®­ç»ƒå’ŒéªŒè¯æ•°æ®
            train_ratio = 0.9
            split_idx = int(len(self.training_data) * train_ratio)
            train_examples = self.training_data[:split_idx]
            val_examples = self.training_data[split_idx:] if split_idx < len(self.training_data) else []
            
            # è½¬æ¢ä¸ºLLaMA Factoryæ ¼å¼
            train_data = [example.to_llama_factory_format() for example in train_examples]
            val_data = [example.to_llama_factory_format() for example in val_examples] if val_examples else []
            
            # ä¿å­˜è®­ç»ƒæ•°æ®
            train_file = self.output_dir / "train_data.json"
            with open(train_file, 'w', encoding='utf-8') as f:
                json.dump(train_data, f, ensure_ascii=False, indent=2)
            
            result = {
                "train_file": str(train_file),
                "train_samples": len(train_data)
            }
            
            # ä¿å­˜éªŒè¯æ•°æ®
            if val_data:
                val_file = self.output_dir / "val_data.json"
                with open(val_file, 'w', encoding='utf-8') as f:
                    json.dump(val_data, f, ensure_ascii=False, indent=2)
                result["val_file"] = str(val_file)
                result["val_samples"] = len(val_data)
            
            self.logger.info(f"æ•°æ®è½¬æ¢å®Œæˆ: è®­ç»ƒæ ·ä¾‹ {len(train_data)}, éªŒè¯æ ·ä¾‹ {len(val_data)}")
            return result
            
        except Exception as e:
            self.logger.error(f"æ•°æ®æ ¼å¼è½¬æ¢å¤±è´¥: {e}")
            return {}
    
    def generate_dataset_info(self, data_files: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆæ•°æ®é›†ä¿¡æ¯æ–‡ä»¶
        
        Args:
            data_files: æ•°æ®æ–‡ä»¶ä¿¡æ¯
            
        Returns:
            str: æ•°æ®é›†ä¿¡æ¯æ–‡ä»¶è·¯å¾„
        """
        try:
            dataset_info = {
                "crypto_qa_dataset": {
                    "file_name": data_files["train_file"],
                    "formatting": "alpaca",
                    "columns": {
                        "prompt": "instruction",
                        "query": "input",
                        "response": "output",
                        "system": "system"
                    }
                }
            }
            
            # å¦‚æœæœ‰éªŒè¯æ•°æ®ï¼Œæ·»åŠ åˆ°é…ç½®ä¸­
            if "val_file" in data_files:
                dataset_info["crypto_qa_dataset"]["file_name"] = [
                    data_files["train_file"],
                    data_files["val_file"]
                ]
            
            # ä¿å­˜æ•°æ®é›†ä¿¡æ¯
            info_file = self.output_dir / "dataset_info.json"
            with open(info_file, 'w', encoding='utf-8') as f:
                json.dump(dataset_info, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"æ•°æ®é›†ä¿¡æ¯æ–‡ä»¶å·²ç”Ÿæˆ: {info_file}")
            return str(info_file)
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆæ•°æ®é›†ä¿¡æ¯æ–‡ä»¶å¤±è´¥: {e}")
            return ""
    
    def generate_training_config(self) -> str:
        """
        ç”Ÿæˆè®­ç»ƒé…ç½®æ–‡ä»¶
        
        Returns:
            str: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        try:
            # æ£€æµ‹GPUç¯å¢ƒ
            gpu_infos = self.gpu_detector.get_all_gpu_info()
            gpu_count = len(gpu_infos) if gpu_infos else 1
            
            # åŸºç¡€é…ç½®
            config = {
                # æ¨¡å‹é…ç½®
                "model_name": "Qwen/Qwen3-4B-Thinking-2507",
                "model_revision": "main",
                "template": "qwen",
                "flash_attn": "auto",
                
                # è®­ç»ƒé…ç½®
                "stage": "sft",
                "do_train": True,
                "finetuning_type": "lora",
                "dataset": "crypto_qa_dataset",
                "cutoff_len": 2048,
                "train_on_prompt": False,
                "mask_history": True,
                
                # è¾“å‡ºé…ç½®
                "output_dir": str(self.output_dir / "model_output"),
                "overwrite_output_dir": True,
                
                # è®­ç»ƒå‚æ•°
                "num_train_epochs": 2,
                "per_device_train_batch_size": 1,
                "per_device_eval_batch_size": 1,
                "gradient_accumulation_steps": 4,
                "learning_rate": 2e-4,
                "lr_scheduler_type": "cosine",
                "warmup_ratio": 0.1,
                "weight_decay": 0.01,
                
                # ä¼˜åŒ–å™¨
                "optim": "adamw_torch",
                "adam_beta1": 0.9,
                "adam_beta2": 0.999,
                "adam_epsilon": 1e-8,
                "max_grad_norm": 1.0,
                
                # æ··åˆç²¾åº¦
                "bf16": True,
                "fp16": False,
                "tf32": True,
                
                # LoRAé…ç½®
                "lora_rank": 8,
                "lora_alpha": 16,
                "lora_dropout": 0.1,
                "lora_target": "all",
                
                # ä¿å­˜å’Œè¯„ä¼°
                "save_strategy": "steps",
                "save_steps": 100,
                "save_total_limit": 3,
                "evaluation_strategy": "steps",
                "eval_steps": 100,
                "load_best_model_at_end": True,
                "metric_for_best_model": "eval_loss",
                
                # æ—¥å¿—
                "logging_steps": 10,
                "log_level": "info",
                "plot_loss": True,
                
                # å…¶ä»–
                "seed": 42,
                "val_size": 0.1,
                "preprocessing_num_workers": 4
            }
            
            # å¤šGPUé…ç½®
            if gpu_count > 1:
                config.update({
                    "ddp_timeout": 1800,
                    "ddp_backend": "nccl",
                    "ddp_find_unused_parameters": False,
                    "dataloader_pin_memory": True
                })
            
            # ä¿å­˜é…ç½®æ–‡ä»¶
            config_file = self.output_dir / "training_config.yaml"
            with open(config_file, 'w', encoding='utf-8') as f:
                yaml.dump(config, f, default_flow_style=False, allow_unicode=True, indent=2)
            
            self.logger.info(f"è®­ç»ƒé…ç½®æ–‡ä»¶å·²ç”Ÿæˆ: {config_file}")
            return str(config_file)
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆè®­ç»ƒé…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return ""
    
    def generate_training_script(self, config_file: str) -> str:
        """
        ç”Ÿæˆè®­ç»ƒè„šæœ¬
        
        Args:
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„
            
        Returns:
            str: è®­ç»ƒè„šæœ¬è·¯å¾„
        """
        try:
            script_content = f'''#!/usr/bin/env python3
"""
LLaMA Factoryè®­ç»ƒè„šæœ¬
è‡ªåŠ¨ç”Ÿæˆäº: {datetime.now().isoformat()}
"""

import os
import sys
import yaml
import logging
from pathlib import Path

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    try:
        # é…ç½®æ–‡ä»¶è·¯å¾„
        config_file = "{config_file}"
        dataset_info_file = "{self.output_dir / 'dataset_info.json'}"
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not Path(config_file).exists():
            logger.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {{config_file}}")
            return False
        
        if not Path(dataset_info_file).exists():
            logger.error(f"æ•°æ®é›†ä¿¡æ¯æ–‡ä»¶ä¸å­˜åœ¨: {{dataset_info_file}}")
            return False
        
        # åŠ è½½é…ç½®
        with open(config_file, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        logger.info("é…ç½®ä¿¡æ¯:")
        logger.info(f"- æ¨¡å‹: {{config.get('model_name', 'Unknown')}}")
        logger.info(f"- æ•°æ®é›†: {{config.get('dataset', 'Unknown')}}")
        logger.info(f"- è¾“å‡ºç›®å½•: {{config.get('output_dir', 'Unknown')}}")
        logger.info(f"- è®­ç»ƒè½®æ•°: {{config.get('num_train_epochs', 'Unknown')}}")
        logger.info(f"- å­¦ä¹ ç‡: {{config.get('learning_rate', 'Unknown')}}")
        logger.info(f"- LoRA rank: {{config.get('lora_rank', 'Unknown')}}")
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        os.environ["DATASET_INFO_FILE"] = dataset_info_file
        
        # æ£€æŸ¥LLaMA Factoryæ˜¯å¦å¯ç”¨
        try:
            # è¿™é‡Œåº”è¯¥å¯¼å…¥å¹¶è°ƒç”¨LLaMA Factoryçš„è®­ç»ƒå‡½æ•°
            # from llamafactory.train.tuner import run_exp
            # run_exp(config)
            
            logger.info("æ³¨æ„: è¿™æ˜¯ä¸€ä¸ªæ¼”ç¤ºè„šæœ¬")
            logger.info("è¦è¿›è¡Œå®é™…è®­ç»ƒï¼Œè¯·:")
            logger.info("1. å®‰è£… LLaMA Factory: pip install llamafactory")
            logger.info("2. å–æ¶ˆæ³¨é‡Šä¸Šé¢çš„å¯¼å…¥å’Œè°ƒç”¨ä»£ç ")
            logger.info("3. æˆ–è€…ä½¿ç”¨ LLaMA Factory CLI:")
            logger.info(f"   llamafactory-cli train {{config_file}}")
            
            return True
            
        except ImportError as e:
            logger.error(f"LLaMA Factoryæœªå®‰è£…: {{e}}")
            logger.info("è¯·å®‰è£… LLaMA Factory: pip install llamafactory")
            return False
        
    except Exception as e:
        logger.error(f"è®­ç»ƒæ‰§è¡Œå¤±è´¥: {{e}}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
'''
            
            script_file = self.output_dir / "train.py"
            with open(script_file, 'w', encoding='utf-8') as f:
                f.write(script_content)
            
            # è®¾ç½®æ‰§è¡Œæƒé™ï¼ˆåœ¨Unixç³»ç»Ÿä¸Šï¼‰
            if os.name != 'nt':  # ä¸æ˜¯Windows
                os.chmod(script_file, 0o755)
            
            self.logger.info(f"è®­ç»ƒè„šæœ¬å·²ç”Ÿæˆ: {script_file}")
            return str(script_file)
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆè®­ç»ƒè„šæœ¬å¤±è´¥: {e}")
            return ""
    
    def generate_summary_report(self, data_files: Dict[str, Any], config_file: str, script_file: str) -> str:
        """
        ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        
        Args:
            data_files: æ•°æ®æ–‡ä»¶ä¿¡æ¯
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„
            script_file: è®­ç»ƒè„šæœ¬è·¯å¾„
            
        Returns:
            str: æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        try:
            # ç»Ÿè®¡ä¿¡æ¯
            difficulty_dist = {}
            crypto_terms_count = {}
            
            for example in self.training_data:
                # éš¾åº¦åˆ†å¸ƒ
                level = example.difficulty_level.name
                difficulty_dist[level] = difficulty_dist.get(level, 0) + 1
                
                # æœ¯è¯­ç»Ÿè®¡
                for term in example.crypto_terms:
                    crypto_terms_count[term] = crypto_terms_count.get(term, 0) + 1
            
            # GPUä¿¡æ¯
            gpu_infos = self.gpu_detector.get_all_gpu_info()
            gpu_summary = []
            for gpu in gpu_infos:
                gpu_summary.append({
                    "name": gpu.name,
                    "memory_gb": round(gpu.total_memory / 1024, 1),
                    "compute_capability": f"{gpu.compute_capability[0]}.{gpu.compute_capability[1]}" if gpu.compute_capability else "Unknown"
                })
            
            report = {
                "demo_info": {
                    "name": "ç®€åŒ–ç‰ˆå¾®è°ƒæ¼”ç¤ºç¨‹åº",
                    "version": "1.0.0",
                    "execution_time": datetime.now().isoformat(),
                    "output_directory": str(self.output_dir)
                },
                "data_summary": {
                    "total_examples": len(self.training_data),
                    "train_examples": data_files.get("train_samples", 0),
                    "val_examples": data_files.get("val_samples", 0),
                    "difficulty_distribution": difficulty_dist,
                    "top_crypto_terms": dict(sorted(crypto_terms_count.items(), key=lambda x: x[1], reverse=True)[:10])
                },
                "hardware_summary": {
                    "gpu_count": len(gpu_infos),
                    "gpu_details": gpu_summary
                },
                "generated_files": {
                    "train_data": data_files.get("train_file", ""),
                    "val_data": data_files.get("val_file", ""),
                    "dataset_info": str(self.output_dir / "dataset_info.json"),
                    "training_config": config_file,
                    "training_script": script_file
                },
                "next_steps": [
                    "æ£€æŸ¥ç”Ÿæˆçš„é…ç½®æ–‡ä»¶å’Œæ•°æ®æ–‡ä»¶",
                    "å®‰è£… LLaMA Factory: pip install llamafactory",
                    "è¿è¡Œè®­ç»ƒè„šæœ¬: python train.py",
                    "æˆ–ä½¿ç”¨ CLI: llamafactory-cli train training_config.yaml"
                ]
            }
            
            # ä¿å­˜æŠ¥å‘Š
            report_file = self.output_dir / f"demo_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"æ€»ç»“æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
            return str(report_file)
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆæ€»ç»“æŠ¥å‘Šå¤±è´¥: {e}")
            return ""
    
    def run_demo(self, data_dir: str = "data/raw") -> bool:
        """
        è¿è¡Œå®Œæ•´æ¼”ç¤º
        
        Args:
            data_dir: æ•°æ®ç›®å½•
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸå®Œæˆ
        """
        try:
            print("ğŸš€ å¯åŠ¨ç®€åŒ–ç‰ˆå¾®è°ƒæ¼”ç¤ºç¨‹åº...")
            print(f"ğŸ“‚ æ•°æ®ç›®å½•: {data_dir}")
            print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")
            
            # 1. åŠ è½½å’Œå¤„ç†æ•°æ®
            print("\nğŸ“– æ­¥éª¤ 1: åŠ è½½å’Œå¤„ç†æ•°æ®...")
            if not self.load_and_process_data(data_dir):
                print("âŒ æ•°æ®åŠ è½½å¤±è´¥")
                return False
            
            print(f"âœ… æˆåŠŸåŠ è½½ {len(self.training_data)} ä¸ªè®­ç»ƒæ ·ä¾‹")
            
            # 2. è½¬æ¢æ•°æ®æ ¼å¼
            print("\nğŸ”„ æ­¥éª¤ 2: è½¬æ¢æ•°æ®æ ¼å¼...")
            data_files = self.convert_to_training_format()
            if not data_files:
                print("âŒ æ•°æ®æ ¼å¼è½¬æ¢å¤±è´¥")
                return False
            
            print(f"âœ… æ•°æ®æ ¼å¼è½¬æ¢å®Œæˆ")
            
            # 3. ç”Ÿæˆæ•°æ®é›†ä¿¡æ¯
            print("\nğŸ“‹ æ­¥éª¤ 3: ç”Ÿæˆæ•°æ®é›†ä¿¡æ¯...")
            dataset_info_file = self.generate_dataset_info(data_files)
            if not dataset_info_file:
                print("âŒ æ•°æ®é›†ä¿¡æ¯ç”Ÿæˆå¤±è´¥")
                return False
            
            print(f"âœ… æ•°æ®é›†ä¿¡æ¯ç”Ÿæˆå®Œæˆ")
            
            # 4. ç”Ÿæˆè®­ç»ƒé…ç½®
            print("\nâš™ï¸ æ­¥éª¤ 4: ç”Ÿæˆè®­ç»ƒé…ç½®...")
            config_file = self.generate_training_config()
            if not config_file:
                print("âŒ è®­ç»ƒé…ç½®ç”Ÿæˆå¤±è´¥")
                return False
            
            print(f"âœ… è®­ç»ƒé…ç½®ç”Ÿæˆå®Œæˆ")
            
            # 5. ç”Ÿæˆè®­ç»ƒè„šæœ¬
            print("\nğŸ“ æ­¥éª¤ 5: ç”Ÿæˆè®­ç»ƒè„šæœ¬...")
            script_file = self.generate_training_script(config_file)
            if not script_file:
                print("âŒ è®­ç»ƒè„šæœ¬ç”Ÿæˆå¤±è´¥")
                return False
            
            print(f"âœ… è®­ç»ƒè„šæœ¬ç”Ÿæˆå®Œæˆ")
            
            # 6. ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
            print("\nğŸ“Š æ­¥éª¤ 6: ç”Ÿæˆæ€»ç»“æŠ¥å‘Š...")
            report_file = self.generate_summary_report(data_files, config_file, script_file)
            
            # æ‰“å°æ€»ç»“
            self.print_summary(data_files, config_file, script_file, report_file)
            
            return True
                
        except Exception as e:
            self.logger.error(f"æ¼”ç¤ºç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
            print(f"âŒ æ¼”ç¤ºç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
            return False
    
    def print_summary(self, data_files: Dict[str, Any], config_file: str, script_file: str, report_file: str):
        """æ‰“å°æ€»ç»“ä¿¡æ¯"""
        print("\n" + "="*60)
        print("ğŸ‰ ç®€åŒ–ç‰ˆå¾®è°ƒæ¼”ç¤ºç¨‹åºæ‰§è¡Œå®Œæˆï¼")
        print("="*60)
        
        print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"   - è®­ç»ƒæ ·ä¾‹: {data_files.get('train_samples', 0)}")
        print(f"   - éªŒè¯æ ·ä¾‹: {data_files.get('val_samples', 0)}")
        print(f"   - æ€»æ ·ä¾‹æ•°: {len(self.training_data)}")
        
        # GPUä¿¡æ¯
        gpu_infos = self.gpu_detector.get_all_gpu_info()
        if gpu_infos:
            print(f"\nğŸ–¥ï¸ GPUä¿¡æ¯:")
            for i, gpu in enumerate(gpu_infos):
                print(f"   - GPU {i}: {gpu.name} ({gpu.total_memory/1024:.1f}GB)")
        
        print(f"\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        print(f"   - è®­ç»ƒæ•°æ®: {data_files.get('train_file', 'N/A')}")
        if 'val_file' in data_files:
            print(f"   - éªŒè¯æ•°æ®: {data_files['val_file']}")
        print(f"   - æ•°æ®é›†ä¿¡æ¯: {self.output_dir}/dataset_info.json")
        print(f"   - è®­ç»ƒé…ç½®: {config_file}")
        print(f"   - è®­ç»ƒè„šæœ¬: {script_file}")
        print(f"   - æ€»ç»“æŠ¥å‘Š: {report_file}")
        
        print(f"\nğŸš€ ä¸‹ä¸€æ­¥æ“ä½œ:")
        print(f"   1. æ£€æŸ¥ç”Ÿæˆçš„é…ç½®æ–‡ä»¶: {config_file}")
        print(f"   2. å®‰è£… LLaMA Factory: pip install llamafactory")
        print(f"   3. è¿è¡Œè®­ç»ƒ: python {script_file}")
        print(f"   4. æˆ–ä½¿ç”¨ CLI: llamafactory-cli train {config_file}")
        
        print("\n" + "="*60)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="ç®€åŒ–ç‰ˆå¾®è°ƒæ¼”ç¤ºç¨‹åº")
    parser.add_argument("--data-dir", default="data/raw", help="æ•°æ®ç›®å½•è·¯å¾„")
    parser.add_argument("--output-dir", default="simple_demo_output", help="è¾“å‡ºç›®å½•è·¯å¾„")
    parser.add_argument("--verbose", "-v", action="store_true", help="è¯¦ç»†è¾“å‡º")
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # åˆ›å»ºæ¼”ç¤ºç¨‹åº
    demo = SimpleFinetuningDemo(output_dir=args.output_dir)
    
    # è¿è¡Œæ¼”ç¤º
    success = demo.run_demo(data_dir=args.data_dir)
    
    if success:
        print("\nğŸ‰ æ¼”ç¤ºç¨‹åºæ‰§è¡ŒæˆåŠŸï¼")
        sys.exit(0)
    else:
        print("\nğŸ’¥ æ¼”ç¤ºç¨‹åºæ‰§è¡Œå¤±è´¥ï¼")
        sys.exit(1)


if __name__ == "__main__":
    main()
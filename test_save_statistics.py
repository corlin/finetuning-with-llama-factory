#!/usr/bin/env python3
"""
ç›´æ¥æµ‹è¯•save_training_statisticsæ–¹æ³•
éªŒè¯JSONåºåˆ—åŒ–ä¿®å¤æ˜¯å¦æœ‰æ•ˆ
"""

import os
import sys
import json
import numpy as np
from datetime import datetime

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.append('src')

def test_save_statistics():
    """æµ‹è¯•ä¿å­˜ç»Ÿè®¡ä¿¡æ¯"""
    print("ğŸ” æµ‹è¯•ä¿å­˜ç»Ÿè®¡ä¿¡æ¯...")
    
    try:
        from direct_finetuning_with_existing_modules import convert_numpy_types
        
        # åˆ›å»ºæ¨¡æ‹Ÿçš„è®­ç»ƒç»Ÿè®¡æ•°æ®ï¼ˆåŒ…å«numpyç±»å‹ï¼‰
        mock_stats = {
            'training_config': {
                'model_name': 'test_model',
                'batch_size': np.int32(4),
                'learning_rate': np.float64(1e-4),
                'use_lora': np.bool_(True),
                'gradient_accumulation_steps': np.int64(8)
            },
            'dataset_stats': {
                'total_samples': np.int64(81),
                'total_batches': np.int32(81),
                'final_training_steps': np.int32(10),
                'average_chinese_quality': np.float64(0.803),
                'average_crypto_complexity': np.float32(2.27),
                'quality_samples': np.int32(81),
                'crypto_samples': np.int32(44)
            },
            'model_stats': {
                'total_parameters': np.int64(4022468096),
                'trainable_parameters': np.int64(495452160)
            },
            'monitoring_stats': {
                'convergence_status': {
                    'is_converged': np.bool_(False),
                    'convergence_score': np.float64(0.75),
                    'loss_trend': np.float32(-0.1),
                    'plateau_steps': np.int32(0),
                    'loss_smoothness': np.float64(0.85)
                },
                'gpu_utilization_summary': {
                    0: {
                        'avg_utilization': np.float32(85.5),
                        'avg_memory_usage': np.float64(78.2),
                        'avg_temperature': np.float32(72.0),
                        'avg_power_usage': np.float32(250.5)
                    },
                    1: {
                        'avg_utilization': np.float32(90.2),
                        'avg_memory_usage': np.float64(82.1),
                        'avg_temperature': np.float32(75.0),
                        'avg_power_usage': np.float32(265.3)
                    }
                },
                'final_metrics': {
                    'epoch': np.int32(1),
                    'global_step': np.int32(10),
                    'train_loss': np.float64(2.345),
                    'val_loss': np.float64(2.123),
                    'learning_rate': np.float64(1e-4),
                    'memory_efficiency': np.float32(0.85),
                    'load_balance_score': np.float64(0.92),
                    'convergence_score': np.float32(0.75),
                    'gradient_norm': np.float64(1.23)
                }
            },
            'training_completed_at': datetime.now().isoformat()
        }
        
        print("âœ… åˆ›å»ºæ¨¡æ‹Ÿç»Ÿè®¡æ•°æ®ï¼ˆåŒ…å«numpyç±»å‹ï¼‰")
        
        # è½¬æ¢numpyç±»å‹
        converted_stats = convert_numpy_types(mock_stats)
        print("âœ… numpyç±»å‹è½¬æ¢å®Œæˆ")
        
        # æµ‹è¯•JSONåºåˆ—åŒ–
        output_dir = "test_output/statistics_test"
        os.makedirs(output_dir, exist_ok=True)
        
        stats_file = os.path.join(output_dir, 'test_training_statistics.json')
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(converted_stats, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜åˆ°: {stats_file}")
        
        # éªŒè¯æ–‡ä»¶å¯ä»¥æ­£å¸¸è¯»å–
        with open(stats_file, 'r', encoding='utf-8') as f:
            loaded_stats = json.load(f)
        
        print("âœ… ç»Ÿè®¡ä¿¡æ¯æ–‡ä»¶è¯»å–æˆåŠŸ")
        
        # éªŒè¯æ•°æ®å®Œæ•´æ€§
        assert loaded_stats['training_config']['batch_size'] == 4
        assert loaded_stats['dataset_stats']['total_samples'] == 81
        assert loaded_stats['monitoring_stats']['convergence_status']['is_converged'] == False
        assert loaded_stats['monitoring_stats']['gpu_utilization_summary']['0']['avg_utilization'] == 85.5
        
        print("âœ… æ•°æ®å®Œæ•´æ€§éªŒè¯é€šè¿‡")
        
        # æ˜¾ç¤ºæ–‡ä»¶å¤§å°
        file_size = os.path.getsize(stats_file)
        print(f"ğŸ“Š ç»Ÿè®¡æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
        
        return True
        
    except Exception as e:
        print(f"âŒ ä¿å­˜ç»Ÿè®¡ä¿¡æ¯æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ¯ æµ‹è¯•ä¿å­˜è®­ç»ƒç»Ÿè®¡ä¿¡æ¯")
    print("=" * 50)
    
    if test_save_statistics():
        print("\nğŸ‰ ä¿å­˜ç»Ÿè®¡ä¿¡æ¯æµ‹è¯•æˆåŠŸï¼")
        print("âœ… JSONåºåˆ—åŒ–ä¿®å¤æœ‰æ•ˆ")
        print("ğŸ’¡ è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç»Ÿè®¡ä¿¡æ¯ä¿å­˜åº”è¯¥ä¸ä¼šå†å‡ºç°JSONåºåˆ—åŒ–é”™è¯¯")
        return True
    else:
        print("\nâŒ ä¿å­˜ç»Ÿè®¡ä¿¡æ¯æµ‹è¯•å¤±è´¥")
        print("âš ï¸ éœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥JSONåºåˆ—åŒ–ä¿®å¤")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
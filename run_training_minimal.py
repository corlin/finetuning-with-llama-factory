#!/usr/bin/env python3
"""
æœ€å°åŒ–é…ç½®çš„ LlamaFactory è®­ç»ƒè„šæœ¬
"""

import os
import sys
import yaml
import subprocess
from pathlib import Path

def create_minimal_config():
    """åˆ›å»ºæœ€å°åŒ–é…ç½®æ–‡ä»¶"""
    config_file = "final_demo_output/configs/llamafactory_config_20250824_212935.yaml"
    minimal_config = "final_demo_output/configs/llamafactory_config_minimal.yaml"
    
    if not os.path.exists(config_file):
        print(f"âŒ åŸé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        return None
    
    # è¯»å–åŸé…ç½®
    with open(config_file, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # åˆ›å»ºæœ€å°åŒ–é…ç½®
    minimal_config_dict = {
        # åŸºæœ¬æ¨¡å‹é…ç½®
        'model_name_or_path': config.get('model_name', 'Qwen/Qwen3-4B-Thinking-2507'),
        'template': config.get('template', 'qwen'),
        
        # æ•°æ®é…ç½®
        'dataset': config.get('dataset', 'crypto_qa_dataset'),
        'cutoff_len': config.get('cutoff_len', 76),
        'val_size': config.get('val_size', 0.1),
        
        # è®­ç»ƒé…ç½®
        'stage': 'sft',
        'do_train': True,
        'finetuning_type': 'lora',
        'lora_target': 'all',
        'lora_rank': 64,
        'lora_alpha': 64,
        'lora_dropout': 0.1,
        
        # è®­ç»ƒå‚æ•°
        'num_train_epochs': 2,
        'per_device_train_batch_size': 2,
        'per_device_eval_batch_size': 2,
        'gradient_accumulation_steps': 2,
        'learning_rate': 0.0002,
        'lr_scheduler_type': 'cosine',
        'warmup_ratio': 0.1,
        'weight_decay': 0.01,
        
        # ä¿å­˜å’Œè¯„ä¼°
        'output_dir': config.get('output_dir', 'final_demo_output/model_output'),
        'save_strategy': 'steps',
        'save_steps': 100,
        'save_total_limit': 3,
        'evaluation_strategy': 'no',  # ç¦ç”¨è¯„ä¼°ä»¥é¿å…é—®é¢˜
        'load_best_model_at_end': False,  # ç¦ç”¨ä»¥é¿å…ç­–ç•¥åŒ¹é…é—®é¢˜
        
        # æ—¥å¿—
        'logging_steps': 10,
        'log_level': 'info',
        'plot_loss': True,
        
        # ç³»ç»Ÿé…ç½®
        'dataloader_num_workers': 0,  # Windows å…¼å®¹
        'bf16': True,
        'tf32': True,
        'seed': 42,
        'overwrite_output_dir': True,
    }
    
    # ä¿å­˜æœ€å°åŒ–é…ç½®
    os.makedirs(os.path.dirname(minimal_config), exist_ok=True)
    with open(minimal_config, 'w', encoding='utf-8') as f:
        yaml.dump(minimal_config_dict, f, default_flow_style=False, allow_unicode=True)
    
    print(f"âœ… åˆ›å»ºæœ€å°åŒ–é…ç½®æ–‡ä»¶: {minimal_config}")
    return minimal_config

def run_training():
    """è¿è¡Œè®­ç»ƒ"""
    print("ğŸš€ å¼€å§‹ä½¿ç”¨æœ€å°åŒ–é…ç½®è®­ç»ƒ...")
    
    # åˆ›å»ºæœ€å°åŒ–é…ç½®
    config_file = create_minimal_config()
    if not config_file:
        return False
    
    print(f"ğŸ“‹ ä½¿ç”¨é…ç½®æ–‡ä»¶: {config_file}")
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    env = os.environ.copy()
    env["DATASET_INFO_FILE"] = "final_demo_output/data/dataset_info.json"
    env["USE_LIBUV"] = "0"  # ç¦ç”¨ libuv æ”¯æŒ
    env["CUDA_VISIBLE_DEVICES"] = "0"  # åªä½¿ç”¨ç¬¬ä¸€ä¸ª GPU
    env["OMP_NUM_THREADS"] = "1"   # è®¾ç½® OpenMP çº¿ç¨‹æ•°
    
    # æ„å»ºå‘½ä»¤
    cmd = ["uv", "run", "llamafactory-cli", "train", config_file]
    
    print(f"ğŸ”§ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
    
    try:
        # è¿è¡Œè®­ç»ƒ
        result = subprocess.run(
            cmd,
            env=env,
            cwd=os.getcwd(),
            capture_output=False,
            text=True
        )
        
        if result.returncode == 0:
            print("âœ… è®­ç»ƒå®Œæˆ!")
            return True
        else:
            print(f"âŒ è®­ç»ƒå¤±è´¥ï¼Œé€€å‡ºç : {result.returncode}")
            return False
            
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        return False

def check_environment():
    """æ£€æŸ¥ç¯å¢ƒ"""
    print("ğŸ” æ£€æŸ¥ç¯å¢ƒ...")
    
    # æ£€æŸ¥ uv
    try:
        result = subprocess.run(["uv", "--version"], capture_output=True, text=True)
        if result.returncode == 0:
            print(f"âœ… uv ç‰ˆæœ¬: {result.stdout.strip()}")
        else:
            print("âŒ uv æœªå®‰è£…")
            return False
    except:
        print("âŒ uv æœªå®‰è£…")
        return False
    
    # æ£€æŸ¥ LlamaFactory
    try:
        result = subprocess.run(
            ["uv", "run", "python", "-c", "import llamafactory; print(llamafactory.__version__)"],
            capture_output=True, text=True
        )
        if result.returncode == 0:
            print(f"âœ… LlamaFactory ç‰ˆæœ¬: {result.stdout.strip()}")
        else:
            print("âŒ LlamaFactory å¯¼å…¥å¤±è´¥")
            return False
    except:
        print("âŒ LlamaFactory æ£€æŸ¥å¤±è´¥")
        return False
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ LlamaFactory æœ€å°åŒ–é…ç½®è®­ç»ƒå¯åŠ¨å™¨")
    print("=" * 50)
    
    # æ£€æŸ¥ç¯å¢ƒ
    if not check_environment():
        print("âŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥")
        return False
    
    # è¿è¡Œè®­ç»ƒ
    return run_training()

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
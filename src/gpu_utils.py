"""
GPUæ£€æµ‹å’ŒéªŒè¯åŠŸèƒ½æ¨¡å—
é’ˆå¯¹Qwen3-4Bæ¨¡å‹å†…å­˜éœ€æ±‚ä¼˜åŒ–çš„GPUç®¡ç†å·¥å…·
æ”¯æŒGPUæ‹“æ‰‘æ£€æµ‹ã€äº’è”å¸¦å®½åˆ†æå’ŒNUMAæ‹“æ‰‘æ£€æµ‹
"""

import torch
import psutil
import logging
import subprocess
import platform
import re
from typing import Dict, List, Optional, Tuple, Set
from dataclasses import dataclass, field
from pathlib import Path
from enum import Enum

try:
    import pynvml
    PYNVML_AVAILABLE = True
except ImportError:
    PYNVML_AVAILABLE = False
    logging.warning("pynvml not available, GPU monitoring will be limited")

# å°è¯•å¯¼å…¥numaåº“ï¼ˆä¸»è¦åœ¨Linuxç³»ç»Ÿä¸Šå¯ç”¨ï¼‰
NUMA_AVAILABLE = False
LIBNUMA_AVAILABLE = False

# åªåœ¨Linuxç³»ç»Ÿä¸Šå°è¯•å¯¼å…¥numaåº“
if platform.system() == "Linux":
    try:
        import numa
        NUMA_AVAILABLE = True
        LIBNUMA_AVAILABLE = True
    except ImportError:
        pass
    except Exception as e:
        # å¤„ç†å…¶ä»–å¯¼å…¥é”™è¯¯ï¼ˆå¦‚åº“ä¾èµ–é—®é¢˜ï¼‰
        logging.debug(f"numaåº“å¯¼å…¥å¤±è´¥: {e}")

# å¦‚æœnumaåº“ä¸å¯ç”¨ï¼Œè®°å½•è­¦å‘Šï¼ˆä½†è¿™åœ¨Windowsä¸Šæ˜¯æ­£å¸¸çš„ï¼‰
if not NUMA_AVAILABLE and platform.system() == "Linux":
    logging.warning("numa library not available on Linux, NUMA topology detection will be limited")
elif not NUMA_AVAILABLE and platform.system() != "Linux":
    logging.info("numa library not available on non-Linux system, this is expected")


class InterconnectType(Enum):
    """GPUäº’è”ç±»å‹æšä¸¾"""
    NVLINK = "NVLink"
    PCIE = "PCIe"
    NVSWITCH = "NVSwitch"
    UNKNOWN = "Unknown"


@dataclass
class GPUInfo:
    """GPUä¿¡æ¯æ•°æ®ç±»"""
    gpu_id: int
    name: str
    total_memory: int  # MB
    free_memory: int   # MB
    used_memory: int   # MB
    utilization: float # ç™¾åˆ†æ¯”
    temperature: Optional[int] = None
    power_usage: Optional[int] = None
    # æ–°å¢æ‹“æ‰‘ç›¸å…³å­—æ®µ
    pci_bus_id: Optional[str] = None
    numa_node: Optional[int] = None
    compute_capability: Optional[Tuple[int, int]] = None
    multi_processor_count: Optional[int] = None
    max_threads_per_block: Optional[int] = None


@dataclass
class GPUInterconnect:
    """GPUäº’è”ä¿¡æ¯"""
    gpu_a: int
    gpu_b: int
    interconnect_type: InterconnectType
    bandwidth_gbps: float
    bidirectional: bool = True
    link_count: Optional[int] = None


@dataclass
class GPUTopology:
    """GPUæ‹“æ‰‘ç»“æ„ä¿¡æ¯"""
    num_gpus: int
    gpu_info: Dict[int, GPUInfo] = field(default_factory=dict)
    interconnects: List[GPUInterconnect] = field(default_factory=list)
    numa_topology: Dict[int, int] = field(default_factory=dict)  # gpu_id -> numa_node
    bandwidth_matrix: Dict[Tuple[int, int], float] = field(default_factory=dict)
    topology_type: str = "Unknown"  # "Single", "NVLink", "PCIe", "Mixed"
    
    def get_bandwidth(self, gpu_a: int, gpu_b: int) -> float:
        """è·å–ä¸¤ä¸ªGPUä¹‹é—´çš„å¸¦å®½"""
        key = (min(gpu_a, gpu_b), max(gpu_a, gpu_b))
        return self.bandwidth_matrix.get(key, 0.0)
    
    def get_numa_distance(self, gpu_a: int, gpu_b: int) -> int:
        """è·å–ä¸¤ä¸ªGPUä¹‹é—´çš„NUMAè·ç¦»"""
        numa_a = self.numa_topology.get(gpu_a, -1)
        numa_b = self.numa_topology.get(gpu_b, -1)
        
        if numa_a == -1 or numa_b == -1:
            return -1  # æœªçŸ¥
        
        if numa_a == numa_b:
            return 0  # åŒä¸€NUMAèŠ‚ç‚¹
        else:
            return 1  # ä¸åŒNUMAèŠ‚ç‚¹ï¼Œç®€åŒ–ä¸ºè·ç¦»1
    
    def get_optimal_gpu_pairs(self) -> List[Tuple[int, int]]:
        """è·å–æœ€ä¼˜çš„GPUé…å¯¹ï¼ˆåŸºäºå¸¦å®½å’ŒNUMAè·ç¦»ï¼‰"""
        pairs = []
        gpus = list(self.gpu_info.keys())
        
        # æŒ‰å¸¦å®½æ’åºæ‰€æœ‰GPUå¯¹
        gpu_pairs = []
        for i in range(len(gpus)):
            for j in range(i + 1, len(gpus)):
                gpu_a, gpu_b = gpus[i], gpus[j]
                bandwidth = self.get_bandwidth(gpu_a, gpu_b)
                numa_distance = self.get_numa_distance(gpu_a, gpu_b)
                # ä¼˜å…ˆçº§ï¼šå¸¦å®½é«˜ï¼ŒNUMAè·ç¦»å°
                priority = bandwidth * 1000 - numa_distance * 100
                gpu_pairs.append((gpu_a, gpu_b, priority))
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        gpu_pairs.sort(key=lambda x: x[2], reverse=True)
        return [(pair[0], pair[1]) for pair in gpu_pairs]


@dataclass
class SystemRequirements:
    """Qwen3-4Bæ¨¡å‹ç³»ç»Ÿéœ€æ±‚"""
    min_gpu_memory: int = 8192  # MB, æœ€å°8GB
    recommended_gpu_memory: int = 16384  # MB, æ¨è16GB
    min_system_memory: int = 16384  # MB, æœ€å°16GBç³»ç»Ÿå†…å­˜
    min_python_version: Tuple[int, int] = (3, 12)
    required_cuda_version: str = "12.9"
    # æ–°å¢ç¡¬ä»¶å…¼å®¹æ€§éœ€æ±‚
    min_compute_capability: Tuple[int, int] = (7, 0)  # æœ€å°è®¡ç®—èƒ½åŠ›7.0
    recommended_compute_capability: Tuple[int, int] = (8, 0)  # æ¨è8.0+
    min_nvlink_bandwidth: float = 25.0  # GB/s, NVLinkæœ€å°å¸¦å®½
    min_pcie_bandwidth: float = 16.0  # GB/s, PCIeæœ€å°å¸¦å®½
    max_numa_distance: int = 1  # æœ€å¤§NUMAè·ç¦»


@dataclass
class HardwareCompatibility:
    """ç¡¬ä»¶å…¼å®¹æ€§æ£€æŸ¥ç»“æœ"""
    is_compatible: bool
    compatibility_score: float  # 0-100åˆ†
    issues: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    recommendations: List[str] = field(default_factory=list)
    
    def add_issue(self, issue: str):
        """æ·»åŠ å…¼å®¹æ€§é—®é¢˜"""
        self.issues.append(issue)
        self.is_compatible = False
    
    def add_warning(self, warning: str):
        """æ·»åŠ è­¦å‘Š"""
        self.warnings.append(warning)
    
    def add_recommendation(self, recommendation: str):
        """æ·»åŠ å»ºè®®"""
        self.recommendations.append(recommendation)


class GPUDetector:
    """GPUæ£€æµ‹å’ŒéªŒè¯ç±»ï¼Œæ”¯æŒæ‹“æ‰‘æ£€æµ‹å’Œç¡¬ä»¶å…¼å®¹æ€§æ£€æŸ¥"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.requirements = SystemRequirements()
        self._initialize_pynvml()
        self._topology_cache: Optional[GPUTopology] = None
    
    def _initialize_pynvml(self) -> None:
        """åˆå§‹åŒ–NVIDIAç®¡ç†åº“"""
        if PYNVML_AVAILABLE:
            try:
                pynvml.nvmlInit()
                self.logger.info("NVIDIAç®¡ç†åº“åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                self.logger.warning(f"NVIDIAç®¡ç†åº“åˆå§‹åŒ–å¤±è´¥: {e}")
                globals()['PYNVML_AVAILABLE'] = False
    
    def detect_cuda_availability(self) -> bool:
        """æ£€æµ‹CUDAå¯ç”¨æ€§"""
        try:
            cuda_available = torch.cuda.is_available()
            if cuda_available:
                cuda_version = torch.version.cuda
                device_count = torch.cuda.device_count()
                self.logger.info(f"CUDAå¯ç”¨: ç‰ˆæœ¬ {cuda_version}, è®¾å¤‡æ•°é‡: {device_count}")
                return True
            else:
                self.logger.error("CUDAä¸å¯ç”¨")
                return False
        except Exception as e:
            self.logger.error(f"CUDAæ£€æµ‹å¤±è´¥: {e}")
            return False
    
    def get_gpu_info(self, gpu_id: int = 0) -> Optional[GPUInfo]:
        """è·å–æŒ‡å®šGPUä¿¡æ¯ï¼ŒåŒ…å«æ‹“æ‰‘ç›¸å…³ä¿¡æ¯"""
        try:
            if not torch.cuda.is_available():
                return None
            
            device = torch.device(f'cuda:{gpu_id}')
            props = torch.cuda.get_device_properties(device)
            
            # è·å–å†…å­˜ä¿¡æ¯
            total_memory = torch.cuda.get_device_properties(gpu_id).total_memory // (1024**2)
            torch.cuda.empty_cache()  # æ¸…ç†ç¼“å­˜ä»¥è·å¾—å‡†ç¡®çš„ç©ºé—²å†…å­˜
            free_memory = (torch.cuda.get_device_properties(gpu_id).total_memory - 
                          torch.cuda.memory_allocated(gpu_id)) // (1024**2)
            used_memory = total_memory - free_memory
            
            gpu_info = GPUInfo(
                gpu_id=gpu_id,
                name=props.name,
                total_memory=total_memory,
                free_memory=free_memory,
                used_memory=used_memory,
                utilization=0.0,  # PyTorchä¸ç›´æ¥æä¾›åˆ©ç”¨ç‡
                compute_capability=(props.major, props.minor),
                multi_processor_count=props.multi_processor_count,
                max_threads_per_block=getattr(props, 'max_threads_per_block', None)
            )
            
            # å¦‚æœpynvmlå¯ç”¨ï¼Œè·å–æ›´è¯¦ç»†ä¿¡æ¯
            if PYNVML_AVAILABLE:
                try:
                    handle = pynvml.nvmlDeviceGetHandleByIndex(gpu_id)
                    util = pynvml.nvmlDeviceGetUtilizationRates(handle)
                    temp = pynvml.nvmlDeviceGetTemperature(handle, pynvml.NVML_TEMPERATURE_GPU)
                    power = pynvml.nvmlDeviceGetPowerUsage(handle) // 1000  # mW to W
                    
                    # è·å–PCIæ€»çº¿ID
                    pci_info = pynvml.nvmlDeviceGetPciInfo(handle)
                    if hasattr(pci_info.busId, 'decode'):
                        gpu_info.pci_bus_id = pci_info.busId.decode('utf-8')
                    else:
                        gpu_info.pci_bus_id = str(pci_info.busId)
                    
                    gpu_info.utilization = util.gpu
                    gpu_info.temperature = temp
                    gpu_info.power_usage = power
                except Exception as e:
                    self.logger.warning(f"è·å–GPUè¯¦ç»†ä¿¡æ¯å¤±è´¥: {e}")
            
            # è·å–NUMAèŠ‚ç‚¹ä¿¡æ¯
            gpu_info.numa_node = self._get_gpu_numa_node(gpu_id)
            
            return gpu_info
            
        except Exception as e:
            self.logger.error(f"è·å–GPUä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def get_all_gpu_info(self) -> List[GPUInfo]:
        """è·å–æ‰€æœ‰GPUä¿¡æ¯"""
        gpu_infos = []
        if not torch.cuda.is_available():
            return gpu_infos
        
        device_count = torch.cuda.device_count()
        for i in range(device_count):
            gpu_info = self.get_gpu_info(i)
            if gpu_info:
                gpu_infos.append(gpu_info)
        
        return gpu_infos
    
    def validate_qwen_requirements(self, gpu_id: int = 0) -> Dict[str, bool]:
        """éªŒè¯Qwen3-4Bæ¨¡å‹è¿è¡Œéœ€æ±‚"""
        validation_results = {
            "cuda_available": False,
            "sufficient_gpu_memory": False,
            "sufficient_system_memory": False,
            "python_version_ok": False,
            "recommended_setup": False
        }
        
        # æ£€æŸ¥CUDA
        validation_results["cuda_available"] = self.detect_cuda_availability()
        
        # æ£€æŸ¥GPUå†…å­˜
        gpu_info = self.get_gpu_info(gpu_id)
        if gpu_info:
            validation_results["sufficient_gpu_memory"] = (
                gpu_info.free_memory >= self.requirements.min_gpu_memory
            )
            validation_results["recommended_setup"] = (
                gpu_info.total_memory >= self.requirements.recommended_gpu_memory
            )
        
        # æ£€æŸ¥ç³»ç»Ÿå†…å­˜
        system_memory = psutil.virtual_memory().total // (1024**2)  # MB
        validation_results["sufficient_system_memory"] = (
            system_memory >= self.requirements.min_system_memory
        )
        
        # æ£€æŸ¥Pythonç‰ˆæœ¬
        import sys
        python_version = sys.version_info[:2]
        validation_results["python_version_ok"] = (
            python_version >= self.requirements.min_python_version
        )
        
        return validation_results
    
    def get_optimization_recommendations(self, gpu_id: int = 0) -> List[str]:
        """è·å–é’ˆå¯¹Qwen3-4Bæ¨¡å‹çš„ä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        gpu_info = self.get_gpu_info(gpu_id)
        if not gpu_info:
            recommendations.append("æ— æ³•æ£€æµ‹åˆ°GPUï¼Œå»ºè®®æ£€æŸ¥CUDAå®‰è£…")
            return recommendations
        
        # å†…å­˜ä¼˜åŒ–å»ºè®®
        if gpu_info.total_memory < self.requirements.recommended_gpu_memory:
            recommendations.append(
                f"GPUå†…å­˜ ({gpu_info.total_memory}MB) ä½äºæ¨èå€¼ "
                f"({self.requirements.recommended_gpu_memory}MB)ï¼Œå»ºè®®å¯ç”¨ä»¥ä¸‹ä¼˜åŒ–ï¼š"
            )
            recommendations.append("- å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ (gradient_checkpointing=True)")
            recommendations.append("- ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (fp16=True)")
            recommendations.append("- å‡å°æ‰¹æ¬¡å¤§å° (batch_size=1-2)")
            recommendations.append("- å¯ç”¨LoRAå¾®è°ƒä»¥å‡å°‘å‚æ•°é‡")
        
        if gpu_info.total_memory >= self.requirements.recommended_gpu_memory:
            recommendations.append("GPUå†…å­˜å……è¶³ï¼Œå¯ä»¥ä½¿ç”¨æ ‡å‡†é…ç½®è¿›è¡Œè®­ç»ƒ")
            recommendations.append("- å¯ä»¥ä½¿ç”¨è¾ƒå¤§çš„æ‰¹æ¬¡å¤§å° (batch_size=4-8)")
            recommendations.append("- å¯ä»¥è€ƒè™‘å…¨å‚æ•°å¾®è°ƒ")
        
        # å¤šGPUå»ºè®®
        gpu_count = torch.cuda.device_count()
        if gpu_count > 1:
            total_memory = sum(self.get_gpu_info(i).total_memory for i in range(gpu_count))
            recommendations.append(f"æ£€æµ‹åˆ° {gpu_count} ä¸ªGPUï¼Œæ€»å†…å­˜ {total_memory}MB")
            recommendations.append("- å»ºè®®å¯ç”¨æ•°æ®å¹¶è¡Œè®­ç»ƒ")
            recommendations.append("- å¯ä»¥è€ƒè™‘æ¨¡å‹å¹¶è¡Œä»¥å¤„ç†æ›´å¤§çš„æ¨¡å‹")
        
        return recommendations
    
    def generate_system_report(self) -> str:
        """ç”Ÿæˆç³»ç»Ÿç¯å¢ƒæŠ¥å‘Š"""
        report_lines = []
        report_lines.append("=== Qwen3-4B-Thinking ç³»ç»Ÿç¯å¢ƒæŠ¥å‘Š ===")
        report_lines.append("")
        
        # åŸºæœ¬ä¿¡æ¯
        import sys
        report_lines.append(f"Pythonç‰ˆæœ¬: {sys.version}")
        report_lines.append(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
        
        if torch.cuda.is_available():
            report_lines.append(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
            report_lines.append(f"cuDNNç‰ˆæœ¬: {torch.backends.cudnn.version()}")
        
        # ç³»ç»Ÿå†…å­˜
        memory = psutil.virtual_memory()
        report_lines.append(f"ç³»ç»Ÿå†…å­˜: {memory.total // (1024**3)}GB "
                          f"(å¯ç”¨: {memory.available // (1024**3)}GB)")
        
        # GPUä¿¡æ¯
        gpu_infos = self.get_all_gpu_info()
        if gpu_infos:
            report_lines.append("")
            report_lines.append("GPUä¿¡æ¯:")
            for gpu_info in gpu_infos:
                report_lines.append(f"  GPU {gpu_info.gpu_id}: {gpu_info.name}")
                report_lines.append(f"    æ€»å†…å­˜: {gpu_info.total_memory}MB")
                report_lines.append(f"    å¯ç”¨å†…å­˜: {gpu_info.free_memory}MB")
                if gpu_info.utilization is not None:
                    report_lines.append(f"    åˆ©ç”¨ç‡: {gpu_info.utilization}%")
                if gpu_info.temperature is not None:
                    report_lines.append(f"    æ¸©åº¦: {gpu_info.temperature}Â°C")
        else:
            report_lines.append("æœªæ£€æµ‹åˆ°å¯ç”¨GPU")
        
        # éœ€æ±‚éªŒè¯
        validation = self.validate_qwen_requirements()
        report_lines.append("")
        report_lines.append("Qwen3-4Béœ€æ±‚éªŒè¯:")
        for requirement, passed in validation.items():
            status = "âœ“" if passed else "âœ—"
            report_lines.append(f"  {status} {requirement}")
        
        # NUMAæ‹“æ‰‘ä¿¡æ¯
        numa_info = self.get_numa_topology_info()
        report_lines.append("")
        report_lines.append("NUMAæ‹“æ‰‘ä¿¡æ¯:")
        report_lines.append(f"  NUMAåº“å¯ç”¨: {'æ˜¯' if numa_info['numa_available'] else 'å¦'}")
        if numa_info["numa_nodes"]:
            report_lines.append(f"  NUMAèŠ‚ç‚¹: {numa_info['numa_nodes']}")
            for node_id, memory in numa_info["memory_per_node"].items():
                memory_gb = memory // (1024**3) if memory else "æœªçŸ¥"
                report_lines.append(f"    èŠ‚ç‚¹{node_id}: {memory_gb}GBå†…å­˜")
        else:
            report_lines.append("  æœªæ£€æµ‹åˆ°NUMAèŠ‚ç‚¹ä¿¡æ¯")
        
        # GPUæ‹“æ‰‘ä¿¡æ¯
        topology = self.detect_gpu_topology()
        if topology.num_gpus > 1:
            report_lines.append("")
            report_lines.append("GPUæ‹“æ‰‘ä¿¡æ¯:")
            report_lines.append(f"  æ‹“æ‰‘ç±»å‹: {topology.topology_type}")
            if topology.numa_topology:
                report_lines.append("  GPU NUMAåˆ†å¸ƒ:")
                for gpu_id, numa_node in topology.numa_topology.items():
                    report_lines.append(f"    GPU {gpu_id} -> NUMAèŠ‚ç‚¹ {numa_node}")
            
            if topology.interconnects:
                report_lines.append("  GPUäº’è”:")
                for ic in topology.interconnects:
                    report_lines.append(f"    GPU {ic.gpu_a} <-> GPU {ic.gpu_b}: "
                                      f"{ic.interconnect_type.value} ({ic.bandwidth_gbps:.1f} GB/s)")
        
        # ä¼˜åŒ–å»ºè®®
        recommendations = self.get_optimization_recommendations()
        if recommendations:
            report_lines.append("")
            report_lines.append("ä¼˜åŒ–å»ºè®®:")
            for rec in recommendations:
                report_lines.append(f"  {rec}")
        
        return "\n".join(report_lines)
    
    def _get_gpu_numa_node(self, gpu_id: int) -> Optional[int]:
        """è·å–GPUæ‰€åœ¨çš„NUMAèŠ‚ç‚¹ï¼Œæ”¯æŒå¤šç§æ£€æµ‹æ–¹æ³•"""
        try:
            if platform.system() != "Linux":
                return None
            
            # æ–¹æ³•1: ä½¿ç”¨numaåº“
            if NUMA_AVAILABLE:
                try:
                    # è·å–å½“å‰è¿›ç¨‹çš„NUMAèŠ‚ç‚¹
                    current_node = numa.get_mempolicy()[1]
                    if current_node is not None and len(current_node) > 0:
                        return list(current_node)[0]
                except Exception as e:
                    self.logger.debug(f"numaåº“æ£€æµ‹å¤±è´¥: {e}")
            
            # æ–¹æ³•2: ä½¿ç”¨numaåº“çš„å…¶ä»–åŠŸèƒ½
            if NUMA_AVAILABLE:
                try:
                    # å°è¯•è·å–NUMAèŠ‚ç‚¹ä¿¡æ¯
                    from numa import info
                    numa_nodes = info.numa_hardware_info()
                    if numa_nodes:
                        # ç®€åŒ–å¤„ç†ï¼šæ ¹æ®GPU IDåˆ†é…NUMAèŠ‚ç‚¹
                        return gpu_id % len(numa_nodes.get('nodes', [0]))
                except Exception as e:
                    self.logger.debug(f"numa infoæ£€æµ‹å¤±è´¥: {e}")
            
            # æ–¹æ³•3: é€šè¿‡nvidia-ml-pyè·å–PCIæ€»çº¿IDå¹¶æŸ¥è¯¢sysfs
            if PYNVML_AVAILABLE:
                handle = pynvml.nvmlDeviceGetHandleByIndex(gpu_id)
                pci_info = pynvml.nvmlDeviceGetPciInfo(handle)
                if hasattr(pci_info.busId, 'decode'):
                    pci_bus_id = pci_info.busId.decode('utf-8')
                else:
                    pci_bus_id = str(pci_info.busId)
                
                # å°è¯•å¤šç§PCIè·¯å¾„æ ¼å¼
                possible_paths = [
                    f"/sys/bus/pci/devices/0000:{pci_bus_id}/numa_node",
                    f"/sys/bus/pci/devices/{pci_bus_id}/numa_node",
                    f"/sys/class/pci_bus/0000:{pci_bus_id.split(':')[0]}/device/numa_node"
                ]
                
                for numa_path in possible_paths:
                    if Path(numa_path).exists():
                        try:
                            with open(numa_path, 'r') as f:
                                numa_node = int(f.read().strip())
                                return numa_node if numa_node >= 0 else None
                        except (ValueError, IOError):
                            continue
            
            # æ–¹æ³•4: é€šè¿‡/proc/cpuinfoå’ŒGPUäº²å’Œæ€§æ¨æ–­
            return self._infer_numa_from_cpu_affinity(gpu_id)
            
        except Exception as e:
            self.logger.debug(f"è·å–GPU NUMAèŠ‚ç‚¹å¤±è´¥: {e}")
            return None
    
    def _infer_numa_from_cpu_affinity(self, gpu_id: int) -> Optional[int]:
        """é€šè¿‡CPUäº²å’Œæ€§æ¨æ–­NUMAèŠ‚ç‚¹"""
        try:
            # æ£€æŸ¥/proc/cpuinfoè·å–NUMAä¿¡æ¯
            numa_nodes = set()
            with open('/proc/cpuinfo', 'r') as f:
                for line in f:
                    if 'physical id' in line:
                        numa_nodes.add(int(line.split(':')[1].strip()))
            
            if numa_nodes:
                # ç®€åŒ–å¤„ç†ï¼šæ ¹æ®GPU IDåˆ†é…åˆ°ä¸åŒNUMAèŠ‚ç‚¹
                return gpu_id % len(numa_nodes)
            
            return None
        except Exception:
            return None
    
    def get_numa_topology_info(self) -> Dict[str, any]:
        """è·å–ç³»ç»ŸNUMAæ‹“æ‰‘ä¿¡æ¯"""
        numa_info = {
            "numa_available": NUMA_AVAILABLE or LIBNUMA_AVAILABLE,
            "numa_nodes": [],
            "memory_per_node": {},
            "cpu_per_node": {},
            "distances": {}
        }
        
        try:
            if NUMA_AVAILABLE:
                # ä½¿ç”¨numaåº“è·å–è¯¦ç»†ä¿¡æ¯
                try:
                    numa_info["numa_nodes"] = list(range(numa.get_max_node() + 1))
                    for node in numa_info["numa_nodes"]:
                        numa_info["memory_per_node"][node] = numa.node_memsize(node)
                except Exception as e:
                    self.logger.debug(f"numaåº“è·å–æ‹“æ‰‘ä¿¡æ¯å¤±è´¥: {e}")
            
            elif NUMA_AVAILABLE:
                # ä½¿ç”¨numaåº“çš„infoæ¨¡å—è·å–ä¿¡æ¯
                try:
                    from numa import info
                    hardware_info = info.numa_hardware_info()
                    if hardware_info and 'nodes' in hardware_info:
                        numa_info["numa_nodes"] = list(hardware_info['nodes'].keys())
                        for node_id in numa_info["numa_nodes"]:
                            # å°è¯•è·å–å†…å­˜ä¿¡æ¯
                            try:
                                from numa import memory
                                # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…å¯èƒ½éœ€è¦æ›´å¤æ‚çš„é€»è¾‘
                                numa_info["memory_per_node"][node_id] = "æœªçŸ¥"
                            except Exception:
                                pass
                except Exception as e:
                    self.logger.debug(f"numa infoè·å–æ‹“æ‰‘ä¿¡æ¯å¤±è´¥: {e}")
            
            else:
                # ä»/sys/devices/system/node/è¯»å–NUMAä¿¡æ¯
                node_path = Path("/sys/devices/system/node")
                if node_path.exists():
                    numa_dirs = [d for d in node_path.iterdir() 
                               if d.is_dir() and d.name.startswith('node')]
                    numa_info["numa_nodes"] = [int(d.name[4:]) for d in numa_dirs]
                    
                    for node_id in numa_info["numa_nodes"]:
                        # è¯»å–å†…å­˜ä¿¡æ¯
                        meminfo_path = node_path / f"node{node_id}" / "meminfo"
                        if meminfo_path.exists():
                            try:
                                with open(meminfo_path, 'r') as f:
                                    for line in f:
                                        if 'MemTotal:' in line:
                                            memory_kb = int(line.split()[3])
                                            numa_info["memory_per_node"][node_id] = memory_kb * 1024
                                            break
                            except Exception:
                                pass
        
        except Exception as e:
            self.logger.debug(f"è·å–NUMAæ‹“æ‰‘ä¿¡æ¯å¤±è´¥: {e}")
        
        return numa_info
    
    def detect_gpu_topology(self) -> GPUTopology:
        """æ£€æµ‹GPUæ‹“æ‰‘ç»“æ„"""
        if self._topology_cache is not None:
            return self._topology_cache
        
        try:
            if not torch.cuda.is_available():
                return GPUTopology(num_gpus=0)
            
            num_gpus = torch.cuda.device_count()
            topology = GPUTopology(num_gpus=num_gpus)
            
            # è·å–æ‰€æœ‰GPUä¿¡æ¯
            for i in range(num_gpus):
                gpu_info = self.get_gpu_info(i)
                if gpu_info:
                    topology.gpu_info[i] = gpu_info
                    if gpu_info.numa_node is not None:
                        topology.numa_topology[i] = gpu_info.numa_node
            
            # æ£€æµ‹GPUäº’è”
            topology.interconnects = self._detect_gpu_interconnects(num_gpus)
            
            # æ„å»ºå¸¦å®½çŸ©é˜µ
            topology.bandwidth_matrix = self._build_bandwidth_matrix(topology.interconnects)
            
            # ç¡®å®šæ‹“æ‰‘ç±»å‹
            topology.topology_type = self._determine_topology_type(topology.interconnects)
            
            self._topology_cache = topology
            return topology
            
        except Exception as e:
            self.logger.error(f"æ£€æµ‹GPUæ‹“æ‰‘å¤±è´¥: {e}")
            return GPUTopology(num_gpus=0)
    
    def _detect_gpu_interconnects(self, num_gpus: int) -> List[GPUInterconnect]:
        """æ£€æµ‹GPUä¹‹é—´çš„äº’è”"""
        interconnects = []
        
        try:
            if not PYNVML_AVAILABLE or num_gpus < 2:
                return interconnects
            
            for i in range(num_gpus):
                for j in range(i + 1, num_gpus):
                    interconnect = self._detect_gpu_pair_interconnect(i, j)
                    if interconnect:
                        interconnects.append(interconnect)
            
            return interconnects
            
        except Exception as e:
            self.logger.error(f"æ£€æµ‹GPUäº’è”å¤±è´¥: {e}")
            return interconnects
    
    def _detect_gpu_pair_interconnect(self, gpu_a: int, gpu_b: int) -> Optional[GPUInterconnect]:
        """æ£€æµ‹ä¸¤ä¸ªGPUä¹‹é—´çš„äº’è”ç±»å‹å’Œå¸¦å®½"""
        try:
            if not PYNVML_AVAILABLE:
                return None
            
            handle_a = pynvml.nvmlDeviceGetHandleByIndex(gpu_a)
            handle_b = pynvml.nvmlDeviceGetHandleByIndex(gpu_b)
            
            # æ£€æŸ¥NVLinkè¿æ¥
            try:
                # å°è¯•è·å–NVLinkçŠ¶æ€
                nvlink_bandwidth = 0.0
                nvlink_count = 0
                
                # æ£€æŸ¥æ‰€æœ‰å¯èƒ½çš„NVLinkç«¯å£
                for link_id in range(6):  # å¤§å¤šæ•°GPUæœ€å¤š6ä¸ªNVLinkç«¯å£
                    try:
                        # æ£€æŸ¥ä»gpu_aåˆ°gpu_bçš„NVLink
                        remote_info = pynvml.nvmlDeviceGetNvLinkRemotePciInfo(handle_a, link_id)
                        if hasattr(remote_info.busId, 'decode'):
                            remote_pci = remote_info.busId.decode('utf-8')
                        else:
                            remote_pci = str(remote_info.busId)
                        
                        # è·å–gpu_bçš„PCIä¿¡æ¯è¿›è¡Œæ¯”è¾ƒ
                        pci_info_b = pynvml.nvmlDeviceGetPciInfo(handle_b)
                        if hasattr(pci_info_b.busId, 'decode'):
                            pci_b = pci_info_b.busId.decode('utf-8')
                        else:
                            pci_b = str(pci_info_b.busId)
                        
                        if remote_pci == pci_b:
                            # æ‰¾åˆ°NVLinkè¿æ¥
                            nvlink_count += 1
                            # å‡è®¾æ¯ä¸ªNVLink 3.0è¿æ¥æä¾›25GB/så¸¦å®½
                            nvlink_bandwidth += 25.0
                    except:
                        continue
                
                if nvlink_count > 0:
                    return GPUInterconnect(
                        gpu_a=gpu_a,
                        gpu_b=gpu_b,
                        interconnect_type=InterconnectType.NVLINK,
                        bandwidth_gbps=nvlink_bandwidth,
                        link_count=nvlink_count
                    )
            except:
                pass
            
            # å¦‚æœæ²¡æœ‰NVLinkï¼Œå‡è®¾æ˜¯PCIeè¿æ¥
            # ä¼°ç®—PCIeå¸¦å®½ï¼ˆç®€åŒ–å¤„ç†ï¼‰
            pcie_bandwidth = 16.0  # PCIe 4.0 x16çš„ç†è®ºå¸¦å®½
            
            return GPUInterconnect(
                gpu_a=gpu_a,
                gpu_b=gpu_b,
                interconnect_type=InterconnectType.PCIE,
                bandwidth_gbps=pcie_bandwidth
            )
            
        except Exception as e:
            self.logger.debug(f"æ£€æµ‹GPU {gpu_a}-{gpu_b}äº’è”å¤±è´¥: {e}")
            return None
    
    def _build_bandwidth_matrix(self, interconnects: List[GPUInterconnect]) -> Dict[Tuple[int, int], float]:
        """æ„å»ºå¸¦å®½çŸ©é˜µ"""
        bandwidth_matrix = {}
        
        for interconnect in interconnects:
            key = (min(interconnect.gpu_a, interconnect.gpu_b), 
                   max(interconnect.gpu_a, interconnect.gpu_b))
            bandwidth_matrix[key] = interconnect.bandwidth_gbps
        
        return bandwidth_matrix
    
    def _determine_topology_type(self, interconnects: List[GPUInterconnect]) -> str:
        """ç¡®å®šæ‹“æ‰‘ç±»å‹"""
        if not interconnects:
            return "Single"
        
        nvlink_count = sum(1 for ic in interconnects if ic.interconnect_type == InterconnectType.NVLINK)
        pcie_count = sum(1 for ic in interconnects if ic.interconnect_type == InterconnectType.PCIE)
        
        if nvlink_count > 0 and pcie_count == 0:
            return "NVLink"
        elif pcie_count > 0 and nvlink_count == 0:
            return "PCIe"
        elif nvlink_count > 0 and pcie_count > 0:
            return "Mixed"
        else:
            return "Unknown"
    
    def analyze_interconnect_bandwidth(self) -> Dict[str, float]:
        """åˆ†æGPUäº’è”å¸¦å®½"""
        topology = self.detect_gpu_topology()
        
        analysis = {
            "total_bandwidth": 0.0,
            "avg_bandwidth": 0.0,
            "min_bandwidth": float('inf'),
            "max_bandwidth": 0.0,
            "nvlink_bandwidth": 0.0,
            "pcie_bandwidth": 0.0
        }
        
        if not topology.interconnects:
            return analysis
        
        bandwidths = []
        for interconnect in topology.interconnects:
            bandwidth = interconnect.bandwidth_gbps
            bandwidths.append(bandwidth)
            analysis["total_bandwidth"] += bandwidth
            analysis["min_bandwidth"] = min(analysis["min_bandwidth"], bandwidth)
            analysis["max_bandwidth"] = max(analysis["max_bandwidth"], bandwidth)
            
            if interconnect.interconnect_type == InterconnectType.NVLINK:
                analysis["nvlink_bandwidth"] += bandwidth
            elif interconnect.interconnect_type == InterconnectType.PCIE:
                analysis["pcie_bandwidth"] += bandwidth
        
        if bandwidths:
            analysis["avg_bandwidth"] = sum(bandwidths) / len(bandwidths)
        
        if analysis["min_bandwidth"] == float('inf'):
            analysis["min_bandwidth"] = 0.0
        
        return analysis
    
    def check_hardware_compatibility(self) -> HardwareCompatibility:
        """æ£€æŸ¥ç¡¬ä»¶å…¼å®¹æ€§"""
        compatibility = HardwareCompatibility(is_compatible=True, compatibility_score=100.0)
        
        try:
            # æ£€æŸ¥åŸºæœ¬CUDAå¯ç”¨æ€§
            if not self.detect_cuda_availability():
                compatibility.add_issue("CUDAä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡ŒGPUè®­ç»ƒ")
                compatibility.compatibility_score -= 50
                return compatibility
            
            topology = self.detect_gpu_topology()
            
            if topology.num_gpus == 0 or len(topology.gpu_info) == 0:
                compatibility.add_issue("æœªæ£€æµ‹åˆ°å¯ç”¨GPU")
                compatibility.compatibility_score -= 50
                return compatibility
            
            # æ£€æŸ¥GPUå†…å­˜
            insufficient_memory_gpus = []
            for gpu_id, gpu_info in topology.gpu_info.items():
                if gpu_info.total_memory < self.requirements.min_gpu_memory:
                    insufficient_memory_gpus.append(gpu_id)
            
            if insufficient_memory_gpus:
                compatibility.add_issue(
                    f"GPU {insufficient_memory_gpus} å†…å­˜ä¸è¶³ "
                    f"(éœ€è¦è‡³å°‘ {self.requirements.min_gpu_memory}MB)"
                )
                compatibility.compatibility_score -= 30
            
            # æ£€æŸ¥è®¡ç®—èƒ½åŠ›
            low_compute_gpus = []
            for gpu_id, gpu_info in topology.gpu_info.items():
                if (gpu_info.compute_capability and 
                    gpu_info.compute_capability < self.requirements.min_compute_capability):
                    low_compute_gpus.append(gpu_id)
            
            if low_compute_gpus:
                compatibility.add_warning(
                    f"GPU {low_compute_gpus} è®¡ç®—èƒ½åŠ›è¾ƒä½ï¼Œå¯èƒ½å½±å“æ€§èƒ½"
                )
                compatibility.compatibility_score -= 10
            
            # æ£€æŸ¥å¤šGPUäº’è”
            if topology.num_gpus > 1:
                bandwidth_analysis = self.analyze_interconnect_bandwidth()
                
                if bandwidth_analysis["min_bandwidth"] < self.requirements.min_pcie_bandwidth:
                    compatibility.add_warning(
                        f"GPUé—´å¸¦å®½è¾ƒä½ ({bandwidth_analysis['min_bandwidth']:.1f} GB/s)ï¼Œ"
                        f"å¯èƒ½å½±å“å¤šGPUè®­ç»ƒæ•ˆç‡"
                    )
                    compatibility.compatibility_score -= 15
                
                # æ£€æŸ¥NUMAæ‹“æ‰‘
                numa_distances = []
                gpus = list(topology.gpu_info.keys())
                for i in range(len(gpus)):
                    for j in range(i + 1, len(gpus)):
                        distance = topology.get_numa_distance(gpus[i], gpus[j])
                        if distance > 0:
                            numa_distances.append(distance)
                
                if numa_distances and max(numa_distances) > self.requirements.max_numa_distance:
                    compatibility.add_warning(
                        "æ£€æµ‹åˆ°è·¨NUMAèŠ‚ç‚¹çš„GPUé…ç½®ï¼Œå¯èƒ½å½±å“é€šä¿¡æ•ˆç‡"
                    )
                    compatibility.compatibility_score -= 10
            
            # ç”Ÿæˆå»ºè®®
            self._generate_compatibility_recommendations(compatibility, topology)
            
            return compatibility
            
        except Exception as e:
            self.logger.error(f"ç¡¬ä»¶å…¼å®¹æ€§æ£€æŸ¥å¤±è´¥: {e}")
            compatibility.add_issue(f"å…¼å®¹æ€§æ£€æŸ¥å¤±è´¥: {e}")
            compatibility.is_compatible = False
            compatibility.compatibility_score = 0.0
            return compatibility
    
    def _generate_compatibility_recommendations(self, compatibility: HardwareCompatibility, 
                                              topology: GPUTopology):
        """ç”Ÿæˆå…¼å®¹æ€§å»ºè®®"""
        if topology.num_gpus == 1:
            gpu_info = list(topology.gpu_info.values())[0]
            if gpu_info.total_memory < self.requirements.recommended_gpu_memory:
                compatibility.add_recommendation("å¯ç”¨LoRAå¾®è°ƒä»¥å‡å°‘å†…å­˜ä½¿ç”¨")
                compatibility.add_recommendation("ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ(FP16)")
                compatibility.add_recommendation("å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹")
        
        elif topology.num_gpus > 1:
            if topology.topology_type == "NVLink":
                compatibility.add_recommendation("æ£€æµ‹åˆ°NVLinkè¿æ¥ï¼Œå»ºè®®å¯ç”¨æ•°æ®å¹¶è¡Œè®­ç»ƒ")
            elif topology.topology_type == "PCIe":
                compatibility.add_recommendation("ä½¿ç”¨PCIeè¿æ¥ï¼Œå»ºè®®ä¼˜åŒ–é€šä¿¡ç­–ç•¥")
            
            bandwidth_analysis = self.analyze_interconnect_bandwidth()
            if bandwidth_analysis["avg_bandwidth"] > 50.0:
                compatibility.add_recommendation("é«˜å¸¦å®½äº’è”ï¼Œå¯è€ƒè™‘æ¨¡å‹å¹¶è¡Œè®­ç»ƒ")


def main():
    """ä¸»å‡½æ•°ï¼Œç”¨äºæµ‹è¯•GPUæ£€æµ‹åŠŸèƒ½"""
    logging.basicConfig(level=logging.INFO)
    
    detector = GPUDetector()
    print(detector.generate_system_report())
    
    # æµ‹è¯•æ‹“æ‰‘æ£€æµ‹
    print("\n=== GPUæ‹“æ‰‘æ£€æµ‹ ===")
    topology = detector.detect_gpu_topology()
    print(f"GPUæ•°é‡: {topology.num_gpus}")
    print(f"æ‹“æ‰‘ç±»å‹: {topology.topology_type}")
    
    if topology.interconnects:
        print("GPUäº’è”:")
        for ic in topology.interconnects:
            print(f"  GPU {ic.gpu_a} <-> GPU {ic.gpu_b}: "
                  f"{ic.interconnect_type.value} ({ic.bandwidth_gbps:.1f} GB/s)")
    
    # æµ‹è¯•ç¡¬ä»¶å…¼å®¹æ€§
    print("\n=== ç¡¬ä»¶å…¼å®¹æ€§æ£€æŸ¥ ===")
    compatibility = detector.check_hardware_compatibility()
    print(f"å…¼å®¹æ€§è¯„åˆ†: {compatibility.compatibility_score:.1f}/100")
    print(f"æ˜¯å¦å…¼å®¹: {'æ˜¯' if compatibility.is_compatible else 'å¦'}")
    
    if compatibility.issues:
        print("é—®é¢˜:")
        for issue in compatibility.issues:
            print(f"  âŒ {issue}")
    
    if compatibility.warnings:
        print("è­¦å‘Š:")
        for warning in compatibility.warnings:
            print(f"  âš ï¸ {warning}")
    
    if compatibility.recommendations:
        print("å»ºè®®:")
        for rec in compatibility.recommendations:
            print(f"  ğŸ’¡ {rec}")


if __name__ == "__main__":
    main()
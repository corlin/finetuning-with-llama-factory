#!/usr/bin/env python3
"""
CLIå·¥å…·å’Œç”¨æˆ·æ¥å£

æœ¬æ¨¡å—å®ç°äº†å‘½ä»¤è¡Œè®­ç»ƒå·¥å…·ã€é…ç½®æ–‡ä»¶æ¨¡æ¿å’ŒéªŒè¯ã€è®­ç»ƒè¿›åº¦å¯è§†åŒ–ç•Œé¢ç­‰åŠŸèƒ½ã€‚
æä¾›å®Œæ•´çš„ç”¨æˆ·äº¤äº’ç•Œé¢ï¼Œæ”¯æŒè®­ç»ƒæµæ°´çº¿çš„å¯åŠ¨ã€ç›‘æ§å’Œç®¡ç†ã€‚
"""

import os
import sys
import json
import yaml
import click
import logging
import asyncio
import threading
import time
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime
from rich.console import Console
from rich.table import Table
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn
from rich.live import Live
from rich.panel import Panel
from rich.layout import Layout
from rich.text import Text
from rich import box

from src.data_models import TrainingExample, ThinkingExample, DifficultyLevel
from config_manager import TrainingConfig, DataConfig, SystemConfig
from lora_config_optimizer import LoRAMemoryProfile, LoRAOptimizationStrategy
from parallel_config import ParallelConfig, ParallelStrategy
from training_pipeline import TrainingPipelineOrchestrator, PipelineStage, PipelineStatus
# LlamaFactory adapter removed - using direct training engine
from gpu_utils import GPUDetector


# å…¨å±€æ§åˆ¶å°å¯¹è±¡
console = Console()


class ConfigTemplate:
    """é…ç½®æ¨¡æ¿ç”Ÿæˆå™¨"""
    
    @staticmethod
    def generate_training_config_template() -> Dict[str, Any]:
        """ç”Ÿæˆè®­ç»ƒé…ç½®æ¨¡æ¿"""
        return {
            "model": {
                "model_name": "Qwen/Qwen3-4B-Thinking-2507",
                "model_revision": "main",
                "trust_remote_code": True
            },
            "training": {
                "num_train_epochs": 3,
                "per_device_train_batch_size": 1,
                "per_device_eval_batch_size": 1,
                "gradient_accumulation_steps": 4,
                "learning_rate": 2e-4,
                "weight_decay": 0.01,
                "warmup_ratio": 0.1,
                "lr_scheduler_type": "cosine",
                "fp16": False,
                "bf16": True,
                "save_strategy": "steps",
                "save_steps": 500,
                "eval_strategy": "steps",
                "eval_steps": 500,
                "logging_steps": 10,
                "max_seq_length": 2048,
                "seed": 42
            },
            "lora": {
                "rank": 8,
                "alpha": 16,
                "dropout": 0.1,
                "target_modules": ["q_proj", "k_proj", "v_proj", "o_proj"],
                "optimization_strategy": "auto"
            },
            "data": {
                "train_split_ratio": 0.9,
                "eval_split_ratio": 0.1,
                "max_samples": None,
                "shuffle_data": True,
                "data_format": "alpaca"
            },
            "parallel": {
                "strategy": "data_parallel",
                "world_size": 1,
                "enable_distributed": False
            },
            "system": {
                "output_dir": "./output",
                "logging_dir": "./logs",
                "cache_dir": "./cache",
                "log_level": "INFO"
            }
        }
    
    @staticmethod
    def save_template(template: Dict[str, Any], output_file: str):
        """ä¿å­˜é…ç½®æ¨¡æ¿"""
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            yaml.dump(template, f, default_flow_style=False, allow_unicode=True, indent=2)
        
        console.print(f"âœ“ é…ç½®æ¨¡æ¿å·²ä¿å­˜åˆ°: {output_path}", style="green")


class ConfigValidator:
    """é…ç½®éªŒè¯å™¨"""
    
    @staticmethod
    def validate_config_file(config_file: str) -> Tuple[bool, List[str]]:
        """éªŒè¯é…ç½®æ–‡ä»¶"""
        errors = []
        
        try:
            if not Path(config_file).exists():
                errors.append(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
                return False, errors
            
            with open(config_file, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            # éªŒè¯å¿…éœ€çš„é…ç½®èŠ‚
            required_sections = ["model", "training", "lora", "data", "system"]
            for section in required_sections:
                if section not in config:
                    errors.append(f"ç¼ºå°‘é…ç½®èŠ‚: {section}")
            
            # éªŒè¯æ¨¡å‹é…ç½®
            if "model" in config:
                model_config = config["model"]
                if "model_name" not in model_config:
                    errors.append("model.model_name æ˜¯å¿…éœ€çš„")
            
            # éªŒè¯è®­ç»ƒé…ç½®
            if "training" in config:
                training_config = config["training"]
                
                # æ£€æŸ¥æ•°å€¼èŒƒå›´
                if "learning_rate" in training_config:
                    lr = training_config["learning_rate"]
                    if not isinstance(lr, (int, float)) or lr <= 0:
                        errors.append("training.learning_rate å¿…é¡»æ˜¯æ­£æ•°")
                
                if "num_train_epochs" in training_config:
                    epochs = training_config["num_train_epochs"]
                    if not isinstance(epochs, int) or epochs <= 0:
                        errors.append("training.num_train_epochs å¿…é¡»æ˜¯æ­£æ•´æ•°")
            
            # éªŒè¯LoRAé…ç½®
            if "lora" in config:
                lora_config = config["lora"]
                
                if "rank" in lora_config:
                    rank = lora_config["rank"]
                    if not isinstance(rank, int) or rank <= 0:
                        errors.append("lora.rank å¿…é¡»æ˜¯æ­£æ•´æ•°")
                
                if "alpha" in lora_config:
                    alpha = lora_config["alpha"]
                    if not isinstance(alpha, int) or alpha <= 0:
                        errors.append("lora.alpha å¿…é¡»æ˜¯æ­£æ•´æ•°")
            
            # éªŒè¯æ•°æ®é…ç½®
            if "data" in config:
                data_config = config["data"]
                
                if "train_split_ratio" in data_config:
                    ratio = data_config["train_split_ratio"]
                    if not isinstance(ratio, (int, float)) or not 0 < ratio < 1:
                        errors.append("data.train_split_ratio å¿…é¡»åœ¨0å’Œ1ä¹‹é—´")
            
            return len(errors) == 0, errors
            
        except Exception as e:
            errors.append(f"é…ç½®æ–‡ä»¶è§£æå¤±è´¥: {e}")
            return False, errors


class TrainingProgressDisplay:
    """è®­ç»ƒè¿›åº¦æ˜¾ç¤ºå™¨"""
    
    def __init__(self):
        self.console = Console()
        self.is_running = False
        self.current_state = None
        
    def start_display(self, orchestrator: TrainingPipelineOrchestrator):
        """å¯åŠ¨è¿›åº¦æ˜¾ç¤º"""
        self.is_running = True
        
        # åˆ›å»ºå¸ƒå±€
        layout = Layout()
        layout.split_column(
            Layout(name="header", size=3),
            Layout(name="main", ratio=1),
            Layout(name="footer", size=3)
        )
        
        layout["main"].split_row(
            Layout(name="progress", ratio=2),
            Layout(name="status", ratio=1)
        )
        
        with Live(layout, console=self.console, refresh_per_second=2) as live:
            while self.is_running:
                state = orchestrator.get_state()
                self.current_state = state
                
                # æ›´æ–°å¸ƒå±€å†…å®¹
                layout["header"].update(self._create_header(state))
                layout["progress"].update(self._create_progress_panel(state))
                layout["status"].update(self._create_status_panel(state))
                layout["footer"].update(self._create_footer(state))
                
                time.sleep(0.5)
    
    def stop_display(self):
        """åœæ­¢è¿›åº¦æ˜¾ç¤º"""
        self.is_running = False
    
    def _create_header(self, state) -> Panel:
        """åˆ›å»ºå¤´éƒ¨é¢æ¿"""
        title = f"è®­ç»ƒæµæ°´çº¿: {state.pipeline_id}"
        status_color = {
            PipelineStatus.PENDING: "yellow",
            PipelineStatus.RUNNING: "green",
            PipelineStatus.PAUSED: "orange",
            PipelineStatus.COMPLETED: "blue",
            PipelineStatus.FAILED: "red",
            PipelineStatus.CANCELLED: "gray"
        }.get(state.status, "white")
        
        header_text = Text(title, style="bold")
        header_text.append(f" [{state.status.value.upper()}]", style=f"bold {status_color}")
        
        return Panel(header_text, box=box.ROUNDED)
    
    def _create_progress_panel(self, state) -> Panel:
        """åˆ›å»ºè¿›åº¦é¢æ¿"""
        # æ€»ä½“è¿›åº¦æ¡
        progress_bar = "â–ˆ" * int(state.progress / 5) + "â–‘" * (20 - int(state.progress / 5))
        progress_text = f"æ€»ä½“è¿›åº¦: [{progress_bar}] {state.progress:.1f}%\n\n"
        
        # å½“å‰é˜¶æ®µ
        progress_text += f"å½“å‰é˜¶æ®µ: {state.current_stage.value}\n"
        
        # é˜¶æ®µè¿›åº¦
        if state.current_stage_runtime:
            runtime = state.current_stage_runtime.total_seconds()
            progress_text += f"é˜¶æ®µè¿è¡Œæ—¶é—´: {runtime:.0f}ç§’\n"
        
        # å„é˜¶æ®µçŠ¶æ€
        progress_text += "\né˜¶æ®µçŠ¶æ€:\n"
        for stage in PipelineStage:
            if stage == PipelineStage.ERROR:
                continue
                
            stage_progress = state.stage_progress.get(stage, 0.0)
            if stage == state.current_stage:
                status_icon = "ğŸ”„"
            elif stage_progress >= 100.0:
                status_icon = "âœ…"
            elif stage_progress > 0.0:
                status_icon = "â³"
            else:
                status_icon = "â­•"
            
            progress_text += f"  {status_icon} {stage.value}: {stage_progress:.0f}%\n"
        
        return Panel(progress_text, title="è®­ç»ƒè¿›åº¦", box=box.ROUNDED)
    
    def _create_status_panel(self, state) -> Panel:
        """åˆ›å»ºçŠ¶æ€é¢æ¿"""
        status_text = ""
        
        # è¿è¡Œæ—¶é—´
        if state.runtime:
            runtime = state.runtime.total_seconds()
            hours = int(runtime // 3600)
            minutes = int((runtime % 3600) // 60)
            seconds = int(runtime % 60)
            status_text += f"è¿è¡Œæ—¶é—´: {hours:02d}:{minutes:02d}:{seconds:02d}\n\n"
        
        # æ£€æŸ¥ç‚¹ä¿¡æ¯
        if state.latest_checkpoint:
            status_text += f"æœ€æ–°æ£€æŸ¥ç‚¹:\n"
            status_text += f"  ID: {state.latest_checkpoint.checkpoint_id}\n"
            status_text += f"  é˜¶æ®µ: {state.latest_checkpoint.stage.value}\n"
            status_text += f"  æ—¶é—´: {state.latest_checkpoint.timestamp.strftime('%H:%M:%S')}\n\n"
        
        # é”™è¯¯ä¿¡æ¯
        if state.error_message:
            status_text += f"é”™è¯¯ä¿¡æ¯:\n{state.error_message}\n"
        
        return Panel(status_text, title="çŠ¶æ€ä¿¡æ¯", box=box.ROUNDED)
    
    def _create_footer(self, state) -> Panel:
        """åˆ›å»ºåº•éƒ¨é¢æ¿"""
        footer_text = "æŒ‰ Ctrl+C åœæ­¢ç›‘æ§"
        if state.status == PipelineStatus.RUNNING:
            footer_text += " | è®­ç»ƒæ­£åœ¨è¿›è¡Œä¸­..."
        elif state.status == PipelineStatus.COMPLETED:
            footer_text += " | è®­ç»ƒå·²å®Œæˆï¼"
        elif state.status == PipelineStatus.FAILED:
            footer_text += " | è®­ç»ƒå¤±è´¥ï¼"
        
        return Panel(footer_text, box=box.ROUNDED)


# CLIå‘½ä»¤ç»„
@click.group()
@click.option('--verbose', '-v', is_flag=True, help='å¯ç”¨è¯¦ç»†è¾“å‡º')
@click.option('--config', '-c', help='é…ç½®æ–‡ä»¶è·¯å¾„')
@click.pass_context
def cli(ctx, verbose, config):
    """Qwen3-4B-Thinking å¯†ç å­¦å¾®è°ƒå·¥å…·"""
    ctx.ensure_object(dict)
    ctx.obj['verbose'] = verbose
    ctx.obj['config'] = config
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    log_level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=log_level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )


@cli.command()
@click.option('--output', '-o', default='config.yaml', help='è¾“å‡ºé…ç½®æ–‡ä»¶è·¯å¾„')
def init_config(output):
    """ç”Ÿæˆé…ç½®æ–‡ä»¶æ¨¡æ¿"""
    console.print("ğŸ”§ ç”Ÿæˆé…ç½®æ–‡ä»¶æ¨¡æ¿...", style="blue")
    
    template = ConfigTemplate.generate_training_config_template()
    ConfigTemplate.save_template(template, output)
    
    console.print(f"\nğŸ“ é…ç½®æ–‡ä»¶æ¨¡æ¿å·²ç”Ÿæˆ: {output}", style="green")
    console.print("è¯·ç¼–è¾‘é…ç½®æ–‡ä»¶åä½¿ç”¨ 'train' å‘½ä»¤å¼€å§‹è®­ç»ƒ", style="yellow")


@cli.command()
@click.argument('config_file')
def validate_config(config_file):
    """éªŒè¯é…ç½®æ–‡ä»¶"""
    console.print(f"ğŸ” éªŒè¯é…ç½®æ–‡ä»¶: {config_file}", style="blue")
    
    is_valid, errors = ConfigValidator.validate_config_file(config_file)
    
    if is_valid:
        console.print("âœ… é…ç½®æ–‡ä»¶éªŒè¯é€šè¿‡", style="green")
    else:
        console.print("âŒ é…ç½®æ–‡ä»¶éªŒè¯å¤±è´¥:", style="red")
        for error in errors:
            console.print(f"  â€¢ {error}", style="red")
        sys.exit(1)


@cli.command()
@click.argument('data_file')
@click.argument('config_file')
@click.option('--output-dir', '-o', default='./training_output', help='è¾“å‡ºç›®å½•')
@click.option('--pipeline-id', help='æµæ°´çº¿ID')
@click.option('--resume', help='ä»æ£€æŸ¥ç‚¹æ¢å¤')
@click.option('--dry-run', is_flag=True, help='ä»…éªŒè¯é…ç½®ï¼Œä¸æ‰§è¡Œè®­ç»ƒ')
@click.pass_context
def train(ctx, data_file, config_file, output_dir, pipeline_id, resume, dry_run):
    """å¼€å§‹è®­ç»ƒ"""
    console.print("ğŸš€ å¼€å§‹è®­ç»ƒæµç¨‹...", style="blue")
    
    # éªŒè¯é…ç½®æ–‡ä»¶
    is_valid, errors = ConfigValidator.validate_config_file(config_file)
    if not is_valid:
        console.print("âŒ é…ç½®æ–‡ä»¶éªŒè¯å¤±è´¥:", style="red")
        for error in errors:
            console.print(f"  â€¢ {error}", style="red")
        sys.exit(1)
    
    # éªŒè¯æ•°æ®æ–‡ä»¶
    if not Path(data_file).exists():
        console.print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}", style="red")
        sys.exit(1)
    
    # åŠ è½½é…ç½®
    with open(config_file, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # åŠ è½½è®­ç»ƒæ•°æ®
    console.print(f"ğŸ“Š åŠ è½½è®­ç»ƒæ•°æ®: {data_file}", style="blue")
    training_data = load_training_data(data_file)
    console.print(f"âœ“ åŠ è½½äº† {len(training_data)} æ¡è®­ç»ƒæ•°æ®", style="green")
    
    if dry_run:
        console.print("ğŸ” ä»…éªŒè¯æ¨¡å¼ï¼Œä¸æ‰§è¡Œå®é™…è®­ç»ƒ", style="yellow")
        console.print("âœ… é…ç½®å’Œæ•°æ®éªŒè¯é€šè¿‡", style="green")
        return
    
    # åˆ›å»ºé…ç½®å¯¹è±¡
    training_config = create_training_config(config)
    data_config = create_data_config(config)
    lora_config = create_lora_config(config)
    parallel_config = create_parallel_config(config)
    system_config = create_system_config(config)
    
    # ç”Ÿæˆæµæ°´çº¿ID
    if not pipeline_id:
        pipeline_id = f"training_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    # åˆ›å»ºæµæ°´çº¿ç¼–æ’å™¨
    orchestrator = TrainingPipelineOrchestrator(pipeline_id, output_dir)
    orchestrator.configure_pipeline(
        training_data, training_config, data_config, lora_config, parallel_config, system_config
    )
    
    # å¯åŠ¨è¿›åº¦æ˜¾ç¤º
    progress_display = TrainingProgressDisplay()
    display_thread = threading.Thread(
        target=progress_display.start_display,
        args=(orchestrator,),
        daemon=True
    )
    display_thread.start()
    
    try:
        # è¿è¡Œè®­ç»ƒæµæ°´çº¿
        success = orchestrator.run_pipeline(resume_from_checkpoint=resume)
        
        progress_display.stop_display()
        
        if success:
            console.print("\nğŸ‰ è®­ç»ƒå®Œæˆï¼", style="green")
            console.print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}", style="blue")
        else:
            console.print("\nâŒ è®­ç»ƒå¤±è´¥ï¼", style="red")
            if orchestrator.get_state().error_message:
                console.print(f"é”™è¯¯ä¿¡æ¯: {orchestrator.get_state().error_message}", style="red")
            sys.exit(1)
            
    except KeyboardInterrupt:
        console.print("\nâ¹ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­", style="yellow")
        orchestrator.stop_pipeline()
        progress_display.stop_display()
        sys.exit(0)


@cli.command()
@click.argument('pipeline_dir')
def status(pipeline_dir):
    """æŸ¥çœ‹è®­ç»ƒçŠ¶æ€"""
    console.print(f"ğŸ“Š æŸ¥çœ‹è®­ç»ƒçŠ¶æ€: {pipeline_dir}", style="blue")
    
    # æŸ¥æ‰¾æœ€æ–°çš„çŠ¶æ€æ–‡ä»¶
    pipeline_path = Path(pipeline_dir)
    if not pipeline_path.exists():
        console.print(f"âŒ æµæ°´çº¿ç›®å½•ä¸å­˜åœ¨: {pipeline_dir}", style="red")
        sys.exit(1)
    
    # æŸ¥æ‰¾æ£€æŸ¥ç‚¹æ–‡ä»¶
    checkpoints_dir = pipeline_path / "checkpoints"
    if checkpoints_dir.exists():
        checkpoint_files = list(checkpoints_dir.glob("*.json"))
        if checkpoint_files:
            # è·å–æœ€æ–°çš„æ£€æŸ¥ç‚¹
            latest_checkpoint = max(checkpoint_files, key=lambda x: x.stat().st_mtime)
            
            with open(latest_checkpoint, 'r', encoding='utf-8') as f:
                checkpoint_data = json.load(f)
            
            # æ˜¾ç¤ºçŠ¶æ€è¡¨æ ¼
            table = Table(title="è®­ç»ƒçŠ¶æ€")
            table.add_column("é¡¹ç›®", style="cyan")
            table.add_column("å€¼", style="green")
            
            table.add_row("æ£€æŸ¥ç‚¹ID", checkpoint_data["checkpoint_id"])
            table.add_row("é˜¶æ®µ", checkpoint_data["stage"])
            table.add_row("æ—¶é—´", checkpoint_data["timestamp"])
            table.add_row("è¿›åº¦", f"{checkpoint_data['state_data'].get('progress', 0):.1f}%")
            
            console.print(table)
        else:
            console.print("âŒ æœªæ‰¾åˆ°æ£€æŸ¥ç‚¹æ–‡ä»¶", style="red")
    else:
        console.print("âŒ æ£€æŸ¥ç‚¹ç›®å½•ä¸å­˜åœ¨", style="red")


@cli.command()
def list_gpus():
    """åˆ—å‡ºå¯ç”¨çš„GPU"""
    console.print("ğŸ” æ£€æµ‹GPUè®¾å¤‡...", style="blue")
    
    detector = GPUDetector()
    gpu_infos = detector.get_all_gpu_info()
    
    if not gpu_infos:
        console.print("âŒ æœªæ£€æµ‹åˆ°GPUè®¾å¤‡", style="red")
        return
    
    # åˆ›å»ºGPUä¿¡æ¯è¡¨æ ¼
    table = Table(title="GPUè®¾å¤‡ä¿¡æ¯")
    table.add_column("ID", style="cyan")
    table.add_column("åç§°", style="green")
    table.add_column("å†…å­˜", style="yellow")
    table.add_column("åˆ©ç”¨ç‡", style="blue")
    table.add_column("æ¸©åº¦", style="red")
    
    for gpu in gpu_infos:
        memory_text = f"{gpu.memory_used}MB / {gpu.memory_total}MB"
        utilization_text = f"{gpu.utilization:.1f}%"
        temperature_text = f"{gpu.temperature:.1f}Â°C" if gpu.temperature > 0 else "N/A"
        
        table.add_row(
            str(gpu.gpu_id),
            gpu.name,
            memory_text,
            utilization_text,
            temperature_text
        )
    
    console.print(table)


@cli.command()
@click.argument('data_file')
@click.option('--format', 'data_format', default='json', help='æ•°æ®æ ¼å¼ (json, jsonl)')
@click.option('--sample', type=int, help='æ˜¾ç¤ºæ ·æœ¬æ•°é‡')
def inspect_data(data_file, data_format, sample):
    """æ£€æŸ¥è®­ç»ƒæ•°æ®"""
    console.print(f"ğŸ” æ£€æŸ¥è®­ç»ƒæ•°æ®: {data_file}", style="blue")
    
    if not Path(data_file).exists():
        console.print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}", style="red")
        sys.exit(1)
    
    try:
        training_data = load_training_data(data_file)
        
        # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡
        table = Table(title="æ•°æ®ç»Ÿè®¡")
        table.add_column("é¡¹ç›®", style="cyan")
        table.add_column("å€¼", style="green")
        
        table.add_row("æ€»æ ·æœ¬æ•°", str(len(training_data)))
        
        # ç»Ÿè®¡éš¾åº¦çº§åˆ«
        difficulty_counts = {}
        thinking_count = 0
        crypto_terms_count = 0
        
        for example in training_data:
            # éš¾åº¦çº§åˆ«ç»Ÿè®¡
            difficulty = example.difficulty_level.name
            difficulty_counts[difficulty] = difficulty_counts.get(difficulty, 0) + 1
            
            # thinkingæ•°æ®ç»Ÿè®¡
            if example.has_thinking():
                thinking_count += 1
            
            # å¯†ç å­¦æœ¯è¯­ç»Ÿè®¡
            if example.crypto_terms:
                crypto_terms_count += len(example.crypto_terms)
        
        table.add_row("åŒ…å«thinkingæ•°æ®", str(thinking_count))
        table.add_row("å¯†ç å­¦æœ¯è¯­æ€»æ•°", str(crypto_terms_count))
        
        for difficulty, count in difficulty_counts.items():
            table.add_row(f"éš¾åº¦-{difficulty}", str(count))
        
        console.print(table)
        
        # æ˜¾ç¤ºæ ·æœ¬
        if sample and sample > 0:
            console.print(f"\nğŸ“ æ˜¾ç¤ºå‰ {min(sample, len(training_data))} ä¸ªæ ·æœ¬:", style="blue")
            
            for i, example in enumerate(training_data[:sample]):
                panel_content = f"æŒ‡ä»¤: {example.instruction}\n"
                if example.input:
                    panel_content += f"è¾“å…¥: {example.input}\n"
                panel_content += f"è¾“å‡º: {example.output[:200]}..."
                if example.has_thinking():
                    panel_content += f"\næ€è€ƒ: {example.thinking[:100]}..."
                
                console.print(Panel(panel_content, title=f"æ ·æœ¬ {i+1}"))
        
    except Exception as e:
        console.print(f"âŒ æ•°æ®æ£€æŸ¥å¤±è´¥: {e}", style="red")
        sys.exit(1)


# è¾…åŠ©å‡½æ•°
def load_training_data(data_file: str) -> List[TrainingExample]:
    """åŠ è½½è®­ç»ƒæ•°æ®"""
    data_path = Path(data_file)
    
    if data_path.suffix == '.json':
        with open(data_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    elif data_path.suffix == '.jsonl':
        data = []
        with open(data_path, 'r', encoding='utf-8') as f:
            for line in f:
                data.append(json.loads(line))
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®æ ¼å¼: {data_path.suffix}")
    
    # è½¬æ¢ä¸ºTrainingExampleå¯¹è±¡
    training_examples = []
    for item in data:
        if isinstance(item, dict):
            example = TrainingExample(
                instruction=item.get('instruction', ''),
                input=item.get('input', ''),
                output=item.get('output', ''),
                thinking=item.get('thinking'),
                crypto_terms=item.get('crypto_terms', []),
                difficulty_level=DifficultyLevel(item.get('difficulty', 2))
            )
            training_examples.append(example)
    
    return training_examples


def create_training_config(config: Dict[str, Any]) -> TrainingConfig:
    """åˆ›å»ºè®­ç»ƒé…ç½®"""
    training_section = config.get('training', {})
    
    return TrainingConfig(
        num_train_epochs=training_section.get('num_train_epochs', 3),
        per_device_train_batch_size=training_section.get('per_device_train_batch_size', 1),
        per_device_eval_batch_size=training_section.get('per_device_eval_batch_size', 1),
        gradient_accumulation_steps=training_section.get('gradient_accumulation_steps', 4),
        learning_rate=training_section.get('learning_rate', 2e-4),
        weight_decay=training_section.get('weight_decay', 0.01),
        warmup_ratio=training_section.get('warmup_ratio', 0.1),
        lr_scheduler_type=training_section.get('lr_scheduler_type', 'cosine'),
        fp16=training_section.get('fp16', False),
        bf16=training_section.get('bf16', True),
        save_strategy=training_section.get('save_strategy', 'steps'),
        save_steps=training_section.get('save_steps', 500),
        eval_strategy=training_section.get('eval_strategy', 'steps'),
        eval_steps=training_section.get('eval_steps', 500),
        logging_steps=training_section.get('logging_steps', 10),
        seed=training_section.get('seed', 42)
    )


def create_data_config(config: Dict[str, Any]) -> DataConfig:
    """åˆ›å»ºæ•°æ®é…ç½®"""
    data_section = config.get('data', {})
    
    return DataConfig(
        train_split_ratio=data_section.get('train_split_ratio', 0.9),
        eval_split_ratio=data_section.get('eval_split_ratio', 0.1),
        max_samples=data_section.get('max_samples'),
        shuffle_data=data_section.get('shuffle_data', True),
        data_format=data_section.get('data_format', 'alpaca')
    )


def create_lora_config(config: Dict[str, Any]) -> LoRAMemoryProfile:
    """åˆ›å»ºLoRAé…ç½®"""
    lora_section = config.get('lora', {})
    
    return LoRAMemoryProfile(
        rank=lora_section.get('rank', 8),
        alpha=lora_section.get('alpha', 16),
        target_modules=lora_section.get('target_modules', ['q_proj', 'k_proj', 'v_proj', 'o_proj'])
    )


def create_parallel_config(config: Dict[str, Any]) -> ParallelConfig:
    """åˆ›å»ºå¹¶è¡Œé…ç½®"""
    parallel_section = config.get('parallel', {})
    
    strategy_map = {
        'data_parallel': ParallelStrategy.DATA_PARALLEL,
        'model_parallel': ParallelStrategy.MODEL_PARALLEL,
        'pipeline_parallel': ParallelStrategy.PIPELINE_PARALLEL,
        'hybrid_parallel': ParallelStrategy.HYBRID_PARALLEL,
        'auto': ParallelStrategy.AUTO
    }
    
    strategy = strategy_map.get(parallel_section.get('strategy', 'data_parallel'), ParallelStrategy.DATA_PARALLEL)
    
    return ParallelConfig(
        strategy=strategy,
        data_parallel_size=parallel_section.get('world_size', 1),
        enable_zero_optimization=parallel_section.get('enable_distributed', False)
    )


def create_system_config(config: Dict[str, Any]) -> SystemConfig:
    """åˆ›å»ºç³»ç»Ÿé…ç½®"""
    system_section = config.get('system', {})
    
    return SystemConfig(
        cache_dir=system_section.get('cache_dir', './cache'),
        log_level=system_section.get('log_level', 'INFO')
    )


if __name__ == '__main__':
    cli()
#!/usr/bin/env python3
"""
ä¸“å®¶è¯„ä¼°ç³»ç»ŸåŸºç¡€ä½¿ç”¨ç¤ºä¾‹

æœ¬è„šæœ¬å±•ç¤ºäº†ä¸“å®¶è¯„ä¼°ç³»ç»Ÿçš„åŸºæœ¬ä½¿ç”¨æ–¹æ³•ï¼Œé€‚åˆåˆå­¦è€…å¿«é€Ÿä¸Šæ‰‹ã€‚

ä½¿ç”¨æ–¹æ³•:
    uv run python examples/expert_evaluation_basic_usage.py

ä½œè€…: ä¸“å®¶è¯„ä¼°ç³»ç»Ÿå¼€å‘å›¢é˜Ÿ
"""

import json
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.expert_evaluation.engine import ExpertEvaluationEngine
from src.expert_evaluation.config import ExpertEvaluationConfig

def basic_usage_example():
    """åŸºç¡€ä½¿ç”¨ç¤ºä¾‹"""
    
    print("ğŸš€ ä¸“å®¶è¯„ä¼°ç³»ç»ŸåŸºç¡€ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)
    
    # 1. åˆ›å»ºç®€å•é…ç½®
    print("\nğŸ“‹ æ­¥éª¤1: åˆ›å»ºé…ç½®")
    config_dict = {
        "model": {
            "device": "auto",
            "batch_size": 1
        },
        "evaluation": {
            "dimensions": [
                "semantic_similarity",
                "domain_accuracy"
            ],
            "weights": {
                "semantic_similarity": 0.6,
                "domain_accuracy": 0.4
            }
        }
    }
    
    config = ExpertEvaluationConfig.from_dict(config_dict)
    print("âœ… é…ç½®åˆ›å»ºæˆåŠŸ")
    
    # 2. åˆå§‹åŒ–è¯„ä¼°å¼•æ“
    print("\nğŸ¤– æ­¥éª¤2: åˆå§‹åŒ–è¯„ä¼°å¼•æ“")
    engine = ExpertEvaluationEngine(config)
    print("âœ… å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
    
    # 3. å‡†å¤‡QAæ•°æ®
    print("\nğŸ“Š æ­¥éª¤3: å‡†å¤‡QAæ•°æ®")
    qa_item = {
        "question_id": "example_001",
        "question": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
        "reference_answer": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹å­¦ä¹ å’Œæ”¹è¿›ã€‚",
        "model_answer": "æœºå™¨å­¦ä¹ æ˜¯AIçš„ä¸€éƒ¨åˆ†ï¼Œè®©è®¡ç®—æœºå¯ä»¥ä»æ•°æ®ä¸­è‡ªåŠ¨å­¦ä¹ æ¨¡å¼å’Œè§„å¾‹ã€‚",
        "domain_tags": ["äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ "],
        "difficulty_level": "beginner"
    }
    print("âœ… QAæ•°æ®å‡†å¤‡å®Œæˆ")
    
    # 4. æ‰§è¡Œè¯„ä¼°
    print("\nğŸ” æ­¥éª¤4: æ‰§è¡Œè¯„ä¼°")
    result = engine.evaluate_single_qa(qa_item)
    
    # 5. æ˜¾ç¤ºç»“æœ
    print("\nğŸ“Š è¯„ä¼°ç»“æœ:")
    print(f"ğŸ¯ æ€»ä½“å¾—åˆ†: {result.overall_score:.3f}")
    print(f"ğŸ“ˆ è¯­ä¹‰ç›¸ä¼¼æ€§: {result.dimension_scores.get('semantic_similarity', 0):.3f}")
    print(f"ğŸ“ˆ é¢†åŸŸå‡†ç¡®æ€§: {result.dimension_scores.get('domain_accuracy', 0):.3f}")
    
    if result.improvement_suggestions:
        print("\nğŸ’¡ æ”¹è¿›å»ºè®®:")
        for suggestion in result.improvement_suggestions:
            print(f"   - {suggestion}")
    
    print("\nâœ… åŸºç¡€ä½¿ç”¨ç¤ºä¾‹å®Œæˆ!")

if __name__ == "__main__":
    try:
        basic_usage_example()
    except Exception as e:
        print(f"âŒ ç¤ºä¾‹æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
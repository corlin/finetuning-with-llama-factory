#!/usr/bin/env python3
"""
è·¨å¹³å°GPUæ£€æµ‹åŠŸèƒ½æµ‹è¯•
"""

import sys
import os
import platform

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from gpu_utils import GPUDetector


def test_cross_platform_gpu_detection():
    """æµ‹è¯•è·¨å¹³å°GPUæ£€æµ‹åŠŸèƒ½"""
    print(f"å½“å‰æ“ä½œç³»ç»Ÿ: {platform.system()}")
    print("=" * 60)
    
    # åˆ›å»ºGPUæ£€æµ‹å™¨
    detector = GPUDetector()
    
    # æµ‹è¯•CUDAå¯ç”¨æ€§æ£€æµ‹
    print("ğŸ” æ£€æµ‹CUDAå¯ç”¨æ€§...")
    cuda_available = detector.detect_cuda_availability()
    print(f"CUDAå¯ç”¨: {'æ˜¯' if cuda_available else 'å¦'}")
    
    # æµ‹è¯•GPUä¿¡æ¯è·å–
    print("\nğŸ” è·å–GPUä¿¡æ¯...")
    gpu_infos = detector.get_all_gpu_info()
    
    if gpu_infos:
        print(f"æ£€æµ‹åˆ° {len(gpu_infos)} ä¸ªGPU:")
        for gpu in gpu_infos:
            print(f"  GPU {gpu.gpu_id}: {gpu.name}")
            print(f"    æ€»å†…å­˜: {gpu.total_memory}MB")
            print(f"    å¯ç”¨å†…å­˜: {gpu.free_memory}MB")
            print(f"    åˆ©ç”¨ç‡: {gpu.utilization}%")
            if gpu.temperature is not None:
                print(f"    æ¸©åº¦: {gpu.temperature}Â°C")
            if gpu.power_usage is not None:
                print(f"    åŠŸè€—: {gpu.power_usage}W")
            if gpu.pci_bus_id:
                print(f"    PCIæ€»çº¿ID: {gpu.pci_bus_id}")
            if gpu.numa_node is not None:
                print(f"    NUMAèŠ‚ç‚¹: {gpu.numa_node}")
            print()
    else:
        print("æœªæ£€æµ‹åˆ°GPU")
    
    # æµ‹è¯•NUMAæ‹“æ‰‘ä¿¡æ¯
    print("ğŸ” è·å–NUMAæ‹“æ‰‘ä¿¡æ¯...")
    numa_info = detector.get_numa_topology_info()
    print(f"NUMAåº“å¯ç”¨: {'æ˜¯' if numa_info['numa_available'] else 'å¦'}")
    print(f"å¹³å°: {numa_info['platform']}")
    
    if numa_info["numa_nodes"]:
        print(f"NUMAèŠ‚ç‚¹: {numa_info['numa_nodes']}")
        for node_id in numa_info["numa_nodes"]:
            memory = numa_info["memory_per_node"].get(node_id, 0)
            if memory:
                memory_gb = memory // (1024**3)
                print(f"  èŠ‚ç‚¹{node_id}: {memory_gb}GBå†…å­˜")
    else:
        print("æœªæ£€æµ‹åˆ°NUMAèŠ‚ç‚¹ä¿¡æ¯")
    
    # æµ‹è¯•GPUæ‹“æ‰‘æ£€æµ‹
    if len(gpu_infos) > 1:
        print("\nğŸ” æ£€æµ‹GPUæ‹“æ‰‘...")
        topology = detector.detect_gpu_topology()
        print(f"GPUæ•°é‡: {topology.num_gpus}")
        print(f"æ‹“æ‰‘ç±»å‹: {topology.topology_type}")
        
        if topology.numa_topology:
            print("GPU NUMAåˆ†å¸ƒ:")
            for gpu_id, numa_node in topology.numa_topology.items():
                print(f"  GPU {gpu_id} -> NUMAèŠ‚ç‚¹ {numa_node}")
        
        if topology.interconnects:
            print("GPUäº’è”:")
            for ic in topology.interconnects:
                print(f"  GPU {ic.gpu_a} <-> GPU {ic.gpu_b}: "
                      f"{ic.interconnect_type.value} ({ic.bandwidth_gbps:.1f} GB/s)")
    
    # æµ‹è¯•Qwen3-4Béœ€æ±‚éªŒè¯
    print("\nğŸ” éªŒè¯Qwen3-4Bè¿è¡Œéœ€æ±‚...")
    validation = detector.validate_qwen_requirements()
    
    print("éœ€æ±‚éªŒè¯ç»“æœ:")
    for requirement, passed in validation.items():
        status = "âœ…" if passed else "âŒ"
        print(f"  {status} {requirement}")
    
    # æµ‹è¯•ä¼˜åŒ–å»ºè®®
    print("\nğŸ’¡ è·å–ä¼˜åŒ–å»ºè®®...")
    recommendations = detector.get_optimization_recommendations()
    for rec in recommendations:
        print(f"  {rec}")
    
    # æµ‹è¯•ç¡¬ä»¶å…¼å®¹æ€§æ£€æŸ¥
    print("\nğŸ” æ£€æŸ¥ç¡¬ä»¶å…¼å®¹æ€§...")
    compatibility = detector.check_hardware_compatibility()
    
    print(f"å…¼å®¹æ€§è¯„åˆ†: {compatibility.compatibility_score:.1f}/100")
    print(f"æ˜¯å¦å…¼å®¹: {'æ˜¯' if compatibility.is_compatible else 'å¦'}")
    
    if compatibility.issues:
        print("é—®é¢˜:")
        for issue in compatibility.issues:
            print(f"  âŒ {issue}")
    
    if compatibility.warnings:
        print("è­¦å‘Š:")
        for warning in compatibility.warnings:
            print(f"  âš ï¸ {warning}")
    
    if compatibility.recommendations:
        print("å»ºè®®:")
        for rec in compatibility.recommendations:
            print(f"  ğŸ’¡ {rec}")
    
    return len(gpu_infos) > 0


def test_system_report():
    """æµ‹è¯•ç³»ç»ŸæŠ¥å‘Šç”Ÿæˆ"""
    print("\n" + "=" * 60)
    print("ç”Ÿæˆç³»ç»Ÿç¯å¢ƒæŠ¥å‘Š")
    print("=" * 60)
    
    detector = GPUDetector()
    report = detector.generate_system_report()
    print(report)


def test_platform_specific_features():
    """æµ‹è¯•å¹³å°ç‰¹å®šåŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•å¹³å°ç‰¹å®šåŠŸèƒ½")
    print("=" * 60)
    
    detector = GPUDetector()
    
    if platform.system() == "Windows":
        print("Windowså¹³å°ç‰¹å®šæµ‹è¯•:")
        
        # æµ‹è¯•WMIæ£€æµ‹
        try:
            wmi_gpus = detector._detect_gpus_wmi()
            print(f"  WMIæ£€æµ‹åˆ° {len(wmi_gpus)} ä¸ªGPU")
        except Exception as e:
            print(f"  WMIæ£€æµ‹å¤±è´¥: {e}")
        
        # æµ‹è¯•WMICæ£€æµ‹
        try:
            wmic_gpus = detector._detect_gpus_wmic()
            print(f"  WMICæ£€æµ‹åˆ° {len(wmic_gpus)} ä¸ªGPU")
        except Exception as e:
            print(f"  WMICæ£€æµ‹å¤±è´¥: {e}")
    
    elif platform.system() == "Linux":
        print("Linuxå¹³å°ç‰¹å®šæµ‹è¯•:")
        
        # æµ‹è¯•lspciæ£€æµ‹
        try:
            lspci_gpus = detector._detect_gpus_lspci()
            print(f"  lspciæ£€æµ‹åˆ° {len(lspci_gpus)} ä¸ªGPU")
        except Exception as e:
            print(f"  lspciæ£€æµ‹å¤±è´¥: {e}")
        
        # æµ‹è¯•procæ£€æµ‹
        try:
            proc_gpus = detector._detect_gpus_proc_nvidia()
            print(f"  /procæ£€æµ‹åˆ° {len(proc_gpus)} ä¸ªGPU")
        except Exception as e:
            print(f"  /procæ£€æµ‹å¤±è´¥: {e}")
    
    elif platform.system() == "Darwin":
        print("macOSå¹³å°ç‰¹å®šæµ‹è¯•:")
        
        # æµ‹è¯•system_profileræ£€æµ‹
        try:
            profiler_gpus = detector._detect_gpus_system_profiler()
            print(f"  system_profileræ£€æµ‹åˆ° {len(profiler_gpus)} ä¸ªGPU")
        except Exception as e:
            print(f"  system_profileræ£€æµ‹å¤±è´¥: {e}")
    
    # æµ‹è¯•nvidia-smiæ£€æµ‹ï¼ˆæ‰€æœ‰å¹³å°ï¼‰
    try:
        smi_gpus = detector._detect_gpus_nvidia_smi()
        print(f"  nvidia-smiæ£€æµ‹åˆ° {len(smi_gpus)} ä¸ªGPU")
    except Exception as e:
        print(f"  nvidia-smiæ£€æµ‹å¤±è´¥: {e}")


if __name__ == "__main__":
    print("è·¨å¹³å°GPUæ£€æµ‹åŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    
    try:
        # åŸºæœ¬GPUæ£€æµ‹æµ‹è¯•
        has_gpu = test_cross_platform_gpu_detection()
        
        # ç³»ç»ŸæŠ¥å‘Šæµ‹è¯•
        test_system_report()
        
        # å¹³å°ç‰¹å®šåŠŸèƒ½æµ‹è¯•
        test_platform_specific_features()
        
        print("\n" + "=" * 60)
        if has_gpu:
            print("ğŸ‰ GPUæ£€æµ‹åŠŸèƒ½æµ‹è¯•å®Œæˆï¼Œæ£€æµ‹åˆ°GPUè®¾å¤‡ï¼")
        else:
            print("âœ… GPUæ£€æµ‹åŠŸèƒ½æµ‹è¯•å®Œæˆï¼Œæœªæ£€æµ‹åˆ°GPUè®¾å¤‡ï¼ˆè¿™åœ¨æŸäº›ç¯å¢ƒä¸­æ˜¯æ­£å¸¸çš„ï¼‰")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()